[{"content":"回顾 Channel 在很多主流的编程语言中，多个线程传递数据的方式一般都是共享内存，为了解决线程竞争，需要限制同一时间能够读写这些变量的线程数量。\n虽然在 Go 语言中也能使用共享内存加互斥锁进行通信，但是 Go 语言提供了一种不同的并发模型，即通信顺序进程。Goroutine 之间会通过 Channel 传递数据。\n1 2 3 4 5 6 7 ch := make(chan int) // 发送数据 ch \u0026lt;- 1 // 接收数据 i := \u0026lt;-ch 这里关于 channel 的其他使用就不详细介绍了。\n为什么使用 Channel 避免协程竞争和数据冲突问题\n更高级的抽象，降低开发难度，增加程序可读性\n模块之间更容易解耦，增加扩展性和可维护性\nChannel 底层结构 channel 的数据结构是 runtime/chan.go 中的一个 hchan 结构体。\n1 2 3 4 5 6 7 8 9 10 11 12 13 type hchan struct { qcount uint // channel 中的元素个数 dataqsiz uint // channel 能存放的元素容量 buf unsafe.Pointer // 用于存放元素的环形缓冲区，指向第一缓存的第一个数据成员 elemsize uint16 // channel 元素类型的大小 closed uint32 // 标识 channel 是否关闭![]( elemtype *_type // channel 元素类型 sendx uint // 发送元素进入环形缓冲区的 index recvx uint // 接收元素所处的环形缓冲区的 index recvq waitq // 等待接收数据的协程链表 sendq waitq // 等待发送数据的协程链表 lock mutex // 互斥锁，保护 hchan 结构体本身 } 概括一下，Channel 主要由三大核心部分组成。\n💿 一个环形缓存 buf\n🔗 两个链表（发送协程链表 recvq waitq / 接收协程链表 sendq waitq ）\n🔒 一个保护 hchan 的互斥锁 mutex\n💿 环形缓存 buf 在 hchan 结构体中，使用以下字段组成了一个环形缓存区：\n1 2 3 4 5 qcount uint // channel 中的元素个数 dataqsiz uint // channel 能存放的元素容量 buf unsafe.Pointer // 用于存放元素的环形缓冲区，指向第一缓存的第一个数据成员 elemsize uint16 // channel 元素类型的大小 elemtype *_type // channel 元素类型 💡 使用环形缓存区的好处：环形地使用数据，类似于一个环形链表，大幅降低 GC 的开销，使用时不需要回收内存。\n🔗 发送/接收协程链表 在 hchan 中，通过 recvx 和 revcq 组成了一个接收链表；通过 sendx 和 sendq 组成了一个发送链表。\n1 2 3 4 sendx uint // 发送元素进入环形缓冲区的 index（游标） recvx uint // 接收元素所处的环形缓冲区的 index（游标） recvq waitq // 等待接收数据的协程链表 sendq waitq // 等待发送数据的协程链表 等待发送和接收的协程双向链表 recvq sendq 都是 waitq 类型。waitq 是 chan.go 中定义的结构体，有 first 和 last 两个属性，分别指向链表的第一个和最后一个成员。\n1 2 3 4 type waitq struct { first *sudog last *sudog } 这个 waitq 中的指针都是 sudog 类型。sudog 是协程的一个包装，将一个协程包装成一个节点。\n1 2 3 4 5 6 7 8 9 10 11 type sudog struct { g *g next *sudog prev *sudog elem unsafe.Pointer c *hchan // ... 其他属性 } g 包装了协程，使用 next prev 指针，将协程串联成一个链表。\nelem 是 unsafe 的万能指针，存储了想要接收变量的数据的指针。比如 i \u0026lt;- ch，这里 elem 就会存储这个变量 i 的指针。\n🔒 保护 hchan 的互斥锁 mutex 这个 lock mutex 用来保护 hchan struct 的所有字段，所有协程想要操作 hchan 这个结构体的内容，就需要加这个 mutex 锁。\n并不是用来排队发送数据、接收数据的。\n为什么 channel 的内部有锁，还能达到高并发量呢？\nchannel 的互斥锁在大部分情况下仅用于保护少数关键操作，而不是每次读写操作都加锁，只有在写数据/读数据的一瞬间需要加锁，不需要一直加锁。\n使用了其他一些技术来提高 channel 的性能，比如使用无锁的循环队列实现缓冲区，减少锁的使用。\nGo 语言的运行时系统（runtime）内部对锁有一些优化技术，可以减少互斥锁的开销。\n🙋‍♂️ channel 发送数据原理 如果我们想向 channel 中发送数据，会使用 \u0026lt;- 关键字。\n1 2 3 4 ch := make(chan int) // 发送数据 ch \u0026lt;- 1 这个 \u0026lt;- 是 go 中的“语法糖”，在编译阶段，会把 \u0026lt;- 转换成 chansend1()。\n1 2 3 4 5 6 7 8 // chan.go // // entry point for c \u0026lt;- x from compiled code. // //go:nosplit func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } 📚 发送情形 channel 的发送情形可以分为三类：\n➡️ 直接发送\n💾 放入缓存\n💤 休眠等待\n➡️ 直接发送 当发送数据时，在 hchan 的 recvq 中存在休眠等待接收的协程。（这个时候缓存一定为空，或者没有缓存，不用考虑）\n直接将数据拷贝给该协程的接收变量，并唤醒在 recvq 中的这个等待协程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // chan.go func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { // ... lock(\u0026amp;c.lock) // ... if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } // .. } 加锁\n从阻塞度协程队列中取出一个 goroutine 的封装对象 sudog，如果不为 nil，直接发送\n在 send 方法中，会基于 memmove 方法，直接将元素拷贝交给 sudog 对应的 goroutine\n在 send 方法中会完成解锁动作\n💾 放入缓存 当没有协程在等待接收数据，但是还有缓存空间 qcount \u0026lt; dataqsiz，将数据放入环形缓存，维护索引 sendx qcount，成功返回。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // chan.go func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { // ... lock(\u0026amp;c.lock) // ... if c.qcount \u0026lt; c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) typedmemmove(c.elemtype, qp, ep) c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ unlock(\u0026amp;c.lock) return true } // ... } 加锁\n将当前元素添加到环形缓冲区 sendx 对应的位置\n维护索引 sendx++ qcount++\n解锁，返回成功\n💤 等待休眠 当没有协程在休眠等待数据，并且缓存已经满了（或没有缓存），将自己包装成一个 sudog，放入 sendq 队列，解锁后进行休眠。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { // ... lock(\u0026amp;c.lock) // ... // Block on the channel. gp := getg() mysg := acquireSudog() // 包装成 sudog mysg.elem = ep mysg.g = gp mysg.c = c gp.waiting = mysg c.sendq.enqueue(mysg) // 入队 atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // 休眠，之后改协程卡在这段代码 KeepAlive(ep) // someone woke us up. if mysg != gp.waiting { // 唤醒这个协程，只需要维护一下数据即可（该协程被唤醒，数据已经是被取走了的） throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) if closed { if c.closed == 0 { throw(\u0026#34;chansend: spurious wakeup\u0026#34;) } panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } return true } 加锁\n构造封装当前 goroutine 的 sudog 对象\n完成指针指向，建立 sudog、goroutine、channel 之间的指向关系\n把 sudog 添加到当前 channel 的阻塞写协程队列中\npark 当前协程\n倘若协程从 park 中被唤醒，则回收 sudog（sudog能被唤醒，其对应的元素必然已经被读协程取走，维护其他数据）\n解锁\n💁‍♂️ Chanel 接收数据原理 1 2 3 4 5 6 7 8 ch := make(chan int) // 发送数据 ch \u0026lt;- 1 // 接收数据 i := \u0026lt;- ch 接收数据的 \u0026lt;- 同样是 go 中的“语法糖”。\n在编译阶段，如果是 i \u0026lt;- ch 会转换成 runtime.chanrecv1()；如果是 i, ok \u0026lt;- ch 会转化成 runtime.chanrecv2()，两者最终都会调用 chanrecv() 方法。\n1 2 3 4 5 6 7 8 9 10 11 12 // entry points for \u0026lt;- c from compiled code. // //go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } //go:nosplit func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } 📚 接收情形 可以大致可以分为以下四大类：\n➡️ 接收有阻塞的发送协程\n💿 接收无阻塞发送协程，且缓冲区有元素\n💤 接收无阻塞发送协程，且缓冲区无元素\n➡️ 接收有阻塞的发送协程 无缓冲区，有协程在 sendq 中等待发送数据，直接将数据从发送协程中拷贝过来，再唤醒该发送协程。\n有缓冲区，读取缓冲区 recvx 元素，将 sendq 中的一个发送协程的元素写入缓冲区。\n为什么有发送协程阻塞的时候，还是要从缓存中获取数据呢？\n缓存区的数据一定比等待发送的协程中的数据更早；如果不从缓存中接收，缓存中的数据可能一直拿不走。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // chan.go func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { lock(\u0026amp;c.lock) // Just found waiting sender with not closed. if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } } func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { if c.dataqsiz == 0 { if ep != nil { // copy data from sender recvDirect(c.elemtype, sg, ep) } } else { // Queue is full. Take the item at the // head of the queue. Make the sender enqueue // its item at the tail of the queue. Since the // queue is full, those are both the same slot. qp := chanbuf(c, c.recvx) if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemmove(c.elemtype, qp, sg.elem) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz } sg.elem = nil gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) sg.success = true goready(gp, skip+1) } 加锁\n从阻塞发送协程队列中获取到一个发送协程\n倘若 channel 无缓冲区，则直接读取发送协程元素，并唤醒发送协程\n倘若 channel 有缓冲区，则读取缓冲区头部元素，并将发送协程元素发送入缓冲区尾部后唤醒发送协程\n解锁，返回\n💿 接收无阻塞发送协程，且缓冲区有元素 在 channel 中，如果没有协程在发送队列 sendq 等待接收，判断该 channel 中有无缓存，如果有，直接从缓存中取走一个数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { lock(\u0026amp;c.lock) if c.qcount \u0026gt; 0 { // Receive directly from queue qp := chanbuf(c, c.recvx) if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(\u0026amp;c.lock) return true, true } } 加锁\n获取 recvx 对应位置的元素\nrecvx++\nqcount--\n解锁，返回\n💤 接收无阻塞发送协程，且缓冲区无元素 在 channel 中，如果在 sendq 中没有协程在等待发送数据，并且 buf 中没有缓存，将该接收协程包装成 sudog，并放入等待队列 recvq 中，进行休眠。\n这个放入队列的接收协程，当被唤醒时，数据已经拷贝到位，不需要考虑如何拷贝。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { lock(\u0026amp;c.lock) gp := getg() mysg := acquireSudog() mysg.elem = ep gp.waiting = mysg mysg.g = gp mysg.c = c gp.param = nil c.recvq.enqueue(mysg) atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) gp.waiting = nil success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) return true, success } 加锁\n封装当前接收协程的 sudog 对象\n完成指针指向，建立 sudog、goroutine、channel 之间的指向关系\n把 sudog 添加到当前 channel 的阻塞读协程队列中\npark 当前协程\n倘若协程从 park 中被唤醒，则回收 sudog（sudog能被唤醒，其对应的元素必然已经被写入）\n解锁，返回\n📖参考 https://zhuanlan.zhihu.com/p/597232906\nhttps://juejin.cn/post/7265891728163635215?searchId=202308131806253D2D64A0EC686F660F01\n图片全部来自于 https://zhuanlan.zhihu.com/p/597232906\n","date":"2023-08-03T12:13:14+08:00","image":"https://emerywan.github.io/blog/p/golang/channel/go-channel_hu694e273dcd03227372ad88c983a08eba_66790_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/golang/channel/","title":"golang channel"},{"content":"🤿 深入 Kafa 🛩️ 集群与控制器 Kafka 使用 Zookeeper 来维护集群成员的信息，每个 Broker 都有一个唯一标识符（可以在配置中指定或随机生成），在 Broker 启动时，通过创建临时节点将自己的 ID 注册到 Zookeeper。\n控制器本身就是一个 Broker，复制分区领导的选举工作。集群的第一个启动 Broker 通过在 Zookeeper 中创建一个 /controller 临时节点让自己成为控制器，其他 Broker 启动时再尝试创建，会收到节点已经存在异常，会在控制器节点上创建 Zookeeper watch 对象，接受节点变更通知，确保集群中只会有一个控制器存在。\n✈️ 复制 复制功能可以让 Kafka 在个别节点失效时，仍然保证 Kafka 的可用性和持久性。\nKafka 使用 Topic 组织数据；每个 Topic 被分为若干个 Partition；每个 Partition 有多个副本，被保存在 Broker 上。副本有两种类型：\n首领副本 leader\n每个 Partition 都有一个首领副本。为了保证一致性，首领副本复制所有的 生产 \u0026amp; 消费请求。\n同步副本 follower\n同步副本不处理任何请求，唯一的任务就是从 Leader 复制消息，保持与 leader 一致的状态。follower 向 leader 发送获取数据的请求（与消费者获取数据的请求相同），leader 将消息响应发送给 follower，包含指定偏移量的消息（有序）。\n🛫 处理请求 Broker 处理客户端的请求并做出响应，会按照请求达到的顺序进行处理，这种「顺序性保证让 Kafka 具备了消息队列的特性。」\nBroker 会在它所监听的每一个端口上运行一个 Acceptor 线程，监听到达的连接（IO多路复用）；当请求达到时，会利用 n 个 Processor 线程进行处理，复制从客户端获取请求消息，并放入请求队列；放入请求队列的消息，会有 m 个 Handler 线程进行处理。\n元数据请求\n客户端使用「元数据请求」，获取所有主题列表（分区、首领、副本等所有信息），并将这些信息缓存起来，以此知道向哪里发送请求。\n元数据请求会定时/遇到错误时，定时刷新。\n生产请求\nKafka 使用 acks = 0/1/all 客户端配置，指定了需要多少个 Broker 确认才可以认为一个消息是写入成功的。\n消息被 Broker 写入本地磁盘。在 Linux 系统上，消息会被写到文件系统缓存 Page Cache 里，并不保证什么是否会被刷新到磁盘上。Kafka 依赖复制功能保障消息的持久性。\n消费请求\nConsumer 向 Broker 发送请求，从主题分区里获取特定偏移量的消息，类似于说：“请把主题 Test 分区 0 偏移量从 53 开始的消息发给我”\n其他请求\n在旧版本的 Kafka 中，消费者使用 Zookeeper 来跟踪偏移量，在消费者启动的时候，通过检查保持在 Zookeeper 上的偏移量知道从哪里开始处理消息。\n在新版本中，偏移量 offset 保存在特定版本的 Kafka 主题 __consumer_offset 上。\n💺 物理存储 Kafka 的基本存储单元是分区 Partition。\n文件管理\n保留数据是 Kafka 的一个基本特性，Kafka 不会一直保留数据，也不会等到所有的数据都消费完才删除。Kafka 可以为每个主题配置数据的保留期限，规定数据在删除之前可以保留多长时间，或者清理数据之前可以保留的数据大小。\nKafka 保存的数据通常都是很庞大的，在一个大文件中查找和删除消失是很费时的，也很容易出错，所以会把每个分区分成若干个「片段」Partition -\u0026gt; Segment。 在 Broker 向 Partition 写入数据时，如果达到上限，就关闭当前文件，并打开一个新文件。\n当前正在写入数据的片段叫做活跃片段，「活跃片段永远不会被删除」。（即使活跃片段中的消息超过了保留时间，片段在被关闭之前无法被删除）\n文件格式\nKafka 把消息和偏移量保存在文件里，保存在磁盘上的数据格式与从生产者发送来或发送给消费者的数据格式是一样的，Kafka 不会进行处理。\n生产者发送的是被压缩过的消息，同一个批次的消息会被压缩在一起，发送给 Broker，然后 Broker 再发送给消费者。\n索引\nKafka 给每个分区都维护了一个稀疏的哈希索引，把偏移量映射到片段文件和偏移量在文件里的位置。\n索引和 Partition 一样被分为片段，所以在删除消息时，也会删除相应的索引。\nKafka 不会维护索引的校验和，索引出现损坏，或删除了索引（完全安全），Kafka 都会自动重新生成索引。\n👌 可靠数据传递 Kafka 的可靠性并不是单方面的事情，应该从整个系统层面来考虑可靠性的问题，如应用架构、生产者消费者的配置、主题配置、Broker 配置。\n系统的可靠性需要在许多方面做出权衡，如复杂性、可用性、磁盘空间使用等。\n🚗 可靠性保证 关系型数据库使用 ACID 机制来保障数据的可靠性。一个系统的保证机制对于构建可靠的应用程序来说至关重要。 Kafka 可以再以下方面作出保证：\n🛸 Kafka 可以保证 分区 Partition 消息的顺序。\n使用同一个生产者往同一个分区写入消息。\n🛸 只有当消息被写入分区的所有同步副本时（不一定要写入磁盘），消息才被认为是“已提交“的。\n生产者可以选择接收不同类型的确认（acks）。\n🛸 只要还有一个副本是活跃的，已提交的消息就不会丢失。\n🛸 消费者只能读取到已提交的消息。\n我们可以通过 Kafka 的相关配置参数，对所需要的可靠性做出「权衡」：消息的「可靠性、一致性」的重要程度与「可用性、高吞吐量、低延迟、硬件成本」的重要性之间的权衡。\n🚓 复制的可靠 Kafka 的复制机制和分区副本架构是 Kafka 可靠性保证的核心。\n把消息写入多个副本可以使 Kafka 在发生崩溃时，保证消息的「持久性」。\nKafka 的主题 Topic 被分为多个分区 Partition，分区是最基本的数据块。分区可以有多个副本，包含一个首领 leader 和多个同步副本 follower，leader 负责读\u0026amp;写事件，其他副本只需要与首领保持同步，并及时复制最新的事件。\n🚕 Broker 的可靠 Broker 有 3 个配置参数会影响 Kafka 存储消息的可靠性。（可以应用在 broker 级别，控制所有主题的行为；也可以单独应用在 Topic 级别，控制单个主题）\n✒️ 复制系数\nBroker 级别：default.replication.factor Topic 级别：replication.factor 复制系数表示该 Topic 的 Partition 会被几个不同的 Broker 复制。\n如果复制系数为 N，当有 N-1 个 Broker 失效时，仍然可以从 Topic 读取或写入数据。\n更高的复制系数能够带来更高的可用性、可靠性和更少的故障，但会占用成倍的存储空间，需要在可用性和存储硬件间做出平衡。\n✒️ 不完全的首领选举\n只有 Broker 级别，默认为 true ：unclean.leader.election = true 在选举过程中没有丢失数据，这个选举就是”完全“的（提交的数据同时存在于所有同步副本上）。\n如果设置为 true，允许不同步的副本成为首领，需要承担数据不一致或丢失数据的风险。\n✒️ 最少的同步副本\nBroker / Topic 级别：min.insync.replicas 消息只有在被写入到所有同步副本之后才被认为是已提交的。\n当不满足最少同步副本时，会停止接受生产者请求，变成只读状态。\n🛺 生产者的可靠 🧲 发送确认\n三种确认模式：acks: 指定了必须要有多少个分区副本收到消息，生产者才会任务消息写入时成功的\nacks=0 不会等待任务来自服务器的响应。达到最高的吞吐量，无法得知消息状态。\nacks=1 只要 Partition Leader 收到响应。消息可能会丢失，Leader宕机后，一个未同步的Fllower成为新的Leader。\nacks=all 消息要全部同步到所有的 Leader\u0026amp;Fllower。\n🧲 配置重试参数\n生产者向 Broker 发送消失时，会返回一个成功/错误响应码。如果 Broker 返回的错误可以通过「重试」来解决，生产者会自动处理这些错误。\n错误响应码可以分为两种：（1）重试之后可以解决的，可重试错误 LEADER_NOT_AVAILABLE （2）无法通过重试解决的，不可重试错误 INVALID_CONFIG\n如果想抓住异常并多重试几次，可以将重试次数设置多一点，让生产者重试\n如果想丢弃数据，重试参数毫无意义\n如果想保存消息到某个地方，后续进行处理，可以停止重试\n⚠️ 重试会带来消息重复的风险，可以在应用中向消息中加入唯一标识符，用于检测重复消息（新版 Kafka 能够自动处理），消费者在读取时进行清理；在业务上也可以实现幂等，即使出现重复消息，对结果的处理也不会造成负面影响。\n🧲 额外的错误处理\n错误处理器的代码逻辑与具体的应用程序及其目标有关，根据具体的架构决定。（丢弃？记录错误？保存到磁盘？回调另一个应用？）\n如果错误处理只是为了重试发送消息，最好还是使用生产者内置的重试机制。\n🚙 消费者的可靠 只有被写入所有同步副本的数据，对消费者才是可用的，消费者得到的消息已经具备了一致性。\n消费者需要做的是跟踪哪些消息已经读取过，哪些是还没有读取过的，是在读取消失时不丢失消息的关键。\n📐 提交频率（是性能和重复消息之间的权衡）\n可以在轮询后维护状态，也可以在一个循环里多次提交偏移量，完全取决于性能和重复处理消息之间做出权衡。\n📐 消费者需要重试\n在进行轮询后，有些消息不会被完全处理，需要稍后重试。如记录 #31 处理成，记录 #30 处理失败。提交偏移量时需要进行处理（#31？/ #30）\n遇到可重试错误时，提交最后一个处理成功的偏移量，将没有处理好的消息保存到缓冲区中，调用消费者的 pause() 确保其他轮询不会获取数据（停止接收消息防止缓冲区溢出），在保存轮询（保持心跳）的情况下尝试重新处理。如果重试成功或重试次数达到上限并决定放弃，将结果记录下来，使用 resume() 继续从轮询中获取数据。\n遇到可重试错误，把错误写入到一个单独的主题，继续处理业务。使用专门的消费者从这个单独的主题上读取消息进行重试。\n📐 长时间处理消息\n有时处理数据需要很长的时间。「即使不想获取更多的数据，也要保持轮询，这样客户端才能向 Broker 发送心跳。」\n","date":"2023-03-31T08:08:08+08:00","image":"https://emerywan.github.io/blog/p/kafka/more/kafka_hua49c73262baf26feb83224ca97767fc9_25104_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://emerywan.github.io/blog/p/kafka/more/","title":"深入 Kafka"},{"content":"命令行工具 Kafka 提供了一些基于脚本的命名行工具 ${dir}/bin/xxx.sh，用于管理集群。这些管理通过 Java 类实现，通过脚本调用。\n1 2 3 4 5 # 启动 Zookeeper 服务（新版已内置） bin/zookeeper-server-start.sh config/zeekeeper.properties # 启动 Kafka 服务 bin/kafka-server-start.sh config/server.properties 🔍 更多 CLI 操作：🌐 https://www.conduktor.io/kafka/kafka-topics-cli-tutorial/\nTopic 操作 Kafka 大部分命令行工具直接操作 Zookeeper 上的元数据，并不会直接连接到 Broker 上，需要确保所使用的工具版本与集群中的 Broker 版本相匹配。\n🎗️\nKafka 2.2+ 使用 Kafka 的 hostname \u0026amp; port 进行操作 --bootstrap-server 127.0.0.1:9092\n旧版本使用 Zookeeper 的 URL \u0026amp; port 进行操作 --zookeeper 127.0.0.1:2181\n1 2 3 4 5 6 7 8 9 10 # 创建主题 # 2.2 + kafka-topics.sh --bootstrap-server localhost:9092 \\ --create \\ --topic first_topic \\ --partitions 3 \\ # 分区数量 --replication-factor 1 # 副本数量 # old kafka-topics.sh --zookeeper localhost:2181 --topic first_topic --create --partitions 3 --replication-factor 1 1 2 3 4 5 # 列出主题 # 2.2 + kafka-topics.sh --bootstrap-server localhost:9092 --list # 详细信息 kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic first_topic 1 2 3 4 5 # 修改主题 kafka-topics.sh --bootstrap-server localhost:9092 \\ --alter \\ --topic first_topic \\ --partitions 5 生产 \u0026amp; 消费 🎗️ Producer\nKafka 2.5+ 使用 --bootstrap-server\n旧版本 Kafka 使用 --broker-list\n1 2 3 # 生产 kafka-console-producer.sh --bootstrap-server localhost:9092 \\ --topic first_topic 🎗️ Consumer\n使用 --bootstrap-server，自 v0.10 开始 --zookeeper 已被废弃\n1 2 kafka-console-consumer.sh --bootstrap-server localhost:9092 \\ --topic first_topic 🤲 Producer 🐈 生产者 🧩 ProducerRecord 对象包含目标主题 Topic 和需要发送的内容 Value，可以可以指定分区 Partition 和键值 Key（消息的附加信息，可以用来决定消息被写入哪个分区，相同 Key 的消息会写入同一个分区） 🧩 发送消息时，生产者需要将 ProducerRecord 对象序列化为字节数组，在网络上传输 🧩 数据被传送给分区器 Partitioner，如果指定了分区，会直接返回；没有指定，根据 Key 选择一个分区；没有指定 Key，会根据 Value 进行散列，根据散列值把消息映射到相应的分区 🧩 这条记录选好分区后，会被添加到一个记录批次中，这个批次的所有消息会被发送到相同的主题和分区上（批处理），独立的 Processer 线程会负责把这些数据发送到对应的 broker 上 🧩 Broker 收到消息时会返回一个响应 消息成功写入 Kafka，返回一个 RecordMetaData 对象，包含主题和分区的信息 写入失败，会返回一个错误，生产者收到错误之后会尝试重新发送，多次失败直接返回错误信息 重要配置 acks\n指定了必须要有多少个分区副本收到消息，生产者才会任务消息写入时成功的\nacks=0 不会等待任务来自服务器的响应。达到最高的吞吐量，无法得知消息状态。 acks=1 只要 Partition Leader 收到响应。消息可能会丢失，Leader宕机后，一个未同步的Fllower成为新的Leader。 acks=all 消息要全部同步到所有的 Leader\u0026amp;Fllower。 retries\n生产者可以重发消息的次数\nmax.in.flight.requests.per.connection\n生产者在收到服务器响应前可以发送多少个消息。\nKafka 可以保证同一个分区里的消息是有序的，max.in.flight.requests.per.connection=1，即使发送了重试，消息依旧有序，但是会严重影响生产者的吞吐量。\n🐈‍⬛ 同步发送 1 public Future\u0026lt;RecordMetadata\u0026gt; send(ProducerRecord\u0026lt;K, V\u0026gt; record) { } 使用 send() 方法发送消息，会返回一个 Future 对象，调用 get() 方法进行等待，就可以知道消息是否发送成功。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 相关配置 String bootstrapServers = \u0026#34;127.0.0.1:9092\u0026#34;; Properties properties = new Properties(); properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 序列化方式 properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 创建 Producer KafkaProducer\u0026lt;String, String\u0026gt; producer = new KafkaProducer\u0026lt;\u0026gt;(properties); // 创建消息 ProducerRecord\u0026lt;String, String\u0026gt; producerRecord = new ProducerRecord\u0026lt;\u0026gt;(\u0026#34;demo_topic\u0026#34;, \u0026#34;hello world!\u0026#34;); // 发送消息 try { producer.send(record).get(); // get() 同步 } catch (Exception e) { // 发生了无法解决的错误 或 重试超过最大次数 e.printStackTrace(); } 🐅 异步发送 1 public Future\u0026lt;RecordMetadata\u0026gt; send(ProducerRecord\u0026lt;K, V\u0026gt; record, Callback callback) { } 调用 send() 方法，并指定一个回调函数，服务器在返回响应时调用该函数。\n1 2 3 4 5 6 7 8 9 producer.send(producerRecord, new Callback() { public void onCompletion(RecordMetadata recordMetadata, Exception e) { if (e != null) { // 发送失败 // ... // 对应的业务处理逻辑 } } }); 🐆 序列化器 常见的序列化\u0026amp;反序列化器有 Avro、Thrift、Protobuf 等。\nApache Avro 是一种与编程语言无关的序列化格式。\nAvro 通过与语言无关的 schema 来定义，使用 JSON 来描述，数据会被序列化为二进制文件或 JSON 文件。\n满足 Avro 兼容原则下，写入的消息改动 schema 写入了新的数据，负责读消息的应用程序可以继续处理而无需做任何更改。\n🐕 分区 ProducerRecord 对象可以包含 topic、partition、key、value 等，通常我们会指定 key，作为附加消息，决定消息该被写入哪个分区，拥有相同 key 的消息会被写入同一个分区。\n1 2 3 4 5 6 7 // topic: CustomerCountry // key: Laboratory Equipment // value: USA ProducerRecord\u0026lt;String, String\u0026gt; record = new ProducerRecord\u0026lt;\u0026gt;(\u0026#34;CustomerConuntry\u0026#34;, \u0026#34;Laboratory Equipment\u0026#34;, \u0026#34;USA\u0026#34;); // 创建 key-\u0026gt;null 的消息 ProducerRecord\u0026lt;String, String\u0026gt; record = new ProducerRecord\u0026lt;\u0026gt;(\u0026#34;CustomerCountry\u0026#34;, \u0026#34;USA\u0026#34;); 当 key 为 null 时，Kafka 会对键进行散列（Kafka 自己的散列算法），然后根据散列值映射到特殊的分区。\n自定义分区策略 通过实现 interface Partitioner 实现自定义分区策略，主要包含：\nvoid configure(Map\u0026lt;String, ?\u0026gt; configs) 实际应用中，应通过该方法传入相关信息 void partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) void close() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class BananaPartitioner implements Partitioner { void configure(Map\u0026lt;String, ?\u0026gt; configs) {} // 自定义分区策略 int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) { List\u0026lt;PartitionInfo\u0026gt; partitions = cluster.partitionsForTopic(topic); int numPartitions = partition.size(); if ((keyBytes == null) || (!(key instanceOf String))) { throw new InvalidRecordException(\u0026#34;We expect all messages to have customer name as key\u0026#34;); } if (((String) key).equals(\u0026#34;Banana\u0026#34;)) { // Banana 总是被分配到最后一个分区 return numPartitions; } // 其它记录被散列到其他分区 return ((Math.abs(Utils.murmur2(keyBytes))) % (numPartitions - 1)); } void close() { } } 👌 Consumer 🦜 消费者组 🦚 消息轮询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 配置 String bootstrapServers = \u0026#34;127.0.0.1:9092\u0026#34;; String groupId = \u0026#34;demo_groupId\u0026#34;; String topic = \u0026#34;demo_topic\u0026#34;; Properties properties = new Properties(); properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId); properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \u0026#34;earliest\u0026#34;); // 创建消费者 KafkaConsumer\u0026lt;String, String\u0026gt; consumer = new KafkaConsumer\u0026lt;\u0026gt;(properties); // 订阅主题 consumer.subscribe(Arrays.asList(topic)); // 轮询 while(true){ ConsumerRecords\u0026lt;String, String\u0026gt; records = consumer.poll(Duration.ofMillis(100)); // 100 -\u0026gt; 超时时间 for (ConsumerRecord\u0026lt;String, String\u0026gt; record : records){ // 业务处理 log.info(\u0026#34;Key: \u0026#34; + record.key() + \u0026#34;, Value: \u0026#34; + record.value()); log.info(\u0026#34;Partition: \u0026#34; + record.partition() + \u0026#34;, Offset:\u0026#34; + record.offset()); } } 消息轮询是消费者 API 的核心，一旦消费者订阅的主题，轮询会处理所有的细节。 poll() 会负责查找 GroupCordinator，加入群组，接受分配的分区，发送心跳和获取数据。如果发生了再均衡，也是这个轮询期间进行的。\n⚠️ 消费者组中的一个消费者只能运行在一个线程中。如果需要多个线程处理一个 Patition 中的消息，可以将这个消费者获取的一批数据，可以使用 ExecutorService 启动多个线程处理。\n🦉 偏移量 Kafka 使用偏移量 offset 追踪消息在分区中的位置。\nConsumer 向一个特殊的主题 _consumer_offset 发送消息，更新分区当前的位置。\n如果提交的 offset「小于」客户端处理的最后一个消息偏移量，那么「两个偏移量之间的消息会被重复处理」 如果提交的 offset「大于」客户端处理的最后一个消息偏移量，那么「两个偏移量之间的消息会丢失」 自动提交 如果 enable.auto.commit = true，消费者会自动把从 poll() 方法接收到的最大偏移量提交上去。提交的时间间隔由 auto.commit.interval.ms 控制，默认为 5s。\n自动提交发生在每次轮询时，如果没有提交偏移量，会把上一次调用返回的偏移量提交上去，「不能保证这些消息已经被业务处理了」。\n⚠️ 如果设置默认提交时间为 5s，在提交后 3s 发生了再均衡，之后的消费者会再次获取到 3s 前提交的偏移量，这些消息会被重复处理，「无法避免这种情况」，只能缩小提交的时间间隔更频繁地提交 offset，「Kafka 也没有为自动提交预留避免重复处理消息的方法」。\n适合于不重要的消息场景，如日志采集。\n同步提交 设置 auto.commit.offset = false，可以让应用程序决定在什么时候提交偏移量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 while (true) { ConsumerRecords\u0026lt;String, String\u0026gt; records = consumer.poll(100); for (ConsumerRecord\u0026lt;String, String\u0026gt; record : records) { // ... // 处理业务 // ... try { consumer.commitSync(); // 手动提交 } catch (CommitFailedException e) { log.error(\u0026#34;commit failed\u0026#34;, e); } } } 只要没有发生不可恢复的错误，commitSync() 方法会「一直尝试直到提交成功为止」。如果提交失败，则抛出异常。\n异步提交 使用异步提交 API，只管发送提交请求，无需等待 Broker 的响应。\n1 consumer.commitAsync(); 同步提交 commitSync() 会一直重试，但是异步提交 commitAsync()「不会重试」。不进行重试，是因为在收到服务器响应的时候，可能有一个更大的 offset 已经提交成功。\n异步提交同样支持回调。\n1 2 3 4 5 6 7 8 consumer.commitAsync(new OffsetCommitCallback()) { public void onComplete(Map\u0026lt;TopicPartition, OffsetAndMetadata\u0026gt; offsets, Exception e) { if (e != null) { // 异步提交失败 // ... 业务处理 / 重试 } } } 异步提交重试，可以使用一个单调递增的序列号维护异步提交的顺序。在进行重试前，先检查回调序列号与维护的序列号的大小，如果回调序列号较大，说明有一个新的提交已经发送，不应该重试。\n组合提交 一般情况下，偶尔的提交失败不进行重试没有太大问题，只要后续有更大的 offset 成功提交，就不会有问题。\n所以，在消费者关闭前，可以组合使用两种提交方式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 try { while (true) { // ... // 消费消息业务 // ... comsumer.commitAsync(); // 异步提交 } } catch (Exception e) { log.error(\u0026#34;Unexpected error\u0026#34;, e); } finally { try { consumer.commitSync(); // 同步，会不断重试 } finally { consumer.close(); } } 提交特定偏移量 每次消费者 poll() 的都是一批数据，commitSync() / commitAsync() 每次提交都是这个批次最后的 offset，如果想要在批次中间提交偏移量，可以传入「希望提交的分区和偏移量的 map」。\n但是，消费者可能不知读取一个分区，这样做需要「跟踪所有分区的偏移量」，通常会使代码变得很复杂。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 private Map\u0026lt;TopicPartition, OffsetAndMetadata\u0026gt; currentOffsets = new HashMap\u0026lt;\u0026gt;(); int count = 0; while (true) { ConsumerRecords\u0026lt;String, String\u0026gt; records = consumer.poll(100); // 假设每个批次 10000 条数据 for (ConsumerRecord\u0026lt;String, String\u0026gt; record : records) { // 业务处理 // ... currentOffsets.put(new TopicPartition(record.topic(), record.partition()), new OffsetAndMetadata(record.offset() + 1, \u0026#34;no metadata\u0026#34;)); if (count % 1000 == 0) { // 在每个批次中，没处理 1000 条数据提交一次 offset consumer.commitAsync(currentOffsets, null); } count++; } } 🦩 特定offset开始处理 如果想要从分区的起始/末尾位置读取消息，可以直接使用 seekToBeginning(Collection\u0026lt;TopicPartition\u0026gt; tp) 和 seekToEnd(Collection\u0026lt;TopicPartition\u0026gt;)\n有时，在业务上需要从特定的 offset 开始读取消息，可以使用 seek() 进行查找。\n1 2 3 4 5 // class KafkaConsumer void seek(TopicPartition partition, long offset); void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata); 比如在一些业务中，对所有的操作都要进行处理，不能丢失消息，处理消失后要将结果记录到数据库、NoSQL 存储引擎等地方，需要将「保存记录」「偏移量」放在一个原子操作里完成，要么全部成功，要么全部失败。可以将记录和偏移量都保存在数据库中，用一个事务操作，保证原子性。当消费者分配新分区时，就可以使用 seek() 查找保存在数据库中的指定offet了，不会丢失数据和重复处理。\n🖇️ Connect 💦 Stream ","date":"2023-03-26T08:08:08+08:00","image":"https://emerywan.github.io/blog/p/kafka/operation/1_hu7e5e6f704cbbe344fcb15d211398a1e1_48507_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/kafka/operation/","title":"Kafka 操作（Doing）"},{"content":"🧊 Buffer Pool MySQL 的数据是存储在磁盘中的，为了提升读写性能，InnoDB 设计了一个缓存池 Buffer Pool。\n本质上是 InnoDB 向操作系统申请的一段连续内存空间，可以通过 innodb_buffer_pool_size 来进行调整大小。\n当读取数据时，如果数据已经在 Buffer Pool 中，会直接返回；如果不在，就会将数据完整的页信息全部加载到内存中，再返回给客户端。\n当修改数据时，会修改 Buffer Pool 中的缓存页（-\u0026gt; 变成脏页），在合适的时机，由后台线程写入到磁盘。\n🧩 结构 Buffer Pool 中的连续内存，会被分割成一个个的页，和 InnoDB 的页大小一样，都是 16KB，称为缓存页。\n每一个缓存页都会由一个控制块进行管理（位于 Buffer Pool 的最前面），每个缓存页与控制块一一对应。\n🧩 内容 在 Buffer Pool 中，主要包括了六部分的内容：\n数据页 索引页 插入缓冲 undo 页 自适应哈希索引 锁信息 👷‍♂️ 管理 Buffer Pool 的链表 在 MySQL 服务运行过程中，连续的 BuuferPool 内存空间的页面有空闲的，也有非空闲的，为了能够快速的找到需要的页面，防止一个一个的遍历浪费时间， InnoDB 使用了许多🔗链表管理 Buffer Pool 的页（空闲页、干净页、脏页）。\n⛓️ Free 链表 \u0026ndash; 管理空闲页 💡 空闲页：Buffer Pool 内存中未被使用的页。\n为了能快速找到空闲的缓存页，使用 Free 空闲链表管理空闲页。\nFree 链表的节点是一个个空闲页所对应的控制块。\n当需要从磁盘中加载一个页到 Buffer Pool 时，就从 Free 链表中找到一个空闲页，加载数据并更改控制块的信息，并从 Free 链表中移除。\n⛓️ Flush 链表 \u0026ndash; 管理脏页 💡 脏页（dirty page）：修改了缓存页中的数据，与磁盘中的页数据不一致，称为脏页。\n被修改过的缓存页的控制块，会被作为节点加入到 Flush 链表。\nFlush 链表的结构和 Free 链表差不多。后台线程会在一定的时机，通过遍历 Flush 链表，将脏页写入磁盘（WAL）。\n⛓️ LRU 链表 \u0026ndash; 管理脏页\u0026amp;干净页 💡 干净页（clean page）：加载了数据未作修改的缓存页。\n💡 脏页（dirty page）：加载了数据做了修改的缓存页。\nBuffer Pool 的大小是有限的，不可能将所有的数据都放在内存中，innoDB 通过 LRU 算法（修改过的），将频繁访问的数据停留在 Buffer Pool 中。\n简单的 LRU 算法在 MySQL 中可能会导致：\n😵 预读失效\nMySQL 会将被加载页的临近页一同加载到内存（为了减少磁盘 IO），如果这些页没有被访问，这个预读相当于浪费了。\n（通过将 LRU 链表划分为 young 区和 old 区，加载的数据现放到 old 区域，被访问到之后，才被加入 young 区域）\n🤢 Buffer Pool 污染\n一个 SQL 扫描大量的数据（如索引失效时，进行全表扫描来判断条件），由于链表空间有限，可能会把内存中的所有页全部替换出去，导致热点数据全部失效，后续缓存全部没有命中，导致大量磁盘 IO。\n（加大数据放入 young 区的条件，加载到 old 区域的数据，停留时间超过阈值时，才有资格放到 young 区域）\nInnoDB 的 LRU 链表被分为两个区域：（1）热数据 young 区域；（2）冷数据 old 区域。\n📃 预读的页只会加载到 old 区域的头部，当该页真正被访问的时候，才会被移动到 young 区的头部。\n⏱️ 移动到 young 区域的条件除了被访问外，还需要判断停留在 old 区域的时间。（防止全表扫描时，被访问一次后就不在使用）。当访问的缓存页已经在 old 区域停留时间超过阈值 innodb_old_blocks_time=1000ms 时，才会被插入到 young 区头部。\n💿 脏页刷盘的时机 当修改数据时，会记录对应的 redo log \u0026amp; bin log（WAL），修改的是 Buffer Pool 中的缓存页，然后将其设置为脏页并加入 Flush 链表，由后台线程刷新数据到磁盘。\n以下情况会主动刷新数据到磁盘：\n🎗️ 当 redo log 日志写满时\n🎗️ 当 Buffer Pool 空间不足时，会淘汰一些缓存页，如果时脏页，会刷入磁盘\n🎗️ 当 MySQL 认为空闲时，异步地将脏页刷新到磁盘\n🎗️ 当 MySQL 主动正常关闭前\n","date":"2023-03-07T18:02:02+08:00","image":"https://emerywan.github.io/blog/p/mysql/innodb/buffer-pool/bufferpool_hu9753cf048aa8ef6ecf388c9b29af095f_8518_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://emerywan.github.io/blog/p/mysql/innodb/buffer-pool/","title":"InnoDB 缓冲池 Buffer Pool"},{"content":"观察者模式是一种行为型模式。\n观察者模式定义对象间的一对多的依赖关系，当一个对象的状态发生改变时，其他所有依赖的对象都会得到通知，并自动更新。\n观察者模式又称为「发布-订阅模式」Publish-Subscribe，是一种通知机制，让发送通知的一方（被观察者）和接收通知的一方（观察者）彼此分离，互不影响。\n常见的场景：\n🔖 比如 Github 的 Actions，其实就是观察者模式的一种体现，当我们根据规则进行了一些 git 操作后，Github Actions 会根据配置做一些操作，比如编译/检查格式等。 🎈 实现方式 🎗️ 「发布者」添加订阅机制，可以控制对象订阅与取消订阅事件\n一个用于存储订阅者的 List 成员变量 用于添加/删除的公有方法 当发生发布者事件时，通过遍历订阅者并调用对象特定的通知方法 🎗️ 「订阅者」实现统一的接口，发布者仅通过该接口与订阅者交互 通常会有对各订阅者跟踪一个发布者的事件，实现统一接口防止耦合 在接口中声明通知方法及其参数 ⚠ 注意事项：\n顺序执行通知时，可能会因为某一观察者导致卡壳，通常会采用异步的方式执行任务。 🛠️ 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class Store { private Map\u0026lt;String, Product\u0026gt; products = new HashMap\u0026lt;\u0026gt;(); // 希望订阅新上架的商品的人 private List\u0026lt;ProudctObserver\u0026gt; observers = new ArrayList\u0026lt;\u0026gt;(); public boolean addObserver(ProudctObserver pb) { this.observers.add(pb); } pubilc boolean removeObserver(ProductObserver pb) { return this.observers.remove(pb); } // 发布新商品 public void addNewProduct(String name, BigDecimal price) { Product p = new Product(name, price); products.put(name, p); // 📧 通知观察者 observers.forEach(o -\u0026gt; o.onPublished(p)); } // 更新商品价格 public void setProductPrice(String name, double price) { Product p = products.get(name); p.setPrice(price); // 📧 通知观察者 observers.forEach(o -\u0026gt; o.onPriceChanged(p)); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 被观察者实现统一的接口 interface ProductObserver { void onPublished(Product product); void onPriceChanged(Product product); } // 观察者对象 class Customer implements ProdcutObserver { // ... } class Admin implements ProductObserver { // ... } 1 2 3 4 5 6 7 // observer 观察者 Admin admin = new Admin(); Customer customer = new Customer(); // 注册观察者 store.addObserver(admin); store.addObserver(customer); ","date":"2023-03-06T12:02:02+08:00","image":"https://emerywan.github.io/blog/p/design-pattern/observer/observer_hua5fe444eaf0979d6378130641051be73_47507_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/design-pattern/observer/","title":"观察者模式"},{"content":" Apache Kafka is an open-source distributed event streaming platform.\nKafka 是一个开源的分布式事件流平台。\n📑 基本概念 Productor \u0026amp; Consumer 把消息放到队列里面的叫「生产者」；从队列中消费消息的叫「消费者」。\nTopic Producer 将消息发送到特定的主题 Topic，Consumer 通过订阅特定的主题 Topic 来消费消息。\n并非所有的消费者都想要全部的消息，消费者只对自己感兴趣的 Topic 进行订阅，从指定的 Topic 来获取消息。 这个发送问题由 生产者 Product 来解决，生产者在发送消息时，对消息进行逻辑上的分类，将消息发送到指定的 Topic。（发布-订阅模型）\noffset 多个消费者可能对同一个主题感兴趣，即多个消费者 Consumer 订阅同一个主题 Topic。\n这个消费问题由 消费者 Consumer 来解决。 Kafka 将所有的消息进行持久化存储，让消费者各取所需，想取哪个消息，想什么时候取都行，只需要传递一个消息的 offset 即可。\nKafka 将消息以消息日志的方式追加写在磁盘中（顺序磁盘 IO）。\noffset 表示了消费者的消费进度。每一条消息都会根据时间先后顺序有一个递增的序号，用 offset 来表示消费者的消费进度到哪了，每个消费者会都有自己的 offset。\n每次消费消息的时候，都要提交这个 offset，Kafka 可以选择「自动提交」或者「手动提交」。\nPartition Partition 是 Kafka 「最基本的部署单元」。\n对于海量数据，单机的存储容量和读写性能肯定有限，一种常见的存储方案就是「对数据进行分片存储」。\n例如在 MySQL 中，单表的数量达到几千万、上亿时，会进行分库、分表操作\n例如在 Redis 中，当单个实例的数据量达到几十G引发性能瓶颈时，会进行分片集群\n在 Kafka 中，同样采取了水平拆分的方案，将拆分后的数据子集称为 Partition 分区。各个分区的数据集合即为全量数据。\n分区路由可以简单地理解为一个 Hash 函数，生产者在发送消息时，可以自定义这个函数的规则决定发往的分区。将分区规则设计的合理，可以将消息均匀地分配到不同的分区上。\n生产者 Productor 发送一条消息，先通过 Topic 对消息进行逻辑分类，在通过 Partition 进一步做物理分片，最终多个 Partition 会均匀地分布在集群的每台机器上，从而很好地解决了存储扩展性问题。\nBroker 一台 Kafka 服务器被称为 Broker，Kafka 集群由多台 Kafka 服务器组成。\nKafka 是「天然分布式」的。\n一个 Topic 会被分为多个 Partition，这些 Partition 会分布在不同的 Broker 中。\nleader \u0026amp; follower 在 Kafka 集群中，每台机器都会存储一些 Partition，为了防止机器宕机时，这部分数据无法访问的问题（持久化保证数据不丢失）。 需要 Kafka 具备故障转移能力，当某台机器宕机后，能够继续保证服务可用。\n与 Reids Cluster 类似，Kafka 通过「Partition 多副本」的方式，解决了高可用问题。 在 Kafka 集群中，每个 Partition 都有多个副本，保存了相同的信息。\n副本之间是 「一主多从」的关系：\nleader 副本负责读写数据 follower 副本负责同步消息，只负责待命 当 leader 副本发送故障时，选举 follower 副本成为新的 leader 对外提供服务。\nConsumer Group Kafka 是个高并发的系统，消息的拉取同样是并行的，多个消费者去消费 Topic 消息。\nKafka 引入了消费者组 Consumer Group 的概念，每一个消费者都有一个对应的消费者组。组间进行广播消费，组内进行集群消费。同时限定：「每个 Partition 只能由消费者组中的一个消费者进行消费」。\n当需要加快消息的处理速度，（如消费者组B）只需要增加新的消费者即可，Kafka 会以 Patition 为单位重新做负载均衡。\n一个消费者组可以消费 Topic 的全部数据，消费者组在逻辑上是相互独立的。\n🗳️ 存储结构 Kafka 使用「日志文件 Logging」的方式来存储消息；使用「稀疏哈希索引」来加快查询。\nKafka 存储的主要是消息流（文本、自定义格式），对于 Broker 来说，只需要关注消息的投递，无需关注内容本身\n写入方面，数据量级非常大，都是按顺序写入（队列），且无需考虑更新\n需求简单，只需要按照 offset 查询消息即可\n在为了满足其写入需求（量级大、不更新），采用 Append 追加日志的方式最理想，可以充分利用「磁盘顺序 IO」。\n在查询时，只需要通过 offset 定位消息，在内存中维护了一个「从 offset 到日志文件的偏移量」的映射关系，每次 查询时，先根据 offset 找到日志文件的偏移量，即可快速读取到日志消息。\n为了避免哈希索引常驻内存消耗过多空间的问题，将消息划分为若干个块 block，每个索引需要定位 block 块中的第一条消息的 offset 即可（稀疏索引）， 然后在 block 中顺序查找。\n🔥 Kafka 的高性能 📑 生产消息 Kafka 客户端与传统的数据库或消息中间件不同，在将消息发送给 Broker 之前，在 Client 端先完成大量的工作之后才发送消息，分摊 Broker 的计算压力。\n🫧 批量发送\nKafka 通过对多条消息按照分区进行分组，每次发送一个消息集合，从而减少网络传输的开销。\n🫧 消息压缩\n在批量发送的前提下，对消息进行压缩（数据量越大，压缩效果更好）。同时对多条消息进行压缩，能大幅减少数据量， 同时减少网络、磁盘IO开销。消息持久化到 Broker 的磁盘时，依旧是压缩状态，最终是在 Consumer 端进行解压。\n🫧 高效序列化\nKafka 的 Key 和 Value，都支持自定义类型，只需要提供相应的序列化和反序列化器即可。可以根据情况选取对应的序列化方式。\n🫧 内存池复用\nKafka 提出了「内存池机制」，提高复用，减少频繁的创建和回收。（本质上与连接池、线程池一样）。\nProductor 在创建时，会占用一块固定大小的内存区域，划分为若干个块（例如 16KB）。当需要创建一个新的发送 Batch 时，直接从内存中取出一个块， 从中不断地写入消息（写满或到指定阈值时间时），将这个 Batch 发送给 Broker，之后内存块就会回到缓存池中继续复用。 不会涉及 JVM 的内存回收，以应对 Kafka 的高并发场景。\n📇 存储消息 🫧 IO 多路复用\n使用 1 个 Acceptor 线程，处理新的连接；使用 N 个 Processor 线程，读取请求；使用 M 个 Handler 线程，处理业务逻辑。\n1 个 Acceptor 线程：用于监听网络套接字，接受请求，然后将请求派发给 Processor 线程池中的一个线程来处理。 与 Redis 相同，IO 多路复用允许内核中同时管理多个 scoket 连接，内核会一直监听这些连接，一旦有请求到达，就会通知处理线程，达到一个线程处理多个请求的效果。\nN 个 Processor 线程：Kafka 会维护一个线程池，将请求分发给可用的 Processor 线程处理。主要负责从套接字读取消息，解析处理，并将响应发送给客户端。达到批量操作，提高吞吐量。\nM 个 Handler 线程：维护的线程池，负责读取 Kafka Topic 中的消息，并将其提交到对应的 Consumer Group。\n🫧 磁盘顺序 IO\nKafka 采用日志文件的方式持久化日志，以 Append Only 的方式追加到文件末尾，顺序 IO 使写入速度非常快。\n🫧 Page Cache\n利用了操作系统本身的缓存技术，在读写磁盘文件时，其实操作的都是内存，由操作系统决定什么时候将 Page Cache 中的数据真正刷入磁盘。\nPage Cache 缓存中保存的是最近可能被使用的磁盘数据，具有时间局部性（最近访问的数据可能再次访问）和 空间局部性（访问的数据的周边数据被访问的概率极高）。 作为顺序写入的消息队列，如果生产和消费地特别快，利用 Broker Page Cache，甚至可以不经过磁盘完成操作。\n🫧 分区分段结构\nKafka 的 Topic 会被分区为多个 Partition，在多台 Broker 中，使用多个服务来接受消息。\n同时每个分区 Partition 会被分为多个段 Segment 来管理，每个段内都是顺序写，避免分区过大，利于管理。\n📮 消费消息 🫧 稀疏索引\nKafka 查询场景非常简单，按照 offset 查询消息即可。为了加快读操作，只需要在内存中维护一个 offset 到日志文件的偏移量的映射关系 Map 即可。 每次查找消息，先从哈希表中查到文件偏移量，再去读日志文件。\n🫧 mmap\nmemory mapped files\n采用 mmap 映射索引文件，加快索引的查找过程。将磁盘文件与内存虚拟地址做了映射，不需要操作磁盘IO，进程可以使用指针的方式操作这一块内存，系统会自动将脏页写入到对应的磁盘文件上。\n🫧 零拷贝\n采用了零拷贝，将数据从内存中的缓存区直接拷贝到网卡设备，无需经过应用程序，减少了数据的拷贝和内核态与用户态的切换。\n🫧 批量拉取\n与发送消息对应，消费消息也是批量拉取的，每次拉取一个消息集合，减少网络的开销。\n参考 https://mp.weixin.qq.com/s?__biz=MzU2MTM4NDAwMw==\u0026mid=2247490102\u0026idx=1\u0026sn=68d55b3c5ac74038c76d6837b862a11c\u0026chksm=fc78c51acb0f4c0cd5a1d6ceedb9948f82d48791ab789e9edfd6e83e34fbad1ace5749bee203\u0026scene=21#wechat_redirect https://mp.weixin.qq.com/s?__biz=MzU2MTM4NDAwMw==\u0026mid=2247490102\u0026idx=1\u0026sn=68d55b3c5ac74038c76d6837b862a11c\u0026chksm=fc78c51acb0f4c0cd5a1d6ceedb9948f82d48791ab789e9edfd6e83e34fbad1ace5749bee203\u0026cur_album_id=1763234202604388353\u0026scene=189#wechat_redirect https://mp.weixin.qq.com/s?__biz=MzU2MTM4NDAwMw==\u0026mid=2247491055\u0026idx=1\u0026sn=14bc485f91ec2629cc9e8bf7a36ad8f4\u0026chksm=fc78c2c3cb0f4bd566d5ca2534805839420ad3dc67210bc8f2b7ef05283785b02b8ddef640a8\u0026cur_album_id=1763234202604388353\u0026scene=189#wechat_redirect https://mp.weixin.qq.com/s?__biz=MzU2MTM4NDAwMw==\u0026mid=2247491168\u0026idx=1\u0026sn=bd37f96692b3f7cecdaf3172abdb7a8c\u0026chksm=fc78c14ccb0f485a451f70c7ffbf5b05d0f500dfef6321703e7cdebdc0de902d9d77a547d469\u0026cur_album_id=1763234202604388353\u0026scene=189#wechat_redirect https://mp.weixin.qq.com/s?__biz=MzU2MTM4NDAwMw==\u0026mid=2247491507\u0026idx=1\u0026sn=f1bec356c94cd0101809dc11dcf27ba2\u0026chksm=fc78c09fcb0f49898f6cc9b80499aeb871a80f95ab4fbe12c32567cab6a3521a6c33b61dd807\u0026cur_album_id=1763234202604388353\u0026scene=189#wechat_redirect https://mp.weixin.qq.com/s?__biz=MzU2MTM4NDAwMw==\u0026mid=2247491763\u0026idx=1\u0026sn=cc60a6ba13e5cf4384e623819c621e0d\u0026chksm=fc7b3f9fcb0cb6897be67103d91854831b71909c0d12385fb52b2f1d011fca5d1844b3892019\u0026cur_album_id=1763234202604388353\u0026scene=190#rd ","date":"2023-03-04T11:14:45+08:00","image":"https://emerywan.github.io/blog/p/kafka/kafka_hu0e688a86da638634e8e15b21ceb1a2b6_8026_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://emerywan.github.io/blog/p/kafka/","title":"Kafka"},{"content":"事务 数据库事务 事务（单数据库的本地事务）是指一组操作，要么全部正确执行，要么全部不执行。\n事务通常会有 ACID 四大特性：\nA 原子性 C 一致性 I 隔离性 D 持久性 分布式事务 现在的大型业务系统通常都由若干个子系统构成，这些子系统各自拥有独立的数据库，一个业务流程需要由多个子系统共同完成，这些操作需要要么全部成功，要么全部失败。\n分布式事务就是要保障不同数据库数据的一致性。\n例如：在大型的电商系统中，下单时会：扣减库存，减优惠，生成订单id等多个步骤，通常订单服务与库存、优惠、订单id都是不同的服务。 这些操作是否成功，依赖于多个系统的结果，可能涉及三个系统服务，三个数据库。所以需要在数据库与应用程序之间，通过“中间”方案，实现分布式事务的支持。\n一致性 🚑 强一致性 在任意时刻，所有节点的数据都是一样的，每一次读操作，都能获取到数据最近的一次写操作。\n🚚 弱一致性 数据更新后，能够容忍后续的访问只能访问部分数据或全部访问不到。\n🚛 最终一致性 不保证任意时刻任意节点上的同一份数据都是相同的，但是在一段时候之后，节点的数据最终会达到一致的状态。\n⚙️ CAP CAP 定理指一个分布式系统中，一致性 Consistency，可用性 Availability，分区容错性 Partition tolerance，「最多只能满足两项」。\nC - Consistency 一致性\n所有节点在同一时间的数据完全一致。（任意时间在任意节点访问到的都是最新的数据）\nA - Availability 可用性\n服务在一定时间内，都会返回一个明确的结果，服务一直可用。\nP - Partition Tolerance 分区容错性\n一个服务分布在不同的系统中，如果部分系统宕机，其他系统能够继续提供服务。\n🅿️ 分区容错性时分布式系统的根本，如果分区容错性不能满足，那使用分布式式系统将失去意义。\nCP 一致性 \u0026amp; 分区容忍性\n优先保障数据的一致性。\n如涉及金钱交易的环节，保障数据不能出错。\nAP 可用性 \u0026amp; 分区容忍性\n优先保障系统的可用。\n互联网中大多数场景都是保障系统可用，如在有大量请求时，一些服务可以先不提供，如在双十一活动时，限制用户查询历史账单。\n🫧 BASE BASE 理论是指：\nBA - Basically Available 基本可用\n分布式系统出现故障的时候，允许损失部分可用性，保证核心可用。\nS - Soft State 软状态\n允许系统存在中间状态，这个中间状态不会影响系统整体的可用性。\nE - Eventual Consistency 最终一致性\n系统中所有的数据副本经过一定时间后，最终能够达到一致性的状态。\nBASE 理论本质上是对 CAP 理论的延伸，是对 AP 的补充。\n对于业务系统来说，通常选择牺牲一致性来换取系统的可用性和分区容错性。但是不是完全放弃数据一致性，而是牺牲强一致性来换取弱一致性，采用合适的方式来保证最终一致性。\n分布式事务常见场景 银行转账 在银行转账中，扣余额和添加余额需要同时成功。扣减账户余额成功，增加账户余额失败；扣减账户余额失败，增加账户余额成功，都是不允许发生的。\n下订单和扣库存 下订单和扣库存需要保持一致，如果先下订单，扣库存失败，那么将会导致超卖；如果下订单没有成功，扣库存成功，那么会导致少卖。\n同步超时 服务化的系统间调用常常因为网络问题导致系统间调用超时，系统A同步调用系统B超时，系统A可以明确得到超时反馈，但是无法确定系统B是否已经完成了预定的功能或者没有完成预定的功能。于是，系统A就迷茫了，不知道应该继续做什么，如何反馈给使用方。\n一致性协议 事务管理器 TM - Transaction Manager：负责协调和管理事务，控制着全局事务并管理事务的生命周期，并协调各个 RM。\n资源管理器 RM - Resource Manager：事务的参与者，可以指一个数据库实例，通过资源管理器对数据库进行控制，即一个分支事务。\nDTP 模型定义 TM 和 RM 之间的通讯接口规范叫做 XA（即数据库提供的 2PC 接口协议），基于数据库的 XA 协议来实现的 2PC 称为 XA 方案。\n🤲 2PC 两阶段提交（2PC）把分布式事务分为两个过程：准备阶段 Prepare，提交阶段 Commit / 回滚阶段 Rollback。\n第一阶段 prepare\n执行实际的业务操作，但不提交事务，锁定资源。\n事务管理器（TM，Transaction Manager）向所有本地资源管理器（RM，Resource Manager）发起请求，询问是否是就绪 ready 状态，所有的参与者都将本地事务能否成功的信息反馈给协调者。\n第二阶段 commit / rollback\n事务管理器根据所有本地资源管理器的反馈，通知所有本地资源管理器，步调一致地在所有分支上提交或回滚。\n只要有一个 RM 失败，就会进行回滚操作；否则通知所有 RM 提交事务。提交事务后释放锁资源。\n⚒️ Seata 实现 2PC Seata 是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。\n📇 Seata 把一个分布式事务理解成一个「全局事务」和若干「分支事务」：\n全局事务：协调各个分支事务达成一致\n分支事务：可以理解为一个关系数据库的本地事务\n🗃️ Seata 定义了三个组件处理分布式事务：\nTC（Transaction Corinator）事务协调器\n独立的中间件。\n维护全局事务的运行状态：接收 TM 指令发起全局事务的提交与回滚；负责与 RM 通信协调各个分支事务的通知与回滚。\nTM（Transaction Manager）事务管理器\njar包。\n嵌入应用程序中工作，负责开启一个全局事务，最终向 TC 发起全局提交或全局回滚。\nRM（Resource Manager）资源管理器\n控制分支事务。\n接收 TC 的指令，驱动本地事务的提交或回滚。\n📺 在架构方面，2PC 方案的 RM 实际上是在数据库层面，RM 本质上是数据库自身通过 XA 协议实现；seata 中 RM 以 jar 包的形式作为中间件层部署在应用程序一侧。\n🗳️ 在两阶段提交方面，2PC 在第二阶段决议 commit / rollback，事务性资源锁要保持在第二阶段完成后释放；seata 在第一阶段就将事务提交，省去第二阶段持有锁的时间，提高整体效率。\n配置 Seata 服务 启动 seata 中间件服务 配置服务注册中心 在应用配置 regsitry.conf、file.conf（在 seata 中拷贝） 使用 seata 服务，需要在双方数据库中创建 undo log 表 1 2 3 4 5 6 7 8 9 10 11 12 13 CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `context` varchar(128) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, `ext` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 创建代理数据源 每个 RM 通过 DataSourceProxy 使用代理连接。与 TC 进行通信交互、记录 undo_log 等。\n第一阶段业务操作生成对于的 undo_log，将 undo_log 和业务数据放在一个本地事务提交（undo_log 记录了修改前的值，同时提交后释放锁资源）。\nTM 开启全局事务，会将全局事务ID XID 放在事务上下文中，并通过远程调用传入下游的各个分支事务。\n第二阶段（1）事务提交，TC 通知各个分支完成事务，只需要删除对应的undo_log（第一阶段已经分支提交）；（2）事务回滚，通过 XID 和 Branch ID 找到对应的 undo_log 生成反向 SQL 执行即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Configuration public class DatabaseConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;spring.datasource.ds0\u0026#34;) public DruidDataSource ds0() { DruidDataSource druidDataSource = new DruidDataSource(); return druidDataSource(); } @Bean @Primary public DataSource dataSource(DruidDataSource ds0) { DataSourceProxy pds0 = new DataSourceProxy(ds0); return pds0; } } 双方业务实现 @GlobalTransactional 开启全局事务。GlobalTransactinalInterceptor 会拦截 @GlobalTransactional 注解的方法，生成全局事务IDXID。\nXID 会在整个分布式事务中传递，在远程调用时 spring-cloud-alibaba-seata 会拦截 Feign 调用将 XID 传递到下游服务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // // 转账方 // @Service @Sl4j public class AccountServiceImpl implements AccountInfoService { @Autowired private AccountInfoDao accountInfoDao; @Autowired private BankClient bankClinet; /** * 转账业务 */ @Override @Transactional @GlobalTranactional // 开启全局事务 public void updateAccountBalance(String accountNo, BigDecimal amount) { // 本账户扣款 accountInfoDao.updateAccountBalance(accountNo, -1 * amount); // 目标账户增加余额 String remoteRes = bankClinet.transfer(amount); if (\u0026#34;fallback\u0026#34;.remoteRes) { // 远程失败 throw new RuntimeException(\u0026#34;...\u0026#34;); // 抛出自定义异常回滚事务 } // ... } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // // 收款方 // 另一个服务 // @RestController public class BackController { @Autowired private AccountInfoService accountInfoService; // 接收转账 @GetMapping(\u0026#34;/transfer\u0026#34;) public String transfer(BigDecimal amount){ accountInfoService.updateAccountBalance(\u0026#34;2\u0026#34;, amount); return \u0026#34;get:\u0026#34; + amount; } } // --- @Service @Slf4j public class AccountInfoServiceImpl implements AccountInfoService { @Autowired private AccountInfoDao accountInfoDao; // 作为事务分支 // 不需要开启全局事务 @Override @Transactional public void updateAccountBalance(String accountNo, BigDecimal amount) { // RootContext.getXID() log.info(\u0026#34;XID：{}\u0026#34;, RootContext.getXID()); // 增加金额 accountInfoDao.updateAccountBalance(accountNo, amount); // ... } } 🛍️ TCC TCC Try - Confirm - Cancel\nTCC 由支付宝团队提出，被广泛应用于金融系统中。我们用银行账户余额购买基金时，会注意到银行账户中用于购买基金的那部分余额首先会被冻结，由此我们可以猜想，这个过程大概就是 TCC 的第一阶段。\nT - Try 阶段\n尝试执行。完成所有的业务检查，「预留必须的业务资源」。\n是对业务系统进行检查和资源预览，如订单和存储操作，需要检查库存剩余数量是否可用，并进行资源预留。\nC - Confirm 阶段\n确认执行真正的业务。该阶段不会做任何业务检查，只使用 Try 阶段预留的业务资源。\n在 TCC 中，通常认为 Try 阶段成功后，Confirm 一定会成功，如果 Confirm 阶段出错，需要进行重试。\nC - Cancel 阶段\n取消执行。释放 Try 阶段预留的业务资源。\n在 TCC 中，认为 Cancel 一定会成功，如果失败，需要重试。\n基于 TCC 实现分布式事务，需要将业务上的每一个实现逻辑拆分为 Try、Confirm、Cancel 三个部分，相对来说代码实现复杂度较高，对业务的侵入较大和业务紧耦合。\n分布式解决方案 可靠消息最终一致性 可靠消息最终一致性是指在分布式系统中，通过异步消息传递实现数据的一致性。\n每个节点都可以独立地进行操作，「发起方」执行完本地事务后，将操作的结果作为「消息」发送出去； 这些消息可能会有延迟、重复、丢失等； 但最终「事务参与方」一定能接受到消息，并成功处理事务，使得数据状态「最终」达到一致。\n🐬 本地消息表方案 利用了「各系统的本地事务」来实现分布式事务。\n在业务相关的同一个数据库中，创建一张「本地消息表」，⚙️ 执行业务相关操作 \u0026amp; 📋 记录消息到消息表放在同一个事务中。\n后台任务定时扫描本地消息表，将未确认的消息，发送给目标节点/消息队列。（失败重试）\n目标节点接收到消息后，可以将消息写入「本地消息表」（可用来判重、是否成功处理消息）， ⚙️ 执行相关业务操作 \u0026amp; 📋 记录表信息 \u0026amp; 👌 返回 ACK 操作放在同一个事务中。\n如果目标节点中的本地事务失败，会一直不断重试。如果时业务失败，会向源系统发起回滚。\n最大努力通知 可靠消息最终一致性关注的是业务过程中的事务一致，以异步的方法完成业务。（消息可靠性由发起方保障）\n最大努力通知关注的是业务完成后的通知事务，将执行的结果可靠的通知出去。\n发起通知方通过一定的机制，尽最大的努力将消息处理的结果通知到接收方，如果通知失败，发送方会不断地进行超时重试，如果一直不能通知到，接收方会主动查询发送方的接口（消息的可靠性由事务的被动方保障）。\n最常见的场景就是支付回调，支付服务到第三方支付成功后，第三方支付会有回调通知，如果回调失败，会通过一定的频率重试，并且第三方支付会提供主动查询支付状态的接口。既有回调通知，也有交易查询接口。\n参考 https://www.jianshu.com/p/1156151e20c8 https://xiaomi-info.github.io/2020/01/02/distributed-transaction/ https://blog.csdn.net/u010425776/article/details/79516298 https://mp.weixin.qq.com/s/XknegP66mnYboiBx556Kzw https://mp.weixin.qq.com/s/ujRRtdLOeKEHsHrtDRNXGA ","date":"2023-03-03T12:14:45+08:00","image":"https://emerywan.github.io/blog/p/distributed/transaction/cap_hu553ea908437f51f5f9df5986bc7065cb_18394_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://emerywan.github.io/blog/p/distributed/transaction/","title":"分布式事务"},{"content":"📑 主从复制 主从复制指主服务器（master server）上，任何修改和数据结构变更的事件，都会被写入到日志文件 bin log 中，从服务器（slave server）读取主服务器上的日志文件中的事件变更，并在本地重放执行。\n通过主从复制，能够提高数据库的读性能。主库复制写，从库复制读。\n并不适合来扩展写操作。例如在一主多从的架构中，写操作要被执行多次，整个系统的性能会取决于写入最慢的那个。\n💡 常见用途：\n数据备份 数据分发 提高读性能 高可用和故障切换 📖 复制原理 👣 主库中的数据变更会记录到 binlog 中，主库会创建一个 binlog dump thread，将 binlog 传输到从库\n👣 从库创建 IO 线程，将主库传来的 binlog 写入到自己的 relay log 中继日志\n👣 从库创建 SQL 线程，从 relay log 中读取数据，重放到数据库中\n这里的 IO 线程 和 SQL 线程的工作是解耦的，可以独立运行。\n🎫 复制格式 MySQL 有三种方式记录 binlog，同样在复制时，也对应有三种复制格式。\n💡 如果需要安全的数据复制方法，推荐使用基于行的格式复制，除非某些场景下明确需要临时使用基于语句的格式。\n📃 基于语句 statement 通过重新执行主服务器中执行过的 SQL 语句来完成复制的。\n优点🙋‍ 是简单紧凑，例如批量更新了 1000 条数据，也只需要一条语句，节约 IO。\n缺点🙅‍♂️ 是在一些情况下，可能导致主从数据不一致（例如使用了 now() 这样的函数）。\n📓 基于行 row 基于行的日志中，记录了该行数据发生了什么变化，包含该行修改前和修改后的情况。在执行时，进行解析，找到需要变更的记录进行操作。\n优点🙋 是数据具有强确定性。\n缺点🙅‍♂️ 是可能会导致日志中记录大量数据。比如在批量更新时，出现大量的行的修改，但是语句可能只有一条。\n🖇️ 混合模式 mix “试图” 混合模式结合以上两种格式的优点。（可能会有😵不稳定的情况）\n默认情况下使用基于语句的格式，在有需要时切换到基于行的格式。在写入事件时，会有很多的判断条件。\n🎚️ 复制模式 🌑 异步模式（默认） 主库不会主动推送 binlog 给从库，事务执行完直接返回，不关心从库是否接收到数据，从库通过异步的方式进行主从复制。\n🌓 半同步模式 主库执行的事务，等到至少一个从库将日志记录到了 relay log 中之后，再提交（不能保证从库执行完成，只能保证一个从库收到了日志）。\n注意：如果从库在超时时间之内没有返回，会退化成异步模式。\n🌕 全同步模式 主库执行的事务，等到所有的从库都执行完成之后，主库才会提交，返回成功信息给客户端。\n在实际项目中，基本不会使用。会严重影响性能，只要有一个从库发生故障，就会影响业务正常进行。\n参考 https://ost.51cto.com/posts/11721 https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==\u0026mid=2651961330\u0026idx=1\u0026sn=4bdbada3b26d4fc2fc505f7a0f2ad7c4 ","date":"2023-03-02T12:02:02+08:00","image":"https://emerywan.github.io/blog/p/mysql/master-slave-replication/copy_hu2815b7bcceb4bc2e593bd903d3b2a777_501311_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/mysql/master-slave-replication/","title":"MySQL 复制"},{"content":"建立复制 参与复制的 Redis 实例被划分为：\n主节点 master 从节点 slave 一个主节点可以有多个从节点，数据的复制是单向的 master -\u0026gt; slave。\n通过主从复制，可以实现「读写分离」，主服务器负责「写」操作，从服务器负责「读」操作。\n同时，从节点也可以作为主节点的备份。\n在从服务器中，使用 slaveof / replicaof 命令/配置，建立主从服务关系，执行命名后，从节点只会保存主节点的信息，其余的复制流程在节点内部异步进行。\n1 2 3 4 5 6 7 8 # 配置文件中设置 slaveof {masterHost} {masterPort} # 启动从服务时 redis-server --slaveof {masterHost} {masterPort} # 从服务中使用命令 slaveof {masterHost} {masterPort} 同步原理 Redis 内部使用 psync 完成主从数据的同步。\n1 2 3 # runID 保存的主服务器的 id # offset 偏移量，第一次同步为 -1 psync {runID} {offset} 👣 主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器。\n👣 从服务器收到 RDB 文件后，会先「清空当前的数据」，然后载入 RDB 文件。\n👣 在复制期间，主服务器依然可以正常处理命令（通过fork子进程，使用 copy-on-wirite COW），为了保障数据的一致性，写命令会被同时记录在 「复制客户端缓冲区」replication buffer 中，从服务器加载完 RDB 后，会继续运行缓存区中记录的命令。\n部分复制 📃 复制偏移量 offset\n参与主从的节点都会维护自身的复制偏移量，处理完「写命令」后，都会累计命令的字节长度。\n从节点会每秒钟会向主节点上报自身的复制偏移量。\n♒ 复制积压缓冲区\nreplication backlog buffer\n本质上一个先进先出的定长队列（默认两个，2 * 1M），与 MySQL redolog 一样是循环写入，新数据会覆盖旧数据。\n主节点响应写命令后，发送命令到从节点时，同时会将数据写入复制积压缓冲区，用于部分复制命令丢失是的数据补救。\n主从服务器在完成第一次全量复制之后，会通过长连接进行命令传播。\n由于网络是不稳定的，从服务器可能会有短暂的断开，当重新建立连接之后，可以根据情况使用增量复制来同步数据，避免了全量复制带来的性能开销。\n增量复制同样采用了 psync 来同步，从服务器通过 offset 来告知主服务器当前的数据偏移情况。\n当从服务器的偏移量能够在复制积压缓冲区中找到，会进行部分复制；当偏移数据过大，已被覆盖无法找到时，会退化为全量复制。\n💓 保持连接 主从节点间有心跳检测机制：\n主节点每 10s 向从节点发送 ping 命令，判断从节点的连接状态\n从节点每 1s 上报自身 offset 情况\n实时监控从节点网络状态，延迟性 判断数据是否丢失 保障从节点的连接数量 📚 读写分离问题 🎰 数据延迟 Redis 由于异步复制的特性，延迟是无法避免的，取决于当前的网络情况和命令阻塞情况。\n适合于业务场景对延迟不敏感的场景。根据具体业务场景而定，可以考虑使用 Redis 集群做水平扩展的方案。\n🗑️ 过期数据 在 Redis 中，有（1）定期删除；（2）惰性删除；两种删除方案。\n在从服务器中，不会主动检查是否过期，主服务器中找到过期数据，会同步一条 DEL 命令到从服务器中，删除过期数据。\n在 Redis 3.2-，从服务器会直接返回过期数据，不会进行检查\n在 Redis 3.2+，在返回数据前，会检查过期时间，解决了从服务器读取到过期数据的问题\n🌀 节点故障 当主节点宕机后，从节点是无法自动升级为主节点的，需要人工干预。\n考虑使用 Redis 哨兵模式或集群方案。\n👍 相关优化 避免全量复制\n主从复制的全量复制是一个非常消耗资源的操作，除了第一次复制的全量复制，之后需要尽量避免全量复制。\n复制积压缓存区不足，会导致复制退化为全量复制，在运维时，可以根据实际情况增加缓冲区的容量。\n避免复制风暴\n当一个主节点上挂载了多个从节点，如果同时与多个从节点进行全量同步时，会向多个从节点发送RDB文件（Redis 做了优化可共享一个 RDB），导致网络带宽的严重消耗，造成延迟问题。\n建议使用链状/树状结构，从节点挂载到从节点上。\n单机复制风暴\n由于 Redis 的瓶颈不在 CPU 上，通常会在一台服务器上部署多个实例。 为了避免物理机问题导致的故障，导致恢复后大量从节点向一台机器进行复制操作，部署时应该把不同服务的主节点分散到多台机器上。\n🎺 哨兵机制 Redis 在主从模式下，一旦主节点故障😓，需要人工干预将从节点提升为主节点，同时需要在客户端配置新的主节点地址。\n为了达到高可用，提供了哨兵模式 Redis Sentinel 解决这个问题，自动完成故障发现和故障转移。\n在哨兵模式下，相比于复制模式，只是多了 Sentinel 节点，主从模式下的 Redis 节点没有任何特殊处理。 其中，Sentinel 节点本质上是特殊的 Redis 节点，只是不会存储数据，只支持部分命令。\n🔍 监控\n每个哨兵节点会定期检查 Redis 数据节点、其余哨兵节点是否可达。\n📧 通知\n哨兵节点会将故障转移的结果通知给应用方。\n📇 主节点故障转移\n可以实现故障时，将从节点晋升为主节点，并维护正确的主从关系。\n📑 配置提供者\n在哨兵结构中，客户端初始化连接的是哨兵集群，从中获取主节点的信息。\n主观下线和客观下线 🧐 主观下线 ”一家之言“\nSentinel 每 1s 会向其他所有节点发送 ping 进行💓心跳检测，当节点超过时间没有回复，就会对该节点做失败判定。只有这一个节点的判定称为「主观下线」。\n🗳️ 客观下线 当主观下线的为主节点时，当前 Sentinel 节点会询问其他哨兵对该主节点的判断，当多数哨兵都对主节点的下线做了同意判定，超过配置中的 quorum 个数，该节点就被标记为「客观下线」。\n三个定时任务 Redis Sentinel 通过三个定时任务对各个节点发现和监控：\n每隔 10s，每个哨兵节点会向主节点和从节点发送 info 命令获取最新的拓扑结构\n每隔 2s，每个哨兵节点会向 Redis 数据节点的 __sentinel__:hello 频道上发送该 Sentinel 节点对于主节点的判断，以及当前 Sentinel 节点的信息\n每隔 1s，每个哨兵会向其他哨兵节点、主节点、从节点发送 ping 命令判断是否可达\nSentinel 领导选举 当确定客观下线之后，需要进行故障转移工作。实际上故障转移工作只需要一个 Sentinel 节点来完成即可，所以需要先做一个领导者选举的工作。\nRedis 使用 Raft 算法实现领导的选举。\n每个在线的 Redis Sentinel 都有资格成为领导者，在一个哨兵确定主节点客观下线时，会向其他的节点发送 sentinel is-master-down-by-addr 命令， 要求将自己设置为领导者。\n收到命令的节点，如果没有同意过其他节点的请求，就会同意该请求，否则拒绝。每个哨兵节点只有一票。\n当一个哨兵拿到 quorum 个票数时，就成为了领导者，否则进行下一次投票。\n🎡 故障转移 👣 选取新的主节点\n🧩 过滤“不健康”节点（主观下线、掉线）\n🧩 选择「优先级最高」的节点，否则继续下一条规则\n🧩 选取「offset 最大」的节点，否则下一条规则\n🧩 选取「runId 最小」的节点（runId 是 Redis 随机生成的一个id，在集群中这个 id 会保持不变）\n👣 从节点提升为主节点\n从节点内部执行 slaveof no one 成为主节点。\n👣 哨兵领导者向其他从节点发送命令，更换主节点的信息\n👣 将下线的主节点更新为从节点，并保持监控，当再次上线时，将作为从节点复制新的主节点信息\n注意事项 Sentinel 节点应该部署在多台物理机上 Redis 的瓶颈不在 CPU，通过一台物理机会部署多个 Redis 实例，如果哨兵全部都在一台物理机上，如果出现物理故障，所有的实例都会收到影响\n至少三个 Sentinel 节点，且为奇数节点 哨兵领导者选举时，至少需要获取「一半 + 1」个投票。奇数节点可以在满足条件的基础上节省一个节点。\n参考 https://segmentfault.com/a/1190000039766545 Redis 开发于运维 ","date":"2023-03-01T18:52:45+08:00","image":"https://emerywan.github.io/blog/p/redis/replication/replication_hu79bab96584f6667bba9965688b174414_176167_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/redis/replication/","title":"Redis 复制"},{"content":"📖 介绍 适配器模式（Adapter / Wrapper）是一种 结构型模式。\n通过适配器模式，可以将一个类A的接口，转化成一个类B，以满足一些方法的调用。\n如类A是一个第三方、遗留类等，已经被其他地方使用，无法更改，通过适配器模式的思想，通过一个中间的类，封装复杂的转化过程，转换为需要的类型。\n🔖 生活中的插座，各个国家标准不同，可以通过一个转接器，适配不同的插口\n🔖 ARM CPU 适配 X86 应用的转译\n🔖 Linux -\u0026gt; Wine / 虚拟机 -\u0026gt; 运行 Windows 应用\n🎈 实现方式 🎗️ 实现一个中间类，实现/继承 需要的类型\n🎗️ 将需要被转换的类A，作为中间类的成员对象\n🎗️ 在类A中实现相关方法，进行适配\n🎗️ 最后，所有的相关工作，都会被委托给中间类\n☕ Java 中的适配器模式 当我们现在的数据是数组类型时 String[]，现在调用的方法需要传入 List\u0026lt;String\u0026gt; 对象，可以通过工具类进行转换。\n1 2 3 4 // String[] ---Arrays.asList()---\u0026gt; List\u0026lt;String\u0026gt; // Arrays.asList() 相当于一个 Adapter String[] data = new String[] {\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;}; List\u0026lt;String\u0026gt; dataList = Arrays.asList(data); // 这里的 List 是一个内部类 🛠️ 实现 1 2 3 4 5 6 7 class Task implement Callable\u0026lt;String\u0026gt; { @Override public String call() throws Exception { System.out.println(\u0026#34;这是一个现有的任务\u0026#34;); return \u0026#34;这是一个现有的任务\u0026#34;; } } 1 2 3 4 5 // 现在某处，需要使用 Thread 运行线程方法 // ⚠ new Thread(new Runnable()) 不能接收 Callable 对象 // 需要使用适配器模式，将 Callable -----\u0026gt; Runnable Callable\u0026lt;String\u0026gt; task = new Task(); new Thread(new RunnableAdapter(task)).start(); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 1) 实现目标接口 Runnable // 2) 在目标接口中，持有 Callable 对象，对其进行适配 // 3) 在目标接口的方法内部，调用待转换的方法 public class RunnableAdapter implements Runnable { private Callable\u0026lt;?\u0026gt; callable; public RunnableAdapter(Callable\u0026lt;?\u0026gt; callable) { this.callable = callable; } @Override public void run() { try { callable.call(); } catch (Exception e) { throw new RuntimeException; } } } ","date":"2023-02-20T20:02:02+08:00","image":"https://emerywan.github.io/blog/p/design-pattern/adapter/adapter_hu8f557059998a06e7b13ad71eff607ec2_38612_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/design-pattern/adapter/","title":"适配器模式"},{"content":"📖 介绍 责任链模式是一种行为型模式。是一种处理请求的模式，请求在链上传递，每个处理器都有机会处理请求。处理器可以决定请求是否向下传递（如无法处理，需要交给下一个处理），或者直接返回（如处理完成，返回结果）。\n通过责任链模式，可以让请求的发送者和处理请求的处理器进行结构，每个处理器只处理特定的情况，可以方便地添加/删除处理器。\n常见的场景：\n🔖 疫情期间请假出校，学校领导的层层审批 😂\n🔖 击鼓传花游戏\n🔖 缓存架构，在缓存中没有找到数据，往数据库总查找\n🔖 GUI 程序对点击按钮的处理\n🎈 实现方式 关键：每个处理器都实现统一的接口，内部包含下一个 ⏭️ 处理器 next 和本处理器的 🔨处理方式 execute。\n🎗️ 声明一个处理器的通用接口。\n🎗️ 具体的处理者。决定是否处理请求 / 请求是否传递给下一个。\n🎗️ 责任链。\n实现方式一：🔗 包含一个 List，可以用来构建处理请求的数据。process 方法对 List 进行循环，处理器可以执行就处理相应的方法，不能执行返回 null 之类。 实现方式二：在处理器中包含 next，为下一个处理器，不能执行调用 next 的方法。 处理者可以决定是否沿着链传递请求，可以\n（1）处理不了传递给下一个处理器，成功后直接返回，一个请求只能一个处理器执行； （2）所有处理器都依次执行一次请求，完成相应的内容。 🛠️ 实现 1 2 3 4 5 6 7 // 通用方法定义 interface Handler { // true -\u0026gt; 处理成功 // false -\u0026gt; 拒绝 // null -\u0026gt; 交给下一个处理 boolean process(Request request); } 1 2 3 4 5 6 7 8 9 10 11 12 // 具体处理器 public ManagerHandler implements Handler { public boolean process(Request request) { // if () ... } } public DirectorHandler implements Handler { } public CEOHandler implements Handler { } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class HandlerChain { private List\u0026lt;Handler\u0026gt; handlers = new ArrayList\u0026lt;\u0026gt;(); public void addHandler(Handler handler) { this.handlers.add(handler); } public boolean process(Requst request) { for (Handler handler : handers) { boolean b = handler.process(request); if (b != null) { // 根据 true / false 是否要结束调用链 if (...) { // ... return b; } } } throw new RuntimeException(\u0026#34;Could not handle request: \u0026#34; + request); } } ","date":"2023-02-19T20:02:02+08:00","image":"https://emerywan.github.io/blog/p/design-pattern/chain-of-responsibility/chain-of-responsibility_hua8660a3d747ded192e9077eec2242be5_61087_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/design-pattern/chain-of-responsibility/","title":"责任链模式"},{"content":"📖 介绍 策略模式是一种行为型模式。\n策略模式指定义一系列算法，每种算法都封装到不同的类中，在运行时，可以灵活地替换这些的算法（替换执行的策略）。\n📖 常见的场景：\n🔖 旅行的出游方式，选择骑自行车、坐汽车，每一种旅行方式都是一个策略。\n🔖 电商系统中，下单时，可以选择多种则扣策略（满减，优惠券，积分）；支付时，可以选择多种支付方式（支付宝，微信，云闪付）。\n🔖 用策略模式消除大量的 if-else。\n🎈 实现方式 🎗️ 策略接口：使用接口定义具体策略的通用接口，声明了一个上下文用于执行策略的方法。\n🎗️ 具体策略：实现策略接口，实现具体的相关算法。\n🎗️ 客户端调用时，会将使用具体的策略对象传递给上下文，根据策略，执行不同的算法。\n💡 重点：实现同一个接口，通过传入的策略，执行不同的算法。\n🛠️ 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 策略接口 public interface DiscountStrategy { // 获取优惠金额 BigDecimal getDiscount(BigDecimal total); } // 打折优惠 public class UserDiscountStrategy implements DiscountStrategy { public BigDecimal getDiscount(BigDecimal total) { return total.multiply(new BigDecimal(\u0026#34;0.1\u0026#34;)).setScale(2, RoundingMode.DOWN); } } // 满减优惠 public class OverDiscountStrategy implements DiscountStrategy { public BigDecimal getDiscount(BigDecimal total) { return total.compareTo(BigDecimal.valueOf(100)) \u0026gt;= 0 ? BigDecimal.valueOf(20) : BigDecimal.ZERO; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 用于执行策略的上下文 public class DiscountContext { // 持有某种策略 private DiscountStrategy strategy = new UserDiscountStrategy(); public DiscountContext(DiscountStrategy strategy) { this.strategy = strategy; } // 用于更改策略方式 public void setStrategy(DiscountStrategy strategy) { this.strategy = strategy; } // 计算付款金额 public BigDecimal calculatePrice(BigDecimal total) { return total.subtract(this.strategy.getDiscount(total)).setScale(2); } } 1 2 3 4 5 6 7 8 // 使用策略模式 DiscountContext context = new DiscountContext(); BigDecimal price = BigDecimal.valueOf(100); // 使用满减策略 context.setStrategy(new OverDiscountStrategy()); BigDecimal pay = context.calculatePrice(price); ☕ Java 中的策略模式 以排序为例，在 java.util.Arrays java.util.Collections 工具类中 的 sort(XX, Comparator) 方法：\n1 2 3 public static \u0026lt;T\u0026gt; void sort(T[] a, Comparator\u0026lt;? super T\u0026gt; c) { // ... } 普通的 sort() 默认从小到大进行排序，如果我们想要从大到小进行排序，就是要更改排序的 策略，我们可以实现这个 Comparator 的 int compare(T o1, T o2) 方法，并传入 sort() 中\n1 Arrays.sort(nums, (o1, o2) -\u0026gt; o2 - o1); 🔗 参考 https://refactoringguru.cn/design-patterns/strategy https://www.liaoxuefeng.com/wiki/1252599548343744/1281319606681634 https://www.runoob.com/design-pattern/strategy-pattern.html ","date":"2023-01-28T23:02:02+08:00","image":"https://emerywan.github.io/blog/p/design-pattern/strategy/1_hu4b682ac3dd21e3939910ee63d5154e28_59663_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/design-pattern/strategy/","title":"策略模式"},{"content":"MySQL 可以分为：\n（1）Server 层：负责建立连接，分析和执行SQL\n（2）存储引擎层：负责数据的存储和提取\n🛎️ Server 层 Server 层负责建立连接，分析和执行 SQL。主要包括：连接器、查询缓存、分析器、优化器和执行器等，包含 MySQL 大多数核心服务的公共功能。\n🏒 连接器 当我们使用 MySQL 服务连接到数据库时，首先就是通过连接器。\n连接器负责与客户端建立连接、获取权限、维持和管理连接。\n通常使用以下命令连接数据库：\n1 mysql -h$ip -P$port -u$user -p 🥍 查询缓存 🙅‍♂️ MySQL 8.0 已经移除了查询缓存。查询缓存的命中率非常低，除非都是静态表不会更新，只要有一个表更新了数据，这个表的查询缓存就会被清空，有时反而会影响数据库的效率。\n客户端向 MySQL 发送 SQL 语句后，如果是 select 语句，会先去查询缓存中查找这条语句是否被缓存（key-value）。如果命中，会直接返回 value 给客户端。\n🏏 分析器 词法分析\nMySQL 会根据输入的字符串识别出关键字，如 SQL 类型、表名、字段名、where 条件等，构建出 SQL 语法树。\n语法分析\n根据词法分析的结果，语法解析器会根据语法规则，判断该 SQL 语句是否满足 SQL 语法。\n🏑 优化器 优化器主要负责将 SQL 查询语句的执行方案确定下来。\n比如在表中有多个索引的时候，优化器会基于查询成本的考虑，选择使用哪个索引。\n比如判断走索引查询回表和全表扫描的代价，选择进行回表或全表扫描。\n我们可以通过 explain 查看一个条查询语句的执行计划。\n1 explain select * from table where id \u0026gt; 100; 🏓 执行器 通过优化器确定执行方案后，MySQL 开始真正执行语句了。\n在执行过程中，执行器会与存储引擎进行交互，交互以记录（行）为单位。\n对于要进行全表扫描的情况，执行器会调用 InnoDB 引擎接口的获取表的第一行，判断条件是否符合，符合就加入到结果集中。之后不断调用引擎接口重复这个过程，直到读取完表的最后一行。\n对于要使用索引的情况，逻辑同样类似，会通过索引获取满足条件的第一行，根据情况是否要回表、覆盖索引或索引下推，再不断向后循环获取，直到不满足条件。\n💽 存储引擎 存储引擎负责数据的存储和提取。\nMySQL 存储引擎的架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。可以根据需要选择合适的存储引擎。通常我们会选择使用 InnoDB 存储引擎。\n在 InnoDB 存储引擎中，如果查询的数据在 BufferPool 中，会直接返回；如果没有会将数据加载到内存中，在返回给客户端。\n","date":"2023-01-11T18:30:02+08:00","image":"https://emerywan.github.io/blog/p/mysql/how-execute/mysql_hu2e25f96503f96a8e12f0e1c93e28468a_180676_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://emerywan.github.io/blog/p/mysql/how-execute/","title":"MySQL 语句是怎么执行的"},{"content":"🌨️ 缓存雪崩 为了保证缓存中数据与数据库中的数据的一致性，通常 Redis 中数据会设置过期时间。如果（1）缓存层在同一时间有大量数据失效，或者 （2）Redis 由于某些情况宕机，导致所有请求全部访问数据库，造成数据库宕机。\n💡 解决办法：\n🧩 给数据随机设置过期时间\n🧩 互斥锁，只有一个请求会到数据库上，并会重建缓存\n🧩 双 Key 策略，有不同的 Key，但有相同的 Value\n主 Key：设置过期时间 备 Key：不设置过期时间 当主 Key 过期后，大量请求到达时直接返回备 Key，并通知后台线程，重建主 Key 🧩 设置 Key 永不过期，后台更新缓存（内存不够时可能被内存淘汰策略淘汰）\n后台线程定时更新 或 定时检测是否失效，进行重建 业务上发现被淘汰，通过消息队列通知重建 ⚡ 缓存击穿 缓存中某个热点 Key 数据过期了，此时有大量请求访问该数据，导这些请求全部都落到了数据库上，导致数据库宕机。\n💡 解决办法：\n🧩 互斥锁，只有一个请求会到数据库上，并重建缓存\n🧩 热点数据永不过期（内存不够时可能被内存淘汰策略淘汰），后台线程更新缓存\n🌪️ 缓存穿透 请求的数据既不存在于缓存中，也不存在于数据库中，有大量这样的请求，不会命中缓存，直接访问数据库，导致数据库压力非常大。\n可能是由于（1）业务误操作 或 （2）黑客的故意攻击\n💡 解决办法：\n🧩 缓存默认值，后续的请求直接返回该默认值\n🧩 布隆过滤器，当布隆过滤器返回 0 时，说明数据一定不在数据库中\n🧩 非法请求限制，在业务层判断查询条件，如果是恶意请求直接拒绝\n🔥 热点 Key 重建 当热点缓存失效的瞬间，后端会有大量请求，在重建缓存时，会造成后端负载过大，导致应用崩溃。\n💡 使用互斥锁\n只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，才能从缓存获取数据 💡 Key 永不过期\n利用后台线程去单独构建缓存 🎏 缓存一致性 更新 ❌ 先更新数据库，再更新缓存 ❌ 先更新缓存，再更新数据库 删除 ❓ 先删除缓存，再更新数据库 可以考虑延迟双删。在更新完数据库后，延迟一段时间再删除一次缓存。\n⭕ 先更新数据库，再删除缓存 在实际中，出现的概率非常低。缓存的写入要远远快于数据库的写入。\n异步 通过 更新 + 删除，是两个不同的操作，不具备原子性，可能会导致不一致的问题。\n中间件 通过中间件（如 Canal -\u0026gt; https://github.com/alibaba/canal ）订阅数据库的 binlog，当更新完数据库时，通过中间件去删除缓存。\n📕 参考 https://xiaolincoding.com/redis/ Redis 开发与运维 ","date":"2023-01-11T01:52:45+08:00","image":"https://emerywan.github.io/blog/p/redis/cache-problem/cache_huc44aa64b3fbd973aaa777c758ea67bcf_92231_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/redis/cache-problem/","title":"Redis 缓存问题"},{"content":"保障数据不丢失 Redis 的读写操作都是在内存中，为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。\nRDB 快照 AOF 日志 混合持久化（4.0+） 📷 RDB 快照 RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据。（全量备份）\n快照，就是记录某一个瞬间东西，比如当我们给风景拍照时，那一个瞬间的画面和信息就记录到了一张照片。\n触发条件 手动触发 save（阻塞主线程） bgsave 被动触发 根据配置文件选项每隔一段时间触发一次 bgsave 1 2 # 300 秒之内，对数据库至少执行了 10 次操作 save 300 10 从节点执行全量复制操作，主节点会自动执行 bgsave 文件发送给从节点\n默认情况下，执行 shutdown 命令，没有开启 AOF 持久化功能会自动执行 bgsave\n实现方式 执行 bgsave 命令的时候，会通过 fork() 创建子进程，复制父进程的页表，此时子进程和父进程共享同一片内存数据，bgsave 子进程会把该副本数据写入 RDB 文件。\n在这个过程中，Redis 依然可以继续处理操作命令，如果父进程执行写操作，关键的技术就在于写时复制技术（Copy-On-Write, COW），被修改的数据会复制一份副本。（RDB 快照保存的是原本的内存数据）\n📃 AOF 日志 Redis 在执行完一条命令后，会把该命令以追加的方式写入到文件中（会先写到缓冲区，选择合适的刷盘时间才会到磁盘中）。\n当 Redis 重启时，会读取 AOF 日志的内容，然后逐一执行进行数据恢复。\n后写日志 Reids 是先执行写操作命令后，才将该命令记录到 AOF 日志里。\n优点 避免额外的检查命令的开销 写日志的操作不会阻塞当前命令的执行 缺点 数据可能会丢失。在没有写到内存中时，发生宕机，有丢失数据的风险 可能阻塞后续的操作。执行命令和写 AOF 日志都是在主线程中执行，当把日志写入到磁盘时，会阻塞后续的操作 写回策略 Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区，什么时候写回到磁盘，由配置决定。\nRedis.conf 可配置参数 appendfsync。\nAlways\n每次都写回 可靠性高，最大程度会保证数据不丢失 每个命令都要写回硬盘，性能开销大 Everysec\n每秒写回 宕机时会丢失 1s 内的数据 No\n由操作系统决定写回时机 宕机时可能会丢失很多数据 AOF 重写 AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。\n为了避免 AOF 文件越写越大，提供了 AOF 重写机制，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。\nAOF 重写时，会读取数据库中所有的键值对，然后将每一个键值对用一条写命令记录到 新的 AOF 文件中，等到全部记录完之后，就将新的文件替换掉旧的文件。\n实现方式 通过 fork 后台子进程完成。使用 COW 技术，共享物理内存。\n在重写期间，依旧可以执行命令，写命令会同时保存在（1）AOF 缓存区 和 （2）AOF 重写缓存区。\n执行完成之后，将 AOF 重写缓存区的内容追加到文件中，并替换旧的文件。\n🗃️ 混合持久化 混合持久化工作在 AOF 日志重写过程。\n当开启了混合持久化时，在 AOF 重写日志时，\nfork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件， 主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件， 写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。 使用了混合持久化，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。\n","date":"2023-01-06T22:07:45+08:00","image":"https://emerywan.github.io/blog/p/redis/persistence/cow_huef7edcdd3c38f136e9d4b420711ff934_42621_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/redis/persistence/","title":"Redis 持久化"},{"content":"📖 介绍 代理模式是一种结构型模式。\n代理模式是为了方便访问某些资源，使对象类更加易用。为其他对象提供一种代理控制这个对象的访问。\n常见的场景：\n🔖 买火车票不一定要去火车站，也可以去代售点。\n🔖 Windows 中的快捷方式，Linux 中的软链接。\n🔖 Spring AOP。\n🔖 常见的 ORM 框架，只要定义相关的接口，而不需要写实现类，就可以对 XML 或注解中的 SQL 语句进行增删改查操作。\n🔖 一些中间件如 RPC 框架，在拿到 jar 包中对接口的描述后，中间件会字服务启动时，生成对应的代理类。当调用接口时，实际上是通过代理类发出的 Socket 信息。\n🎈 实现方式 🎗️ 方法（1）：抽取接口，代理对象和服务对象实现同一个接口。\n🎗️ 方法（2）：并不是所有情况都能抽取接口（如代码改动很大、不能修改服务类），可以将代理类作为服务类的子类，让代理类继承服务类的所有接口。\n🎗️ 创建代理类，代理类中必须包含一个服务类的成员变量，负责服务类的整个生命周期。（可通过构造函数传入，或在内部创建）\n🎗️ 根据需求实现代理方法。大部分情况下，代理方法会调用服务对象的同名方法。\n🚦 可考虑设计选项：\n构建一个方法，用于客户端判断获得的是代理对象，还是实际服务对象。\n代理对象中服务对象可以考虑延迟初始化。\n☕ Java 中的动态代理 在 Java 标准库中，提供了动态代理功能，允许在运行期动态创建一个接口的实例。其实就是 JVM 在运行期间，动态创建 class 字节码并加载的过程。\n动态代理通过 Proxy 创建代理对象，然后将接口方法“代理”给 InvocationHandler。\n1 2 3 4 5 6 public interface InvocationHandler { // Object proxy -\u0026gt; 代理的对象 // Method method -\u0026gt; 正在调用的方法 // Object[] args -\u0026gt; 方法的参数 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; } 1 2 // Proxy public static Object newProxyInstance(ClassLoader loader, Class\u0026lt;?\u0026gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException { } 在运行期间创建一个 interface 实例的步骤：\n定义一个 InvocationHandler 实例，负责实现接口的方法调用\n通过 Proxy.newProxyInstance() 创建 interface 实例\nClassLoader loader 类加载器（如当前类的类加载器：CurrentProxy.class.getClassLoader()） Class\u0026lt;?\u0026gt;[] interfaces 需要实现的接口的数组（代理的对象是实现了哪个接口） InvocationHandler h 用来处理接口方法调用的 InvocationHandler 实例（生成的代理对象中的代理方法，需要做什么） 返回一个 Object，可强制转型为接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 模拟经纪人代理歌手的场景 // 接口 interface Star { // ... } class class Eason implements Star { // 需要被代理的类 // ... } public class ProxyDemo { public static Star createProxy(Star star) { // 创建代理对象 Star starProxy = (Star) Proxy.newProxyInstance( ProxyDemo.class.getClassLoader(), new Class[]{Star.class}, new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 代理方法需要做的事情 // 排除 Object 中的通用方法，不进行代理 if (Object.class.equals(method.getDeclaringClass())) { return method.invoke(this, args); } String methodName = method.getName(); if (methodName.equals(\u0026#34;sing\u0026#34;)) { // do ... return method.invoke(star, args); } else if (methodName.equals(\u0026#34;dance\u0026#34;)) { // ... } else { // ... } return null; } } ); return starProxy; } } 🎲 适合场景 🎨 延迟初始化。将对象的初始化延迟到真正有需要的时候。\n🎨 访问控制。代理可仅在客户端凭据满足要求时将请求传递给服务对象。\n🎨 本地执行远程服务 （远程代理）。适用于服务对象位于远程服务器上的情形。代理通过网络传递客户端请求，负责处理所有与网络相关的复杂细节。\n🎨 记录日志请求（日志记录代理）。如需要保存对于服务对象的请求历史记录时。\n🎨 缓存请求结果（缓存代理）。 如可对重复请求所需的相同结果进行缓存。\n🔗 参考 https://refactoringguru.cn/design-patterns/proxy https://bugstack.cn/md/develop/design-pattern/2020-06-16-%E9%87%8D%E5%AD%A6%20Java%20%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E3%80%8A%E5%AE%9E%E6%88%98%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E3%80%8B.html https://www.runoob.com/design-pattern/proxy-pattern.html https://www.liaoxuefeng.com/wiki/1252599548343744/1264804593397984 ","date":"2023-01-05T20:02:02+08:00","image":"https://emerywan.github.io/blog/p/design-pattern/proxy/proxy_hu8322062a052f84a06ac01b10a3cc39e2_138273_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/design-pattern/proxy/","title":"代理模式"},{"content":"原因 随着互联网的发展和用户规模的迅速扩大，对系统的要求也越来越高。传统的 MySQL 单库单表架构的性能问题就暴露出来了。下面几个因素会影响数据库性能：\n数据量\nMySQL 单库数据量在 5000w 以内性能比较好，超过阈值后性能会随着数据量的增大而变弱。\nMySQL 单表数据量是 500w-1000w 之间性能比较好，超过 1000w 性能也会下降。\n磁盘\n单个服务的磁盘空间是有限制的，如果并发压力下，所有的请求都访问同一个节点，肯定会对磁盘 IO 造成非常大的影响。\n数据库连接\n数据库连接是非常稀少的资源，如果一个库里既有用户、商品、订单相关的数据，当海量用户同时操作时，数据库连接就很可能成为瓶颈。\n🐟 垂直拆分 当我们单个库太大时，如果表的数量太多，则应该将部分表进行迁移（如按业务区分），这就是所谓的垂直切分。\n🐠 垂直分库 针对一个系统中的不同业务进行拆分，比如用户相关的一个库，商品相关的一个库，订单相关的一个库。\n垂直分库后将用户、商品、订单放到多个不同的服务器上，不会面临单机资源问题。这种做法与“微服务治理”的做法相似，每个微服务使用单独的一个数据库。\n🐡 垂直分表 基于列字段进行的，“大表拆小表”。\n一般是表中的字段较多，将不常用的，数据较大，长度较长（比如text类型字段）的字段数据拆分到“扩展表“。\n针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。\nMySQL 底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销（IO操作变多）。\n数据也是以页为单位加载到内存中，页中存储的是行数据，大小固定，一行数据占用空间越小，页中存储的行数据也就越多。这样表中字段长度较短且访问频率较高，内存中能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。\n优缺点 优点：\n解决业务系统层面的耦合，业务清晰 能对不同业务的数据进行分级管理、维护、监控、扩展等 高并发场景下，能提升一定的磁盘 IO，数据库连接数，单机硬件资源的瓶颈 缺点：\n部分表无法 join 分布式事务处理复杂 还是存在单表数据量过大的问题 🐥 水平拆分 如果数据量行数巨大，存在单库读写、存储性能瓶颈，这时候就需要进行水平切分了。\n🐤 水平库内分表 水平分表是基于全表的，将一个表中的数据拆分到多个表中，可以大大减少单表数据量，提升查询效率。\n库内分表只是解决了单一表数据量过大的问题，没有将表分布到不同机器的库上，对于减轻 MySQL 数据库的压力来说，帮助不是很大，还是竞争同一个物理机的资源。\n🐣 水平分库分表 将单张表的数据切分到多个服务器上去，每个服务器具有相同的库与表，但是表中的数据不同。\n水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。\n优缺点 优点\n不存在单库数据量过大，高并发的性能瓶颈，提升系统的稳定性和负载能力 应用端改造较小，不需要拆分业务模块 缺点\n跨分片的事务一致性难以保证 跨库的 join 关联查询性能较差 数据多次扩展难度和维护量极大 常见分库分表的策略 🔢 根据数值范围划分 按照时间区间或 ID 区间进行区分。如：\n🧩 按日期将不同月或不同日的分散到不同库中 🧩 根据 id 分，将 [0, 1000000] 分到第一个库，[1000001, 2000000] 分到第二个库 🧩 “冷热数据分离”，一些使用较少的历史数据迁移到其他库中，业务功能上只提供热点数据的查询 优点：\n单表大小可控 天然便于水平扩展，扩容只需要添加节点，无需对其他分片数据进行迁移 在范围查找时，连续分片可以快速进行定位查询 缺点：\n热点数据成为瓶颈。连续分片可能存在热点数据，如按时间分片时，有些最近时间的分片会被频繁读取，有些历史分片会很少查询 🧮 根据数值取模 一般采用 hash 取模的分片方式。\n如根据用户 user_no 字段取余（根据数据库的数量取余），余数为 0 放到第一个库，余数为 1 放到第二个库，以此类推。（同一个用户会定位到相同的数据库）\n优点：\n数据分片相对来说比较均匀，不容易出现热点和并发访问的瓶颈。 缺点：\n后期分片扩容时，需要迁移旧数据（使用一致性 hash 算法能较好避免） 容易遇到分片查询复杂问题，如通过 user_no 进行的分库分表，如果有多数查询条件中不包含 user_no 字段，就无法定位数据库，需要在所有的数据库发起查询 🌐 根据地理位置 根据地理位置，将相同地区的放到一张表中。如：华南区一个表，华北区一个表。\n常见分库分表的问题 事务一致性问题 分布式事务\n分布式事务能最大限度保证了数据库操作的原子性。\n使用分布式事务中间件 使用 MySQL 自带的针对跨库的事务一致性方案（XA），性能要比单库的慢 10 倍左右。 在业务上，避免跨库操作（如将用户和商品放到同一个库中） 最终一致性\n不苛求系统的实时一致性，只要在允许的时间段内达到最终一致性即可，可采用事务补偿的方式。\n事务补偿是一种事后检查补救的措施，一些常见的实现方法有：对数据进行对账检查，基于日志进行对比，定期同标准数据来源进行同步等等。\n跨节点关联查询 join 问题 多次查询进行数据组装\n在系统层面，分两次查询，最后将获得到的数据进行字段拼装。\n添加冗余字段\n一种典型的反范式设计，利用空间换时间，为了性能而避免 join 查询。\n但这种方法适用场景有限，适用于依赖字段比较少的情况。而冗余字段的数据一致性也较难保证，要结合实际业务场景进行考虑。\n跨节点分页、排序、函数问题 先在不同的分片节点中将数据进行操作，在服务层进行汇总操作，最终返回给用户。\n主键问题 UUID（不推荐）\n使用 Redis 生成主键（incr 时自增的原子命令）\n使用 Zookeeper 生成唯一 ID\n雪花算法生成\n百度 uidgenerator\n美团 Leaf\n滴滴 TinyID\n数据迁移，扩容问题 如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。\n如果采用的是数值取模分片，针对数据量的递增，可能需要动态的增加表，因为reHash有可能导致数据迁移问题，则考虑后期的扩容问题就相对比较麻烦。\n考虑切分的情况 能不切分就尽量不要切分\n不到万不得已不用轻易使用分库分表这个大招，避免\u0026quot;过度设计\u0026quot;和\u0026quot;过早优化\u0026quot;。\n数据量过大，正常运维影响业务访问\n对数据库备份，如果单表太大，备份时需要大量的磁盘 IO 和网络 IO 对一个很大的表进行 DDL 修改时，MySQL会锁住全表，这个时间会很长，这段时间业务不能访问此表，影响很大 大表会经常访问与更新，就更有可能出现锁等待 随着业务发展，数据量快速增长\n安全性和可用性\n利用垂直切分，一个数据库出现问题，只会影响到部分业务，不会使所有的业务都瘫痪。 利用水平切分，当一个数据库出现问题时，不会影响到100%的用户，每个库只承担业务的一部分数据，这样整体的可用性就能提高。 常见分库分表中间件 sharding-jdbc\nMyCat\n参考 https://blog.nowcoder.net/n/4309986033e64155a8c836959faf01b8 ","date":"2023-01-05T17:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/2.jpeg","permalink":"https://emerywan.github.io/blog/p/mysql/split-database-and-table/","title":"MySQL 分库分表"},{"content":"前言 之前鼠按键一直不灵，经常需要按很多下，换了电池之后还是这样，网上一搜，竟然是这鼠标的通病 😓。看到很多教怎么换鼠标微动的，就打算自己试试了。😤\n🛠️ 工具准备 淘宝随便买焊接工具一套：\n相同的鼠标微动：这个不要买错了，注意高度！我这个是黄的那个，看到网上同款有些时红色的，如果是新手推荐多买几个，不小心弄坏了还可有备用。\n推荐 助焊剂可选的话，安利买焊油🙋‍而不是松香🙅‍，感觉松下这东西不适合新手用，很不方便感觉。\n📚 过程 拆开还是很简单的，只要把两颗看得见的螺丝卸掉，就可以把外壳给开了。\n只要把这两个地方的焊锡熔化，就可以把旧的拆下来，换微动啦。😲\n工厂里面都是使用的高温焊锡，直接用电烙铁是不能把上面的焊锡给直接融化的，⚠ 先加上一点助焊剂（重要！），再往上加焊一点自己焊锡，就可以融化上面的高温锡了（感觉有点像相似相溶）。\n这时候就需要等锡球是液体的时候，用吸锡枪把液体的锡球给吸掉。我的吸锡枪不知道被什么压碎了，用吸锡带放到电烙铁上拖一遍也是可以的，很简单，随便在网上找一个维修视频看看就会了，吸的很干净！\n💡 结果 最后换起来还是很方便的，把新的插进去，再用电烙铁焊上去两点锡，就固定的很好了。👍\n哈哈，第一次焊接，看起来效果非常好。😀\n主板看起来有点脏，没有洗版水洗主板，其实没有影响，不洗也不会影响电气性能。\n最后就是这个烙铁，竟然用几下就变得这么脏了。😂\n","date":"2022-11-12T21:14:45+08:00","image":"https://emerywan.github.io/blog/p/fix-logi-mouse/05_hu6e2e43df522d586c0a61d755538e45f9_1576731_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/fix-logi-mouse/","title":"动手维修罗技鼠标 🤭"},{"content":"java.lang.ThreadLocal ThreadLocal 是一个创建线程局部变量的类。\n通常创建的共享变量是可以被任一个线程访问并修改的，存在线程安全问题。使用 ThreadLocal 创建的变量只有当前线程才可访问，其他线程无法修改和访问。\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class DateUtils { public static final ThreadLocal\u0026lt;DateFormat\u0026gt; df = new ThreadLocal\u0026lt;\u0026gt;() { // 重写 initialValue 可设置初始值 @Override protected DateFormat initialValue() { return new SimpleDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;); } } } // --- DateUtils.df.get().format(new Date()); 原理 每一个线程的 Thread 对象中都有一个 ThreadLocal.ThreadLocalMap 对象，这个对象存储了一组以 ThreadLocal.threadLocalHashCode 为键，以本地线程变量为值的 Key-Value 对。\nThreadLocal 对象就是当前线程的 ThreadLocalMap 的访问入口，每一个 ThreadLocal 对象都包含了一个独一无二的 threadLocalHashCode 值，使用这个值，就可以在线程 K-V 值对中找到对应的本地线程变量。\n1 2 3 4 5 public class Thread implements Runnable { // ... ThreadLocal.ThreadLocalMap threadLocals = null; // ... } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class ThreadLocal\u0026lt;T\u0026gt; { // ... static class ThreadLocalMap { static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { Object value; Enrty(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } private Enrty[] table; } // ... } set() 获取当前线程 利用当前线程作为句柄，获取一个 ThreadLocalMap 对象 如果 ThreadLocalMap 对象不为空，则设置值，否则创建这个 ThreadLocalMap 对象并设置值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } // --- ThreadLocalMap getMap(Thread t) { return t.threadLocals; } // --- void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } get() 获取当前线程，并获取当前线程的 ThreadLocalMap 对象 如果当前线程的 ThreadLocalMap 已经初始化，返回当前 ThreadLocal 为 Key 的值 如果 ThreadLocalMap 没有被初始化，或者不存在以 ThreadLocal 为 Key 的值，将创建一个新的 Value，并返回 initialValue 默认为 null，可进行重写 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // ThreadLocal#get public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) T result = (T)e.value; return result; } } return setInitialValue(); } // ThreadLocal#setInitialValue private T setInitialValue() { T value = initialValue(); // 获得一个初始值，未重写默认为 null Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; } // ThreadLocal#initialValue protected T initialValue() { return null; // 默认为 null，可被重写 } // ThreadLocalMap#createMap void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } remove() 通过调用 ThreadLocalMap 的 remove() 方法完成移除操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public void remove() { ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); } // --- // ThreadLocalMap remove() private void remove(ThreadLocal\u0026lt;?\u0026gt; key) { Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode \u0026amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { if (e.get() == key) { e.clear(); expungeStaleEntry(i); return; } } } 内存泄露 指程序申请内存后，一直无法释放已经申请的内存。\nThreadLocalMap 使用 ThreadLocal 的弱引用作为 key，如果一个 ThreadLocal 不存在外部的强引用时，下次 GC 时，该 key 就会被回收，但是 value 还存在着强引用，如果没有手动地 remove() 或者线程一直没有结束（例如使用线程池），value 就会一直存在，导致内存泄漏。\n解决办法：\n每次使用完后进行 remove()\n使用 set()、get() 时（部分），扩容 rehash() 时（全量），会判断对 key=null 的进行清理\n可以将 ThreadLocal 设置为 staic final\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 private void rehash() { // 进行全量清理 expungeStaleEntries(); if (size \u0026gt;= threshold - threshold / 4) resize(); } private void expungeStaleEntries() { Entry[] tab = table; int len = tab.length; for (int j = 0; j \u0026lt; len; j++) { Entry e = tab[j]; if (e != null \u0026amp;\u0026amp; e.get() == null) expungeStaleEntry(j); } } 应用场景 线程资源持有，代替参数显示传递\n全局存储信息，在需要的地方直接获取\n解决线程安全问题，达到线程隔离\n参考 🔗 https://www.cnblogs.com/crazymakercircle/p/14491965.html#autoid-h2-2-0-0 ","date":"2022-09-02T16:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/19.jpeg","permalink":"https://emerywan.github.io/blog/p/thread/threadlocal/","title":"ThreadLocal"},{"content":"起因 之前博客都部署在腾讯云的 CloudBase，以按量收费的方式，每个月都有一些免费的流程和 CDN，我的博客完全用不完，每月就只需要几毛，基本不用花钱。🫣\n除了偶尔会无法推送成功之外，国内访问速度相当快，毕竟部署在国内。\n但是最近改了付费方式，先买套餐，超出再进行按量收费。🤔\n虽然 CloudBase 可以部署完整的项目，但是我只需要托管一点静态页面，最低正常价 39.9 每月，到时候买这个套餐不如直接买个云服务器。果然白嫖是不可能一直白嫖的。🫠\n流程 腾讯云中还有专门托管静态页面的服务 Webify，类似于 Github 中的静态页面服务，费用相较来说挺低的，这里打算把博客迁移过去。\n在部署模板里面，只有一些前端框架，没有 Hugo，所以这里利用 Github Action 编译成静态页面后，推送到其他分支/仓库，再托管这些静态代码。\n推送到 Github 其他分支的静态页面，还可以再托管一个 Github Page 做备份。\n流程大致为：\nHugo -\u0026gt; Github Action -\u0026gt; 静态页面 -\u0026gt; 腾讯云 Webify 拉取静态页面 -\u0026gt; 部署\n添加 workflows 这里是选择推送到另外一个仓库，因为在 Webify 服务里，没找到怎么更换部署分支，直接用了默认分支。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 name: Webify Pages on: push: branches: - main jobs: deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; extended: true # 是否需要 extended 版本 - name: Build run: hugo --minify --gc --config config.yaml - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.DEPLOY_KEY }} # 外仓库使用 deploy_key external_repository: emerywan/blog publish_dir: ./public publish_branch: main 新建应用 云产品 - Web 应用托管\n选择需要托管的仓库就可以了，下一步就行了。\n自定义域名，也是可以使用免费 CDN 的 🫣 ，只是没有一些高级功能，设置防盗链什么的，作为国内的服务，已经很不错啦。这个再改计费方式，就打算直接用 Vercel 了。😂\n","date":"2022-08-22T18:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/1.jpeg","permalink":"https://emerywan.github.io/blog/p/hugo-in-webify/","title":"迁移博客到 Webify"},{"content":"\n🧐 线程隔离\n程序计数器 虚拟机栈 本地方法栈 ☺️ 线程共享\n方法区 堆 🎋 程序计数器 当前线程执行字节码的行号指示器。\n唯一一个不会出现 OutOfMemoryError 的内存区域，随线程的创建而创建，随线程的结束而死亡。\n🎋 虚拟机栈 每一次方法的调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。\n当线程请求栈的深度超过当前 Java 虚拟机最大深度时，会抛出 StackOverFlowError。\n局部变量表\n存放编译期可知的各种数据类型，对象引用地址。\n操作数栈\n方法执行过程中的计算结果，计算过程中产生的临时变量。\n动态链接\n服务于一个方法需要调用其他方法的场景。\n方法返回地址\n正常返回（return） 异常返回（Exception） 🎋 本地方法栈 本地方法栈用于虚拟机执行 Native 方法，具体与虚拟机栈类似。\n🎍 方法区 方法区是 Java 虚拟机的抽象概念。实现方式在不同虚拟机中可能不同。\nJDK 8 之前，HotSpot 虚拟机使用永久带实现方法区 JDK 8 及之后，使用元空间（直接内存）实现\n字符串常量池与静态变量转移到了堆中。\n类的元信息\n类名，访问修饰符，字段描述，方法描述等\n运行时常量池\n存放编译后的各种字面量，符号引用，常量（final）池表等\n字符串常量池\nJVM 为了减少字符串对内存的消耗，并提升性能，专门开辟的区域\n静态变量\n类变量（static）\n🎍 堆 用来存放和管理对象实例，几乎所有的对象实例都在这里分配。（存在逃逸分析，栈上分配，有些对象不一定在堆中）\nJava 堆是垃圾回收的主要区域，因此也被称为 GC 堆。\nJDK 8 之前，堆被分为\n新生代（Eden、Survivor0、Survivor1） 老年代 永久代（方法区也由永久代实现） JDK 8 之后，永久代被取消\n大部分情况下，对象首先会在新生代的 Eden 区进行分配；在一次垃圾回收后，如果对象还存活，会进入 S0 或 S1；当对象年龄增长到一定程度（默认 15），或累积的年龄超过了 Survivor 的一半，会晋升到老年代。\n参考 图来源于网络。 深入理解 Java 虚拟机 ","date":"2022-08-08T15:02:02+08:00","image":"https://emerywan.github.io/blog/p/java/jvm/memory-area/area_hu7d264de33d14753fd73bf351bb5dce63_911596_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/java/jvm/memory-area/","title":"JVM 内存区域"},{"content":"🌴 对象存活判定 🪨 引用计数法 给每个对象添加一个引用计数器：\n当有地方引用该对象，计数器 +1 当引用失效，计数器 -1 当计数器为 0 时，表示对象不可用 该方法简单高效，但主流的虚拟机都没有选择该方法管理内存，难以解决对象之间循环引用的问题。\n🪨 可达性分析法 通过一系列称为 GC Root 的对象作为起点，从这些起点向下搜索，节点走过的路径称为引用链，当一个对象与 GC Root 之间没有任何引用链相连的话，说明对象不可用，需要被回收。\n可以作为 GC Root 的对象：\n虚拟机栈（栈帧中局部变量表）引用的对象 本地方法栈中引用的对象 类静态属性引用的对象 方法区中常量引用的对象 所有被同步锁（synchronized）持有的对象 🌴 垃圾回收算法 🪵 标记-清除 标记出所有需要回收的对象 标记结束后，统一回收掉所有被标记的对象 执行效率不稳定，大部分对象需要回收时，需要大量标记和清除操作 内存空间碎片化问题 🪵 标记-复制 将内存分为两块，每次只使用其中的一块 当一块内存使用完后，将存活的对象复制到另外一块去 将已经使用的空间一次性清除掉 可用内存变少，有空间浪费问题 🪵 标记-整理 标记出所有需要回收的对象 让这些存活对象向内存的一端移动 直接清除掉边界以外的内存 🪵 分代收集 根据对象存活周期的不同，将 Java 堆分为新生代和老年代，依据各个区域的特点，选择回收算法。\n在新生代中，每次收集都会有大量的对象死去，选择 标记-复制 算法 在老年代中，存活对象的几率较高，没有额外的空间进行分配担保，选择 标记-清除 或 标记-整理 算法 🌴 垃圾收集方式 🪨 部分收集 收集堆部分区域。Partial GC\n新生代收集 Minor GC / Young GC\n目标只是新生代的垃圾收集。\n老年代收集 Major GC / Old GC\n目标只是老年代的垃圾收集，目前只有 CMS 收集器会有单独收集老年代的行为。\n混合收集 Mixed GC\n目标是整个新生代和部分老年代的垃圾收集，目前只有 G1 收集器会有这种行为。\n🪨 整堆收集 收集整个堆和方法区。Full GC\n晋升到老年代的对象大于老年代的剩余空间 Minor GC 后，新生代存活对象超过了老年代的空间（分配担保机制） 手动 System.gc() （Java 8 之前）永久代空间不足 🌴 垃圾收集器 🪵 Serial / Serial Old “单线程”的垃圾收集器，在进行垃圾收集时，必须暂停其他所有工作线程stop the world，直到收集结束。\n新生代采用 标记-复制 算法，老年代采用 标记-整理 算法。 简单高效 依旧是现在 HotSpot 虚拟机运行在客户端模式下的默认新生代垃圾回收方式 🪵 ParNew Serial 的多线程版本，可以使用多条线程进行垃圾回收。（新生代）\n采用标记-复制算法 🪵 Parallel Scavenge / Parallel Old 基于 标记-复制 算法实现的新生代垃圾收集器，能够并行收集的多线程收集器，目标是达到一个可控制的“吞吐量”。 基于 标记-整理 算法实现的老年代多线程收集器。 Java 8 默认的收集器为 Parallel Sacvenge + Parallel Old\n吞吐量 TPS ：系统在单位时间内处理请求的数量\n🪵 CMS Concurrent Mark Swap 获取最短停顿时间的收集器。\n是 HotSpot 虚拟机第一款真正意义上的并发垃圾收集器，实现了用户线程和垃圾回收线程同时工作。基于 标记-清除 算法的 老年代 收集器。\nCMS 收集器整个过程分为四个步骤：\n🐾 初始标记\n标记与 GC Root 直接关联的对象。暂停用户线程（stop the world），但速度较快。\n🐾 并发标记\n用户线程和垃圾回收线程同时工作，从 GC Root 直接关联的对象开始遍历，根据可达性分析，找出存活对象。\n🐾 重新标记\n修正并发标记过程中，由于程序继续运行，导致的标记错误。暂停用户线程（stop the world）。\n🐾 并发清除\n并发地清理未被标记的区域。\n缺点：\n对 CPU 资源敏感 无法处理浮动垃圾：运行过程中，有一些垃圾在当次无法处理，需要等待下次垃圾回收 会产生内存碎片，导致连续空间减少，导致 Full GC 🪵 G1 G1 开创了收集器面向局部收集的设计思路和基于 Region 的内存布局形式。\n将 Java 堆分为 2048 个大小相同的独立 Region，每个 Region 的大小依据堆空间的大小而定，在 JVM 生命周期中不会改变。\n每个 Region 都可以根据需要，作为新生代的 Eden 区，Survivor 区，或者是老年代；新生代和老年代在内存中不是连续的空间，收集器会根据区域的不同采取不同的策略。\nRegion 中还会有一类特殊的巨大区域 Humongous，专门用来存储大对象。当对象的大小超过了一个 Region 的一半，就被判定为大对象。\nG1 收集器回收的步骤：\n🐾 初始标记\n标记 GC Root 能够直接关联到的对象，需要停顿线程（stop the world），耗时较短。\n🐾 并发标记\n从 GC Root 开始对堆中的对象进行可达性分析，找出需要回收的对象，与用户线程同时执行。\n🐾 最终标记\n修正并发标记期间因用户程序继续运作而导致标记产生的变动。\n🐾 筛选回收\n对各个 Region 的回收价值和成本进行排序，会选择价值最大的区域进行回收。\n将回收的 Region 中的存活对象，复制到空的 Region 中，再清理掉整个旧的 Region 区域。\n涉及对象的移动，必须暂停用户线程（stop the world），有多条垃圾收集器并发执行。但是只回收一部分Region，时间是用户可控制的。\n🌴 对象分配和回收原则 🪨 对象优先在 Eden 区分配 大多数情况下，对象在新生代 Eden 区分配，当 Eden 区没有足够空间时，虚拟机会发起一次 Minor GC。\n🪨 大对象直接进入老年代 需要大量连续内存空间的 Java 对象（数组，很长的字符串），直接在老年代分配，避免在 Eden 区和两个 Survivor 区之间来回复制，产生大量的内存复制操作。\n🪨 长期存活的对象进入老年代 虚拟机给每个对象一个对象年龄计数器，每经过一次 MinorGC，年龄就会 +1，\n当年龄增加到一定程度（默认 15），或某个年龄超过了 Survivor 区的一半时，会晋升到老年代。\n🪨 空间分配担保 确保在 Minor GC 之前，老年代还有容纳新生代所有对象的剩余空间。\n进行一次 Minor GC 之后，Eden 区中任然存在大量对象，Survivor 中无法容纳，直接送到老年代，让老年代进行空间分配担保。\n","date":"2022-08-07T12:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/26.jpeg","permalink":"https://emerywan.github.io/blog/p/java/jvm/garbage-collection/","title":"JVM 垃圾回收"},{"content":"JMM Java 内存模型（Java Memory Model）屏蔽了不同操作系统和各种硬件的内存访问差异，实现了 Java 程序在各种平台下，都能达到一致性的访问效果。\nJMM 规定了：\n所有的变量都存储在主存中 每条线程有自己的工作内存 线程对变量的所有操作（读取、赋值等），不能直接读写主存中的数据，都必须在工作内存中进行 原子性、可见性、有序性 Java 内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性三个特征来建立的。\n🐥 原子性 一次或多次操作，要么全部执行且不受到任何干扰，要么全都不执行。\n利用锁，可以让任一时刻只有一个线程访问代码块。synchronized Lock 利用 CAS 原子类，保证原子操作。 🐤 可见性 一个线程修改了共享变量的值，其他线程能够立即得知这个修改。\nvolatile 规定每次写操作，都立即同步到主存；每次读操作，都从主存中读取。\nsynchronized lock 对一个变量执行执行 unlock 之前，必须把变量同步回主存中。\nfinal 🐣 有序性 指令重排问题，代码的执行顺序不一定。\nvolatile 包含禁止指令重排序的语义。\nsynchronized 只有一条线程能够进入临界区。\nvolatile Java 虚拟机提供的轻量级内存同步机制。\n作用：\n✔️ 保障了此变量对所有线程的可见性 volatile 的写操作，都会刷新到主内存中，并使其他线程中的 volatile 变量失效；volatile 的读操作，都会从主存中读取。\n✔️ 禁止指令重排优化（有序性） 防止写操作之前的代码，重排到写操作之后；防止读操作之后的代码，重排到读操作之前。\n❗️无法保障原子性 一条字节码在执行时，是需要运行多条指令才能实现。\n实现方式：内存屏障。重排序时，不能把后面的指令重排序到内存屏障之前的位置。\n保证：之前的指令一定全部执行，之后的指令一定都没有执行，并且前面语句的结果对后面的语句可见。\nhappens-before 原则 对于两个操作 A 和 B，这两个操作可以在不同的线程中执行。如果 A happens-before B（A 优先于 B 执行），那么可以保证，当 A 操作完后，A 的操作对于 B 操作是可见的。\n指令重排提高了并发性能，但是 Java 虚拟机会对指令重排做一些规则限制，并不能让所有的指令都随意改变执行位置。\nJava 内存模型天然的先行发生关系：\n程序顺序规则\n在一个线程内，前面的代码操作优于后面的代码操作。\n锁定规则\n一个 unlock 操作优于后面对于同一个锁的 lock 操作。\nvolatile 规则\n一个 volatile 变量的写操作，优于后面这个变量的读操作。\n传递规则\n如果 A happens-before B，且 B happens-before C，那么 A happens-before C。\n线程启动规则\nThread 对象的 start() 方法 happens-before 线程的每一个动作。\n","date":"2022-08-07T06:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/28.jpeg","permalink":"https://emerywan.github.io/blog/p/java/jvm/memory-model/","title":"JVM 内存模型"},{"content":"类加载器 🙈 BootstrapClassLoader 启动类加载器，最顶层的加载类，由 C/C++ 实现。\n负责加载：\n%JAVA_HOME%/lib 目录下的 jar 包和类 被 -Xbootclasspath 参数指定的路径中的所有类。 🙉 ExtensionClassLoader 扩展类加载器。\n是一种 Java 系统类库的扩展机制。负责加载 %JRE_HOME%/lib/ext 目录下的 jar 包和类，或被 java.ext.dirs 系统变量所指定的路径下的 jar 包。\n🙊 ApplicationClassLoader 面向用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。\n双亲委派模型 每个类加载器都有自己的命名空间，用不同的类加载器加载了同一个限定名的类，JVM 也会认为是两个不同的类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 protected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // (1) 判断是否加载过该类 Class\u0026lt;?\u0026gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { c = parent.loadClass(name, false); } else { // (2) parent == null 约定为：parnet 为 Bootstracp ClassLoader c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // (3) 说明 parent 加载不了，当前 loader 尝试加载 class long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } 默认情况下，一个限定名的类只会被一个类加载器加载并解析使用，在程序中是唯一的，不会产生歧义。\n在加载时，首先会判断当前类是否被加载过，如果已经加载，会直接返回，否则才会尝试加载。\n尝试加载时，不会自己进行加载，而是将请求委派给父类加载器，当父类加载器无法加载时，才会由自己处理。\n","date":"2022-08-06T16:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/25.jpeg","permalink":"https://emerywan.github.io/blog/p/java/jvm/classloader/","title":"类加载器"},{"content":"Java 类生命周期 类加载过程 类加载主要有三步：加载 - 链接 - 初始化。\n🥎 加载 加载是一个读取 Class 文件，将其转化为某种静态数据结构存储在方法区内，并在堆中生成一个便于调用的 java.lang.Class 类型的对象的过程。\n分为三步进行：\n获取定义类的二进制字节流（不限制从哪里获取，可以从文件、网络、即时生成）\n将字节流代表的静态存储结构，转换成方法区中运行时数据结构\n在堆中生成一个代表该类的 java.lang.Class 对象，作为方法区这个类的各种数据访问入口\n🥎 链接 ⚾️ 验证 文件格式验证\n验证字节流是否符合 Class 文件格式的规范，能被当前版本的虚拟机处理。发生在加载阶段。\n元数据、字节码验证\n对字节码进行语法、语义的分析，保证其符合 Java 虚拟机的规范，不会有危害虚拟机的行为。\n符号引用验证\n确保解析行为能够正常执行。发生在解析阶段。\n⚾️ 准备 为类中定义的变量（静态变量 static）分配内存并设置类变量零值的阶段。\nstatic -\u0026gt; 赋零值 static final -\u0026gt; 赋定义的常量值 ⚾️ 解析 解析是将常量池中的符号引用替换为直接引用。\n符号引用：描述引用对象的符号\n直接引用：指向目标实际地址的指针\n🎾 解析部分是灵活的，可以在初始化环节后再进行，实现所谓的“后期绑定”。（方法调用直到运行时才会解析，因为无法在编译时确定方法调用所需的所有信息，所以方法定义和方法调用直到运行时才绑定。）\n当一个类被编译成 Class 之后，假设这个类称为 A，并且在类 A 中引用了类 B。\n在编译阶段，A 无法确定 B 是否被编译（现在 B 一定未加载），此时 A 无法知道 B 的实际地址，所有在 A.Class 中，会使用一个字符串代表 B，这个字符串被称为符号引用。\n在运行阶段，A 发生了加载，在解析时，发现其中的 B 还未被加载，就会触发类 B 的加载，将 B 加载到虚拟机中。此时，A 中的符号引用会被替换为 B 中的实际地址（也就是直接引用）。\n静态解析\n类 B 是具体的实现类，解析的对象十分明确，即会进行静态解析。\n动态解析\nJava 通过后期绑定的方式实现多态，通过动态解析实现。\n如果类 B 是抽象类或者接口，有具体的实现类 C、D，当前具体的实现方式并不明确，无法确定使用哪个具体实现。\n直到运行过程中发生了调用，虚拟机调用栈中会得到具体类的信息，再进行解析，就有明确的直接引用代替符号引用。\n🥎 初始化 虚拟机真正开始执行类中编写的代码，完成一些主动的资源初始化动作。\n执行的是类层面的初始化。 只有显式调用 new 才会执行构造函数的初始化。\n类变量（静态变量）的赋值 static 静态代码块 static { } 如何判断无用类 该类的所有实例对象全部被 GC，在堆中不存在该类的任何实例对象 该类对应的 java.lang.Class 对象，在任何地方都没有被引用 该类的类加载器已经被回收 满足以上三个条件，说明该类可以被回收，但是与对象不同，无用类不一定会被回收。\n参考 https://javaguide.cn/java/jvm/class-loading-process.html\nhttps://www.bilibili.com/video/BV14U4y1L75q/?spm_id_from=333.788\n深入理解 Java 虚拟机\n","date":"2022-08-06T13:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/24.jpeg","permalink":"https://emerywan.github.io/blog/p/java/jvm/class-loading/","title":"类加载机制"},{"content":" 🔥 主要思路：\n🚀 增加数据时，尽量顺序插入\n🚀 删除、修改、查询数据时，尽量走索引操作\n🐈‍⬛ 主键优化 ⭐ 满足业务需求的情况下，尽量降低主键的长度，减少磁盘 IO\n⭐ 插入数据尽量选择顺序插入，选择使用 auto_increment 自增主键\n⭐ 尽量不要使用 UUID 或其他自然主键（如身份证号） 作为主键\n⭐ 业务操作避免对主键的修改\n在 InnoDB 存储引擎中，表数据是根据主键顺序组织存放的。这种存储方式为索引组织表（index organized table IOT）。\n数据行是记录在逻辑结构 page 页中的，而每一个页的大小是固定的，默认 16K。也就意味着，一个页中所存储的行也是有限的，如果插入的数据行在该页存储不下，将会存储到下一个页中，页与页之间会通过指针连接。\n🦮 insert 优化 一次性往数据库中插入多条数据，可从以下三方面优化：\n批量插入数据 1 insert into tb_test values (1, \u0026#39;Tom\u0026#39;), (2, \u0026#39;Cat\u0026#39;), (3, \u0026#39;Jerry\u0026#39;); 手动控制事务 1 2 3 4 5 start transaction; insert into tb_test values (1, \u0026#39;Tom\u0026#39;), (2, \u0026#39;Cat\u0026#39;), (3, \u0026#39;Jerry\u0026#39;); insert into tb_test values (4,\u0026#39;Tom\u0026#39;), (5,\u0026#39;Cat\u0026#39;), (6,\u0026#39;Jerry\u0026#39;); insert into tb_test values (7,\u0026#39;Tom\u0026#39;), (8,\u0026#39;Cat\u0026#39;), (9,\u0026#39;Jerry\u0026#39;); commit; 主键顺序插入 数据在 B+ 树的叶子节点有序存放，顺序插入保障每次插入都是在后面添加一条记录（顺序磁盘 IO），不需要调整叶子节点中的内容。\n1 2 🙅‍♂️ 主键乱序插入 : 8 1 9 21 88 2 4 15 89 5 7 3 🙋‍ 主键顺序插入 : 1 2 3 4 5 7 8 9 15 21 88 89 🦛 update 优化 🫧 防止索引失效\n🫧 防止升级为表锁\nInnoDB的行锁是针对索引加的锁，不是针对记录加的锁，并且该索引不能失效，否则会从行锁升级为表锁。\n开启多个事务，在执行 SQL 时，防止行锁升级为表锁。\n🦒 order by 优化 🍀 根据排序字段建立合适的索引\n🍀 多字段排序时，尽量遵循最左前缀法则\n🍀 尽量使用索引 / 覆盖索引 🐎 limit 优化 在数据量比较大时，如果进行 limit 分页查询，在查询时，越往后，分页查询效率越低。\n当在进行分页查询时，如果执行 limit 2000000,10 ，此时 MySQL 会排序前 2000010 条的记录， 仅仅返回 2000000 - 2000010 的记录，其他记录会被丢弃，查询排序的代价非常大。\n优化思路:\n🎈 在业余允许的情况下，可以限制页数。通常用户也不会向后面翻很多页。\n例如在淘宝双十一时不能查询历史购物记录。\n🎈 可以通过先定位数据，先偏移，再 limit\n1 2 3 select * from user where id \u0026gt; 2000000 limit 10; 🎈 通过覆盖索引 + 子查询形式进行优化\n1 2 3 4 5 6 7 8 9 10 select * from user u where id \u0026gt;= (select id from user order by id limit 2000000 1) limit 10; -- or select * from user u, (select id from tb_sku order by id limit 2000000, 10) a where u.id=a.id; 🦬 count 优化 count(*) == count(数字) \u0026gt; count(主键) \u0026gt; count(字段)\n⭐ count(主键)\nInnoDB 引擎会遍历整张表，把每一行的 主键id 值都取出来，返回给服务层。服务层拿到主键后，按行进行累加（主键不可能为null）。 ⭐ count(字段)（注意 null 约束）\n没有 not null 约束: InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，服务层判断是否为 null，不为 null，就计数累加。 有 not null 约束：InnoDB 引擎会遍历整张表把每一行的字段值都取出来，返回给服务层，直接按行进行累加。 ⭐ count(数字)\nInnoDB 引擎遍历整张表，但不取值。服务层对于返回的每一行，放一个数字 “1” 进去，直接按行进行累加。 ⭐ count(*)\nInnoDB引擎并不会把全部字段取出来，而是专门做了优化，不取值，服务层直接按行进行累加。 ","date":"2022-07-01T18:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/20.jpeg","permalink":"https://emerywan.github.io/blog/p/mysql/sql-optimize/","title":"SQL 语句优化"},{"content":"事务 事务是一组逻辑上的数据库操作，这些操作要么全部成功，要么全部失败。\nA 原子性：事务是不可分割的最小操作单元，要么全部成功，要么全部失败。\nC 一致性：事务完成时，必须使所有的数据都保持一致状态。\nI 隔离性：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行。\nD 持久性：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。\nC(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是是为了保证一致性，数据库提供的手段。\n🔃 redo log 重做日志，记录的是“某个数据页上做了什么修改”。（物理日志）\nredo log 用来保障数据库的持久性。在一个事务中，执行增删改的操作时，InnoDB 引擎会先操作缓冲池 Buffer Pool 中的数据，如果缓冲区没有对应的数据，会通过后台线程将磁盘中的数据加载出来，存放在缓冲区中，再将缓冲池中的数据修改。\n修改后的数据页我们称为脏页，缓冲区的脏页数据并不是实时刷新的，而是一段时间之后将缓冲区的数据刷新到磁盘中（随机磁盘 IO），从而保证缓冲区与磁盘的数据一致。\n对缓冲区的数据进行增删改，会首先将操作的数据页的变化，记录在 redo log buffer 中。在事务提交时，将 redo log buffer 中的数据刷新到 redo log 磁盘文件中（顺序磁盘 IO）。\n如果刷新缓冲区的脏页到磁盘时发生错误，或者发生了异常断电，就可以借助于 redo log 进行数据恢复，这样就保证了事务的持久性。\n🔙 undo log 回滚日志。记录操作数据库的逆操作，用于进行回滚。\n作用：\n提供回滚操作（保障事务的原子性） 实现 MVCC 操作，提升数据库性能 undo log 是逻辑日志，在 InnoDB 存储引擎对记录进行修改时，会把回滚需要的信息全部记录到 undo 中，如果发生回滚，就会读取 undo log，然后执行与之相反的操作。\n➕ 插入数据，记录这条数据的主键，回滚时根据主键把该条记录删除\n➖ 删除数据，记录这条数据的所有内容，回滚时将这些内容组成的记录插入表中\n🖋️ 更新数据，\n更新了主键，会记录两条 undo log，一条删除的，一条更新的 没有更新主键，记录这条数据更新列的旧值，回滚时将数据更新为旧值 📔 MVCC 多版本并发控制，同一条记录在数据库中，可以存在多个版本。\n依赖于：\n行的隐式字段 DB_TRX_ID 事务 id DB_ROLL_PTR 回滚指针（记录这条记录的上一个版本） undo log Read View 当前读 读取的是记录的最新版本。\nupdate insert delete select ... for update select ... lock in share mode 都是进行当前读。\n快照读 简单的不加锁 select 就是快照读。读取的是快照版本，通过 MVCC 进行并发控制。\n🚀 关键特性 InnoDB 存储引擎的特性，可以带来更高的性能和可靠性。\n🧮 插入缓冲 Insert Buffer 当插入一条数据的时候，在聚簇索引中，通常数据都是在叶子节点顺序存放的，只需要将插入的数据放到最后即可（主键顺序存放）。\n通常我们都会在一张表上创建一些二级索引，而这些二级索引在数据插入时，需要维护索引是离散的，由于随机 IO 就会导致插入性能的下降。\n为了解决以上问题，InnoDB 设计了 Insert Buffer。\n二级索引的更新操作：\n如果需要更新的索引页在 Buffer Pool 中，则直接插入； 如果不在，则插入 Insert Buffer，之后以一定的频率和情况在与二级索引合并 使用 Insert Buffer 需要满足两个条件：\n⭐ 二级索引 ⭐ 非唯一索引 如果二级索引是唯一的，在插入时，还需要去索引页查找改索引是否唯一，这样的离散读取两部分，会导致 Insert Buffer 失去意义。\n后续的版本提供了升级版本 Change Buffer，对 Insert、Delete、Update 都进行缓冲。\n🖋️ 两次写 Double Write InnoDB 将脏页刷新到磁盘中时，突然发生宕机，只写入了一半，可能会发生数据丢失的问题。\nInnDB 使用 Double Wirte 机制，给数据添加副本，防止数据丢失。\n需要刷新的脏页会被复制到 Double Write Buffer 中，在需要刷盘时：\n先分两次写入一份到共享表空间的 double wirte 物理磁盘上（顺序写入） 再将数据同步到磁盘中（随机 IO） 🗂️ 自适应哈希索引 InnoDB 存储引擎会自动根据访问的频率和模式给热点数据建立一个 Hash 索引，加快读请求。\n只能为等值查询建立，范围查询不能建立。\n📖 预读机制 InnoDB 会将查询页的邻近页一起读到 Buffer Pool 中。\n通过改进的 LRU 链表（管理干净页 \u0026amp; 脏页的链表），解决了预读失效的问题。。\n","date":"2022-07-01T13:01:02+08:00","image":"https://emerywan.github.io/blog/p/mysql/innodb/innodb_hu8ff343fd1b5043b6585fcd032816a519_42672_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://emerywan.github.io/blog/p/mysql/innodb/","title":"InnoDB 存储引擎"},{"content":"🖥️ Server 层日志 错误日志 错误日志是 MySQL 中最重要的日志之一，它记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。\n当数据库出现任何故障导致无法正常使用时，建议首先查看此日志。查看日志位置：\n1 show variables like \u0026#39;%log_error%\u0026#39;; 查询日志 查询日志中记录了客户端的所有操作语句。（binlog 不包含查询数据的 SQL 语句）\n默认情况下，查询日志是未开启的。\n如果需要开启查询日志，可以修改MySQL的配置文件 /etc/my.cnf 文件，添加如下内容：\n1 2 3 4 5 6 7 # 该选项用来开启查询日志 # 可选值 0 关闭 1 开启 general_log=1 # 设置日志的文件名 # 如果没有指定，默认的文件名为 host_name.log general_log_file=mysql_query.log 开启了查询日志之后，/var/lib/mysql/ 目录下就会出现 mysql_query.log 文件。\n所有的客户端的增删改查操作都会记录在该日志文件之中，长时间运行后，该日志文件将会非常大。\n慢查询日志 慢查询日志记录了：\n执行时间超过 long_query_time 扫描记录数大于 min_examined_row_limit 的所有的SQL语句的日志，默认未开启。 如果需要开启慢查询日志，需要在 MySQL 的配置文件 /etc/my.cnf 中配置如下参数：\n1 2 3 4 5 # 慢查询日志 slow_query_log=1 # 执行时间参数 long_query_time=2 默认情况下，不会记录管理语句，也不会记录不使用索引进行查找的查询。\n1 2 3 4 5 # 记录执行较慢的管理语句 log_slow_admin_statements=1 # 记录执行较慢的未使用索引的语句 log_queries_not_using_indexes= 1 🔢 bin log 二进制日志（bin log）是记录了所有的数据库表结构变更（DDL）和表数据修改（DML）的日志。\n作用：\n数据归档 灾难时数据恢复 MySQL 主从复制 1 show variables like \u0026#39;%log_bin%\u0026#39;; log_bin_basename\n当前数据库服务器的binlog日志的基础名称(前缀)，具体的binlog文件名需要再该basename的基础上加上编号(编号从000001开始)。 log_bin_index\nbinlog的索引文件，里面记录了当前服务器关联的binlog文件有哪些。 binlog 格式 MySQL 服务器中提供了多种格式来记录二进制日志：\n配置二进制日志的格式，只需要在 /etc/my.cnf 中配置 binlog_format 参数即可。\n📃 statement\n基于 SQL 语句的日志记录，记录的是 SQL 语句，对数据进行修改的 SQL 都会记录在日志文件中。 📕 row （默认）\n基于行的日志记录，记录的是每一行的数据变更。 🖇️ mixed\n混合了 statememt 和 row 两种格式，默认采用statement，在某些特殊情况下会自动切换为 row 进行记录。 1 show variables like \u0026#39;%binlog_format%\u0026#39;; 查看 bin log 日志是以二进制方式存储的，不能直接读取，需要通过二进制日志查询工具 mysqlbinlog 来查看。\n1 2 3 4 5 6 7 mysqlbinlog [参数] logfilename 参数选项： -d 指定数据库名称，只列出指定的数据库相关操作 -o 忽略掉日志中的前 n 行命令 -v 将行事件(数据变更)重构为SQL语句 -vv 将行事件(数据变更)重构为SQL语句，并输出注释信息 清理 bin log reset master\n删除全部 binlog 日志，删除之后，日志编号，将从 binlog.000001重新开始 purge master logs to 'binlog.000005'\n删除 000005 之前的所有日志 purge master logs before 'yyyy-mm-dd hh24:mi:ss'\n删除日志为 \u0026ldquo;yyyy-mm-dd hh24:mi:ss\u0026rdquo; 之前产生的所有日志 可以在 mysql 的配置文件中配置二进制日志的过期时间，设置了之后，二进制日志过期会自动删除。\n1 show variables like \u0026#39;%binlog_expire_logs_seconds%\u0026#39;; 💽 InooDB 存储引擎日志 ⏱️ redo log 重做日志 MySQL 更新数据操作的都是 Buffer Pool 内存中的缓存页，被修改过的脏页不会立即被刷新到磁盘中（随机磁盘 IO 性能低），为了防止断电等情况造成内存中的数据丢失，利用 redo log 记录数据页的更新操作，后续在合适的时间再修改磁盘中的数据。（WAL 技术）\nredo log 是物理日志，记录了数据页做了什么修改。例如：对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了 AAA 更新。\nredo log 记录了事务完成后的数据状态，当事务提交时，只要将 redo log 持久化到硬盘即可（顺序磁盘 IO），不需要将 Buffer Pool 中的脏页持久化到硬盘（随机磁盘 IO）。\n保证了事务 ACID 特性中的持久性，当数据库发生故障时，可以利用 redo log 恢复数据。\n🔃 redo log 循环写 redo log 是为了防止 Buffer Pool 中的脏页丢失而设计的。当随着服务的运行，Buffer Pool 中的脏页刷新到了磁盘中，redo log 中的记录就没有用了，可以擦除旧记录。\n所以 redo log 采用了循环写的方式，数据写到末尾又会回到文件的开头，新数据可以覆盖无用的旧数据。\n刷盘 产生的 redo log 并不是直接写入磁盘的，会先写到 redo log buffer 中，后续再持久化到磁盘。\nredo log buffer 默认大小为 innodb_log_Buffer_size = 16MB，增加它的大小，可以让 MySQL 处理大事务不必写入到磁盘，进而提升 IO 性能。\nredo log buffer 刷盘时机：\nInnoDB 的后台线程，每隔 1s，会将 redo log buffer 持久化到磁盘\nredo log buffer 中记录的写入量大于设置空间的一半时\nMySQL 正常关闭时\n每次事务提交时，将 redo log buffer 中 redo log 持久化到磁盘 innodb_flush_log_at_trx_commit 控制\n两阶段提交 redo log 和 bin log 持久化到硬盘，是两个独立的操作，可能会出现半成功的状态，导致两份日志之间的逻辑不一致。\n为了避免这个问题，保证两个日志的一致性，使用了”两阶段提交“来解决。把单个事务的提交拆分成了两个阶段：\nPrepare 准备阶段\nCommit 提交阶段\n将 redo log 写入拆成了两个步骤：prepare 和 commit，中间再穿插写入 bin log。\nredo log prepare -\u0026gt; bin log -\u0026gt; redo log commit\n当 bin log 成功持久化到磁盘，就被认为事务已经执行成功（即使 redo log 是 prepare 也没有关系）。\n🔙 undo log 回滚日志 undo log 是一种用于撤销回滚的日志。InnoDB 更新记录前，会将操作前的数据记录的 undo 中，当事务回滚时，利用 undo log 进行回滚。\nundo log 主要用于：\n🎗️ 实现事务回滚，保障事务 ACID 中的原子性\n🎗️ undo log 与 ReadView 配合，实现 MVCC\n在 InnoDB 存储引擎对记录进行修改时，会把回滚需要的信息全部记录到 undo 中，如果发生回滚，就会读取 undo log，然后执行与之相反的操作。\n➕ 插入数据，记录这条数据的主键，回滚时根据主键把该条记录删除\n➖ 删除数据，记录这条数据的所有内容，回滚时将这些内容组成的记录插入表中\n🖋️ 更新数据，\n更新了主键，会记录两条 undo log，一条删除的，一条更新的 没有更新主键，记录这条数据更新列的旧值，回滚时将数据更新为旧值 版本链 一条记录的每次更新操作产生的 undo log 格式都会有：\ntrx_id 事务 id\n记录了该记录是由哪一个事务修改的。\nroll_pointer 回滚指针\n回滚指针可以将 undo log 串连成一个链表，这个链表称为版本链。\n","date":"2022-06-30T18:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/19.jpeg","permalink":"https://emerywan.github.io/blog/p/mysql/log/","title":"MySQL 中的日志"},{"content":"索引 索引（index）是帮助 MySQL 高效获取数据的数据结构，提高查询效率。\n优点\n提高数据的查询速度 降低数据库的 IO 成本 缺点\n占用磁盘空间 增删改需要维护索引，性能可能会下降 索引的分类 1 2 -- 查看表中的索引 show index from table_name; 主键索引 当一张表，把某个列设为主键的时候，则该列就是主键索引。\n1 2 3 create table demo ( id int primary key auto_increment ); 普通索引 用表中的普通列构建的索引，没有任何限制。\n1 2 3 4 5 6 7 8 9 create table demo ( id int primary key auto_increment, name varchar(128), index demo_index_name(name) ); --- create index demo_index_name on demo_table(name); 唯一索引 索引列的值必须唯一，允许有多个空值 null（和主键不同，主键不允许为空）。\n1 2 3 4 5 6 7 8 9 create table demo ( id int primary key auto_increment, name varchar(128), unique index new_unique_index_name(name) ); --- create unique index new_unique_index_name on demo_table(name); 全文索引 1 2 3 4 5 6 create table demo ( id int primary key auto_increment, name varchar(128), content text, fulltext index demo_fulltext_index_content(content) ); 组合索引 组合索引 / 联合索引\n1 create index demo_name_age_index on demo(name, age); 聚簇索引 索引和数据放在一起，索引结构的叶子节点保存了行数据，找到了索引就找到了数据。\n访问数据更快，聚簇索引将索引和数据保存在一个B+树上。\n插入速度严重依赖于插入顺序。\n更新聚簇索引列的代价很高。\n非聚簇索引（二级索引） 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键。\n二级索引访问需要两次索引查找，要回表。 索引的结构 B Tree B 树是一种多叉平衡查找树，其主要特点：\n树的节点中存储着多个元素，每个内节点有多个分叉。\n在所有的节点都储存数据。每个节点中包含键值和数据，节点中的键值从小到大排列。\n父节点当中的元素不会出现在子节点中。\n所有的叶子结点都位于同一层，叶节点具有相同的深度，叶节点之间没有指针连接。\nB+ Tree B+ 树是 B 树的升级版。B+ 树在结构上和B树的区别在于：\n只有叶子节点才会存储数据，非叶子节点只存储键值，用于查找。\n叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表。\n叶子节点保存了父节点所有关键字记录的指针。\n相比与 B 树，B+ 树有以下提升：\n扫表能力更强（进行全表扫描，只需要遍历叶子节点即可）\n具有更好的磁盘读写能力（非叶子节点不存储数据，使树更矮，IO 操作更少，一次磁盘加载扫描范围更大）\n查询效率稳定（数据都存储在叶子节点，IO 次数稳定）\n增删数据效率更高（数据在叶子节点以有序链表存储，可提高数据增删效率）\n数据库中，B+ 树的高度一般都在 2~4 层。由于 MySQL 的 INNODB 引擎在设计时是将 B+ 树的根节点常驻内存的，因此在查找某一键值的行记录时，最多只需要 1~3 次磁盘IO。\nHash 支持 hash 索引的是 Memory 存储引擎。采用一定的 hash 算法，将键值换算成新的 hash 值，映射到对应的槽位上，然后存储在 hash 表中。\n特点：\n只能用于对等比较（=, in），不支持范围查询（between, \u0026gt;, \u0026lt;） 无法利用索引完成排序操作 查询效率高，通常只需要一次检索（无 hash 冲突的情况） 创建索引的原则 🙆 建议创建索引 ✅ select 语句，频繁作为 where 条件的字段 1 2 3 4 5 6 7 8 select * from employees where first_name=\u0026#34;Georgi\u0026#34;; -- index(first_name) select * from employees where first_name=\u0026#34;Georgi\u0026#34; and last_name=\u0026#34;Cools\u0026#34;; -- 联合索引 -- index(first_name, last_name) -- 注意满足：最左前缀原则 -- index(last_name, first_name) -\u0026gt; where first_name=\u0026#34;Georgi\u0026#34; 无法使用索引 ✅ update/delete 语句的 where 条件 1 2 3 update employees set first_name=\u0026#34;Jim\u0026#34; where emp_no=\u0026#34;100001\u0026#34;; delete from employees where fitst_name=\u0026#34;Georgi\u0026#34;; ✅ 需要分组，排序的字段 1 select dept_no, count(*) from dept_emp group by dept_no; ✅ 使用 distinct 的字段 1 select distinct(first_name) from employees; ✅ 字段需要唯一性约束\n唯一索引 主键索引 ✅ 多表查询，连接字段应创建索引\n类型务必保持一致，避免隐式装换 1 2 3 4 5 6 7 select emp.*, d.dept_name from employees emp left join dept_emp de on emp.emp_no=de.emp_no left join departments d on de.dept_no=d.dept_no where de.emp_no=\u0026#34;100001\u0026#34;; -- employees.emp_no dept_emp.emp_no 类型务必保持一致 -- dept_emp.dept_no departmants.dept_no 类型务必保持一致 🙅 不建议创建索引 ❌ where 子句中用不到的字段\n索引的作用是快速定位到想要的数据，用不到就没有必要创建数据了。\n❌ 表里的记录非常少\n如只有 100 条数据，有无影响不大。\n❌ 有大量重复数据，选择性低\n如：性别字段，导致大量回表。\n索引的选择性越高，查询效率越好，可以在查找过程中过滤更多的行\n❌ 频繁更新的字段，创建索引要考虑维护索引的开销\n频繁修改的字段，不推荐创建索引。\n索引失效与解决方案 是否使用索引取决于 🚀 查询代价\n即使可以使用索引时，但 MySQL 评估后，不如全表扫描，会放弃使用索引\n⚠️ 索引列不独立，进行了计算或变成了参数 索引字段进行了表达式计算 1 2 3 explain select * form employees where emp_no + 1 = 100003 应事先计算好表达式的值，再传入，避免在 SQL where 的左侧做计算。\n索引字段是函数的参数 1 2 3 4 explain select * from employees where substring(fitst_name, 1, 2) = \u0026#34;Geo\u0026#34;; 事先计算好再传入。\n或者使用一些等价的 SQL。\n1 2 3 4 5 6 explain select * from employees where first_name list \u0026#34;Geo%\u0026#34;; -- first_name 需要是索引的情况下有效（根据实际场景） -- 注意 like 索引失效的情况 ⚠️ 使用了左模糊 1 2 3 4 5 6 7 explain select * from employees where first_name like \u0026#34;%Geo%\u0026#34;; -- 无法使用索引 explain select * from employee where first_name like \u0026#34;Geo%\u0026#34;; -- 可以使用索引 如果无法避免，且有较高需求，可以考虑使用搜索引擎。\n⚠️ or 查询的部分字段没有索引 or 的含义是两个条件满足一个即可，所以只有一个条件列有索引是无用的。只要条件列中有一个不是索引列，就会进行全表扫描。\n1 2 3 4 5 explain select * from employees where first_name=\u0026#34;Georgi\u0026#34; or last_name=\u0026#34;Georgi\u0026#34;; -- 假设当前 first_name 有索引，last_name 没有索引，该条 sql 无法使用索引 -- index(fitst_name) 解决：根据实际业务，添加相应的索引。\n添加索引后，避免了全表扫描。\n⚠️ 不符合最左前缀原则的查询 1 2 3 4 explain select * from employees where first_name=\u0026#34;Facello\u0026#34;; -- index(last_name, first_name) 1 2 3 4 5 explain select * from employees where first_name=\u0026#34;Facello\u0026#34;; -- 更换索引顺序 -- index(first_name, last_name) 1 2 3 4 select * from employees where last_name=\u0026#34;\u0026#34; and first_name=\u0026#34;\u0026#34; -- index(first_name, last_name) -- MySQL 的引擎为更好利用复合索引，会动态调整字段顺序 ⚠️ 字符串条件没有使用 \u0026quot;\u0026quot; 1 2 3 explain select * from dept_emp where dept_no=3; -- 这里 dept_no 在数据库定义为 varchar ⚠️ 隐式转换导致索引失效 1 2 3 4 5 6 7 select emp.*, d.dept_name from employees emp left join dept_emp de on emp.emp_no=de.emp_no left join departments d on de.dept_no=d.dept_no where de.emp_no=\u0026#34;100001\u0026#34;; -- employees.emp_no dept_emp.emp_no 类型不一致时会导致隐式转换 -- dept_emp de departments.dept_no 类型不一致时会导致隐式转换 null 条件查询 查询时，采用 is null is not null 条件，根据表中的数据分布，MySQL 会自行判断是否走索引，并不固定\nMySQL 官方建议尽量把字段定义为 NOT NULL\n1 2 3 explain select * from users where mobile is null; MySQL 评估全表扫描更快 MySQL 在查询时，会评估使用索引的效率与走全表扫描的效率，如果走全表扫描更快，则放弃索引，走全表扫描。\n因为索引是用来索引少量数据的，如果通过索引查询返回大批量的数据，则还不如走全表扫描来的快，此时索引就会失效。\n最左前缀法则 最左前缀法则指的是查询从索引的最左列开始，并且不跳过索引中的列。\n如果跳跃某一列，索引将会部分失效(后面的字段索引失效)。\n中间不能跳过某一列，否则该列后面的字段索引将失效。\n范围查询 联合索引中，出现范围查询(\u0026gt;, \u0026lt;)，范围查询右侧的列索引失效。\n覆盖索引 对于索引 X，SELECT 的字段只需要从索引中就能获得，而无需回表获取。\n1 2 3 4 -- index(name, age, pos) select pos from staffs where name=\u0026#34;July\u0026#34; and age=14; 前缀索引 当字段类型为字符串（varchar，text，longtext等）时，有时候需要索引很长的字符串，这会让 索引变得很大，查询时，浪费大量的磁盘 IO， 影响查询效率。\n可以只将字符串的一部分前缀，建立索引，这样可以大大节约索引空间，从而提高索引效率。\n1 2 -- 为 email 字段，建立索引长度为 5 的前缀索引 create index index_email_5 on tb_user(email(5)); explain 查看 SQL 语句的执行计划。字段含义：\nid\n在一个大的查询语句中，每个 select 关键字都对应一个唯一 id id 相同，执行顺序从上到下；id 不同，值越大，越先执行 select_type\n表示 select 对应的查询类型 SIMPLE (简单 select,不使用 union 或子查询等) PRIMARY (查询中若包含任何复杂的子部分,最外层的 select 被标记为 PRIMARY) UNION (union 中的第二个或后面的 select 语句) SUBQUERY (子查询中的第一个 select) table\n这一行的数据是关于哪张表 type\nMySQL 在表中找到所需行的方式 性能由好到差的连接类型为：NULL、system、const、eq_ref）、ref、range、index、all（全表扫描） possible_keys\n可能应用在这张表上的索引 key\n实际使用的索引，如果为 NULL，则没有使用索引 key_len\n实际使用索引的长度（该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下，长度越短越好） ref\n上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 rows\nMySQL 认为必须要执行查询的行数，在 innodb 引擎的表中，是一个估计值，不是准确的 Extra\nMySQL解决查询的详细信息 参考 https://juejin.cn/post/6936032090546765837 ","date":"2022-06-30T14:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/15.jpeg","permalink":"https://emerywan.github.io/blog/p/mysql/index/","title":"MySQL 索引"},{"content":"Linux 是一个开源的系统，使得 Linux 发行版本有很多，利用 Linux 开发产品的团队也有很多，如果任由每个人都按照自己的想法来配置 Linux 系统文件目录，后期可能会产生诸多的管理问题。\n为了避免诸多使用者对 Linux 系统目录结构天马行空，Linux 基金会发布了 FHS 标准。多数 Linux 发行版系统都遵循这一标准。\nFHS（Filesystem Hierarchy Standard），文件系统层次化标准，该标准规定了 Linux 系统中所有一级目录以及部分二级目录（/usr 和 /var）的用途。发布此标准的主要目的就是为了让用户清楚地了解每个目录应该存放什么类型的文件。\n几乎所有的 Linux 发行版都包含以下的目录结构：\n不同的发行版可能会添加一下独有的目录，例如 Ubuntu 中包含 /snap 来放置 snap 应用。\n/bin Binary\n二进制可执行文件和可执行文件的快捷方式（软链接），存放着常用的命令。\n例如常用的 ls cp cd 等命令都存放在这里。\n/boot 启动 Linux 时使用的一些核心文件，包括一些连接文件以及镜像文件。\n如果是以 UEFI 方式安装的系统，其中 efi 文件夹中的为 EFI 分区中的引导。\n/dev Device\n存放着所有的设备文件。在 Linux 中，所有东西都是以文件的形式存在的，包括硬件设备。\n/etc Etcetera\n存放程序的配置信息，大多数安装的应用配置信息都会在这里。\n例如：\n/etc/apt apt 源配置目录 /ect/vim vim 配置目录 /etc/nginx nginx 配置目录 /ect/redis redis 配置目录 /home 用户的主目录。\n在 Linux 中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名。\n/lib Library\n系统最基本的动态连接共享库，其作用类似于 Windows 里的 DLL 文件。\n几乎所有的应用程序都需要用到这些共享库。包含 bin 和 sbin 中可执行文件的依赖。\n/media 自动挂载的设备，比如 U 盘，移动硬盘，网络设备等的目录。\n比如现在有一个 U 盘，插到电脑上之后，系统会把 U 盘自动挂载到 /media/$USER 文件夹中。\n/mnt 提供给用户临时手动挂载设备文件夹，一般是空文件夹。\n比如现在要手动挂载一个硬盘，可用如下挂载到 /mnt：\n1 mount /dev/sdb1 /mnt/disk /opt Optional\n一些第三方软件安装的目录。\n比如 Chrome 浏览器，WPS 等软件，都会安装在这里。\n/root 这是 root 用户的家目录。\n/proc Processes\n/proc 是一种伪文件系统（也即虚拟文件系统），存储的是当前内核运行状态的一系列特殊文件，这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。\n/proc 里面有一大堆数字命名的文件夹，这个数字其实是 Process ID（PID），对应着运行的服务。\n/sbin Superuser Binaries\n这里存放的是系统管理员使用的系统管理程序。\n例如常见的 groupadd groupdel。\n/srv Service\n主要用来存放服务数据。对于桌面版 Linux 系统，这个文件夹一般是空的，但是对于 Linux 服务器，Web 服务或者 FTP 文件服务的资源可以存放在这里。\n/tmp Temporary\n存储一些程序的临时文件。\n临时文件可能起到很重要的作用。比如有时候 Word 文档崩溃了，好不容易写的东西全没了，Linux 的很多文本编辑器都会在 /tmp 放一份当前文本的 copy 作为临时文件，如果你的编辑器意外崩溃，有机会在 /tmp 找一找临时文件抢救一下。\n/usr Unix Shared Resources\n共享资源，这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于 windows 下的 program files 目录。\n/usr/bin /usr/sbin 系统用户 / 超级管理员 使用的应用程序。\n在 Ubuntu 中，/bin /sbin 其实就是 /usr/bin /usr/sbin 的一个链接。\n/usr/src 内核源代码默认的放置目录。\n/usr/lib 包含所有那些用户不能直接执行的库文件。包含着所有 \u0026lsquo;/usr/bin\u0026rsquo; 和 \u0026lsquo;/usr/sbin\u0026rsquo; 目录中可执行命令程序需调用的二进制库文件。\n例如使用 apt 安装 openjdk 的目录在 /usr/lib/jvm。\n/usr/share 包含独立于架构的共享数据。\n例如系统桌面图标目录 /user/share/applications。\n/usr/local 用于本地安装软件的目标目录。从源代码安装的用户程序都将安装到这里。\n/var Variable\n存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。\n例如日志文件。\n参考 https://segmentfault.com/a/1190000038497705 https://www.runoob.com/linux/linux-system-contents.html ","date":"2022-06-23T02:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/10.jpeg","permalink":"https://emerywan.github.io/blog/p/linux-dir/","title":"Linux 目录结构介绍"},{"content":"创建数据库 1 2 3 create database test; use test; 创建表 1 2 3 4 5 6 7 create table mytable ( id int not null auto_increment, col1 int not null default 1, col2 varchar(45) null, col3 date null, primary key (`id`) ); 修改表 1 2 3 alter table mytable add col char(20); alter table mytable drop column col; 删除表 1 drop table mytable; 插入信息 1 insert into mytable(col1, col2) values (\u0026#34;val1\u0026#34;, \u0026#34;val2\u0026#34;); 更新信息 1 update mytable set col=val where id=1; 删除信息 1 delete from mytable where id=1; 查询 distinct 去重\n1 2 select distinct col1, col2 from mytable; limit 限制返回的行数\n1 2 3 4 5 6 7 8 -- 返回前5行 select * from mytable limit 5; select * from mytable limit 0, 5; -- 返回 3-5 行 -- offset:2, limit:3 跳过2行取3个结果 select * from mytable limit 2, 3; select * from mytable limit 3 offset 2; asc 升序（默认）\n1 select * from mytable order by col1 asc; desc 降序\n1 select * from mytable order by col2 desc; 过滤 where\n= 等于\n\u0026lt; 小于\n\u0026gt; 大于\n!= 不等于\n\u0026lt;= 小于等于\n\u0026gt;= 大于等于\nbetween \u0026hellip; and \u0026hellip; 两个值之间（左闭右闭区间）\nis null 空值\nand\nor\nin\nnot\n1 select * from mytable where col is null; 通配符 % 匹配 \u0026gt;= 0 个字符 _ 匹配一个字符 [] 匹配集合内中的任一字符 [^] 不匹配集合内的任一字符 1 2 3 4 5 6 -- 不以 A B 开头的任意文本 select * from mytable where col like \u0026#39;[^AB]%\u0026#39;; -- 学号的最后一位不是2、3、5的学生信息 select * from 学生表 where 学号 like \u0026#39;%[^235]\u0026#39;; -- 查询学生表中姓 张、李、刘 的学生的情况。 select * from 学生表 where 姓名 like \u0026#39;[张李刘]%\u0026#39;; 分组 GROUP BY\n把具有相同的数据值的行，放在同一组中。\n可以对同一分组数据，使用汇总函数进行处理，例如求分组数据的平均值。\n指定的分组字段，处理能按字段进行分组，也会自动按该字段进行排序。\nHAVING 过滤分组。\n子查询 子查询只能返回一个字段的数据。可以将子查询的结果作为 where 语句的过滤条件。\n1 2 3 4 5 6 select * from mytable1 where col in (select col2 from mytable2) select cust_name, (select count(*) from orders where orders.cust_id = customers.cust_id as corder_num) from customers order by cust_name; 连接 把两个或多个表的行结合起来\nJOIN / INNER JOIN 表中存在至少一个匹配时返回行。\n1 2 3 4 5 6 7 8 9 select website.id, website.name, access_log.count, access_log.data from website inner join access_log on website.id = access_log.site_id; --- inner join 和 join 是一样的 select website.id, website.name, access_log.count, access_log.data from website join access_log on website.id = access_log.site_id; LEFT JOIN 从 左表 返回所有的行，即使右表中没有匹配。（没有匹配显示结果为 null）\n1 2 3 4 5 6 -- 返回所有的网站及他们的访问量（如果有的话） -- 将 website 作为左表，access_log 作为右表 select website.name, access_log.count, access_log.date from website left join access_log on website.id = access_log.site_id order by access_log.count desc; RIGHT JOIN 从右表返回所有的行，即使坐标没有匹配。（左表没有匹配显示结果为 null）\n1 2 3 4 5 6 -- 返回所有网站的访问记录 -- 在左表中没有记录，也会显示 null select website.name, access_log.count, access_log.date from website right join access_log on access_log.site_id = website.id order by access_log.count desc; FULL JOIN（不支持） （MySQL 不支持，使用 union 拼接）\n全连接。 只要左表，右表，其中一个表存在匹配，则返回行。\n1 2 3 4 select website.name, access_log.count, access_log.date from website full join on website.is = access_log.site_id on website.id = access_log.site_id order by access_log.count desc; 自连接 1 2 3 4 5 6 7 8 9 10 11 -- 找出与 jim 处在同一部门的所有员工的姓名 select name from employee where department = ( select department from employee where name=\u0026#34;jim\u0026#34; ); -- select e1.name from employee as e1 inner join employee as e2 on e1.department = e2.department and e2.name = \u0026#34;jim\u0026#34;; 组合 union 组合两个查询。每个查询必须包含相同的列，表达式和聚集函数。\n默认去除相同的行，如果需要保留相同的行，使用 union all。\n1 2 3 select col from mytable where col=1 union select col from mytable where col=2; 函数 计算字段 avg() 平均值（会忽略 null 行） round() round(x) 四舍五入；round(x, n) 保留 n 位小数 count() 返回某列的行数 max() 返回某列的最大值 min() 返回某列的最小值 sum() 某列之和 文本处理 left() 左边的字符 right() 右边的字符 lower() 转换成小写 upper() 转换成大写 ltrem() 去除左边的空格 rtrem() 去除右边的空格 length() 长度 soundex() 转换成语音值 条件函数 if(expr, v1, v2) expr 成立，返回结果 v1，否则返回 v2。\n1 2 3 4 5 6 7 8 9 -- SELECT IF(1 \u0026gt; 0,\u0026#39;正确\u0026#39;,\u0026#39;错误\u0026#39;) -- -\u0026gt;正确 -- -- -- 将用户划分为25岁以下和25岁及以上两个年龄段，分别查看这两个年龄段用户数量 select if (age\u0026gt;=25, \u0026#39;25岁及以上\u0026#39;, \u0026#39;25岁以下\u0026#39;) as age_info, count(*) from user_profile group by age_info; ifnull(v1, v2) v1 的值不为 null，返回 v1，否则返回 v2。\n1 2 3 4 5 6 7 8 9 select ifnull( ( select distinct salary from Employee order by salary desc limit 1, 1 ) , null ) as SecondHighestSalary; case 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 -- 将用户划分为25岁以下和25岁及以上两个年龄段，分别查看这两个年龄段用户数量 select ( case when age\u0026gt;=25 then \u0026#34;25岁及以上\u0026#34; else \u0026#34;25岁以下\u0026#34; end ) as age_info, count(*) as number from user_profile group by age_info ; -- 将用户划分为20岁以下，20-24岁，25岁及以上三个年龄段，分别查看不同年龄段用户的明细情况 select device_id, gender, ( case when age\u0026lt;20 then \u0026#34;20岁以下\u0026#34; when age\u0026gt;=20 and age\u0026lt;=24 then \u0026#34;20-24岁\u0026#34; when age\u0026gt;=25 then \u0026#34;25岁及以上\u0026#34; else \u0026#34;其他\u0026#34; end ) as age_cut from user_profile ; 1 2 3 4 5 6 7 update Salary set sex=( case set when \u0026#39;m\u0026#39; then \u0026#39;f\u0026#39; then \u0026#39;f\u0026#39; end ); ","date":"2022-06-01T18:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/29.jpeg","permalink":"https://emerywan.github.io/blog/p/mysql/sql-base/","title":"数据库基础总结"},{"content":"Redis 提供了丰富的数据类型，常见的有五种：\nString 字符串 List 列表 Hash 哈希 Set 集合 Zset 有序集合 随着 Redis 版本的更新，后面又支持了四种数据类型：\nBitMap (2.2) HyperLogLog (2.8) GEO (3.2) Stream (5.0) 在线 Redis 体验 → https://try.redis.io/\n🦮 String String 是最基本的 key-value 结构。key 是唯一标识（可以是字符串、数字），value 是具体的值（最长可以容纳 521M）。\n🎗️ 常用命令 🧩 基本操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 设置 set name emery # 获取 get name # 判断 key 是否存在 exists name # 获取字符串的长度 strlen name # 删除 del name 🧩 批量设置 1 2 3 4 5 # 批量设置 k-v mset key1 value1 key2 value2 # 批量获取 k-v mget key1 key2 🧩 计数器（value 为整数） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 设置 set num 0 # +1 incr num # +10 incrby num 10 # -1 decr num # -10 decrby num 10 🧩 过期（默认为永不过期） 1 2 3 4 5 6 7 8 9 10 11 # 添加并设置过期时间 ex-\u0026gt;秒 px-\u0026gt;毫秒 set name emery ex 60 # 对已存在的 key 设置过期 expire name 60 # 查看过期时间 ttl name # 移除过期时间（无过期时间 ttl 返回 -1） persist name 🧩 存在与不存在 1 2 3 4 5 # key 不存在才成功 set name emery nx # key 存在才成功 set name emery xx 🎡 实现方式 String 的底层实现是自定义的 SDS（简单动态字符串）。\n相比于 C 语言的字符串：\nSDS 不仅可以保存文本，还可以保存二进制数据（如图片、音频、视频等）。 SDS 的 API 都会一处理二进制的方式处理保存在 buf[] 数组中的数据。\nSDS 获取字符串长度的时间复杂度是 O(1)。 C 语言的字符串不会记录自身长度，获取需要遍历，时间复杂度为 O(n)。SDS 结构中记录了长度。\nSDS 的 API 是安全的，拼接字符串不会导致缓冲区溢出。 SDS 在拼接前会检查空间是否满足要求，不够的话会自动扩容。\n🧵 使用场景 📐 缓存对象\n直接缓存 JSON。 SET user:1 '{\u0026quot;name\u0026quot;:\u0026quot;emery\u0026quot;, \u0026quot;age\u0026quot;:18}' 分离为 user:id 作为 key，用 mset 存储。 MSET user:1:name emery user:1:age 18 user:2:name lin user:2:age 20 📐 常规计数\nRedis 处理命令是单线程的，所以执行命令的过程是原子的。可以对访问访问次数、点赞、转发、库存数量进行统计。\n1 2 3 4 set aritcle:readcount:1001 0 # 原子操作 incr aritcle:readcount:1001 📐 分布式锁 NX 参数可以实现在 key 存在的时候，才插入数据，可以用来实现分布式锁。\n1 2 3 4 5 # lock_key 分布式锁的 key # unique_value 客户端生成的唯一标识 # NX 在 lock_key 不存在时，才进行操作 # PX 毫秒 10000ms -\u0026gt; 10s set lock_key unique_value NX PX 10000 📐 共享 session 信息 Session 保存在服务端，通常用于保存用户的会话状态（登录）。\n在分布式系统中，用户多次请求不一定都在同一台服务器中，我们可以借助 Redis 对 Session 信息进行统一的存储和管理，服务器都去同一个 Redis 获取相关的 Session 信息，这样就解决了分布式系统下 Session 存储的问题。\n🐅 List List 是简单的字符串列表，按照插入顺序排序，可以从头部或尾部向 List 中添加元素。最大长度为 2^32 - 1。\n🎗️ 常用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 插入 lpush key value rpush key value # 移除 lpop key rpop key # 返回指定区间内的元素（从 0 开始） lrange key start end # 弹出一个元素，并阻塞 timeout 秒（当 timeout=0 就一直阻塞） blpop key timeout brpop key timeout 🎡 实现方式 Redis List 底层由（1）压缩列表 或 （2）双向链表 实现。\n压缩列表：\n如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置）， 列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置）， Redis 会使用压缩列表作为 List 类型的底层数据结构。 双向列表：不满足压缩列表的条件底层就会使用双向列表。\n压缩列表\n是 Reids 为了节约内存而开发的，由连续内存块组成的顺序型数据结构，有点类型于数组。\n在表头有三个字段： （1）zlbytes：压缩列表占用的内存字节数； （2）zltail：列表尾的偏移量（尾部距离首部有多少个字节）； （3）zllen：压缩列表包含的节点数量；\n在表尾有一个字段： （4）zlend：列表结束的标志（固定值 0xFF -\u0026gt; 255）；\n查找定位第一个和最后一个元素的时间复杂度为：O(1) 查找其他元素，只能逐个查找，O(n)，所以压缩列表不适合保存过多的元素。\n在 Redis中，List、Hash、Zset 对象，在元素数量较少，元素值不大时，会使用压缩列表作为底层数据结构。\n🧵 使用场景 📐 消息队列 🦛 Hash Hash 是一个键值对的集合 key-value，特别适合存储对象。\n🎗️ 常用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 存储一个 key=people 的哈希表 hset people name \u0026#34;Emery\u0026#34; # 获取哈希表中的值 hget people name # 存储多个键值对 hmset people name \u0026#34;Emery\u0026#34; age 18 # 批量获取键值对 hmget people name age # 删除一个哈希表 hdel people # 获得哈希表中key-value对的数量 hlen people # 获取哈希表中所有的 key hgetall people 🎡 实现方式 Hash 类型的底层数据结构由 （1）压缩列表 或 （2）哈希表 实现。\n压缩列表\n元素小于 512 个 所有的值小于 64 字节 使用压缩列表 哈希表\n不满足以上条件使用 hash 表 🧵 使用场景 📐 缓存对象 1 2 3 4 hmset uid:10001 name Tom age 15 hmset uid:10002 name Jerry age 13 hmget uid:10001 使用 String 类型缓存 JSON 也是缓存对象的一种凡是，如果对象中某些属性频繁变化，可以考虑使用 Hash。\n🛒 购物车 😃 用户 id -\u0026gt; key 🏪 商品 id -\u0026gt; field 🔢 商品数量 -\u0026gt; value 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 添加商品 cart:{用户id} {商品id} 1 hset cart:10001 22223 1 # 添加数量 hincrby cart:10001 22223 1 # 获得商品数量 hget cart:10001 22223 # 删除商品 hdel cart:10001 22223 # 获取购物车所有商品 hgetall cart:10001 在实际业务中，Redis 中只存储了商品的 id 信息，在回显商品的具体信息时，再拿商品 id 查询一次数据库，获取完整的商品信息。\n🐑 Set Set 是一个无序并唯一的集合（存储顺序不会按照插入的先后顺序进行存储）。\n集合中最多可以存储 2^32 - 1 个元素，除增删改查外，还支持多个集合的交集、并集和差集。\nList 与 Set 的区别：\nList 可以存储重复元素，Set 不可以 List 按照元素添加的顺序存储元素，Set 存储元素是无序的 🎗️ 常用命令 🧩 常用操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 添加元素（已存在则忽略） sadd key value1 [value2 ...] # 删除元素 srem key value1 [value2 ...] # 获取所有的元素 smembers key # 获取集合中的元素个数 scard key # 判断是否存在 sismember key value # 从集合中随机选取 count 个元素，不从中删除 srandmember key [count] # 从集合中随机选取 count 个元素，并删除 spop key [count] 🧩 运算操作 ⚠ Set 的交并差集运算的复杂度较高，在数据量较大时，如果直接执行计算，会导致 Redis 实例阻塞。 在实际中，推荐获取数据后，在客户端去完成计算。\n1 2 3 4 5 6 7 8 9 10 11 12 # 交集 sinter key1 [key2 ...] # 交集并存储 sinterstore destination key1 [key2 ...] # 并集 sunion key1 [key2 ...] sunionstore destination key1 [key2 ...] # 差集 sdiff key1 [key2 ...] sdiffstore destination key1 [key2 ...] 🎡 实现方式 Set 类型的底层数据结构由 （1）哈希表 或 （2）整数集合实现。\n整数集合\n元素个数少于 512 个，底层采用整数集合作为数据结构 哈希表\n不满足以上条件，使用哈希表作为底层数据结构 🧵 使用场景 Set 主要是无续，不可重复，可求交并差的特性。\n📐 点赞 Set 类型可以保证用户只能点一个赞。\nkey -\u0026gt; 文章 id value -\u0026gt; 用户 id 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 文章 1 被 id 为 1、2、3 的用户点赞 sadd article:1 uid:1 sadd article:1 uid:2 sadd article:1 uid:3 # 取消点赞 srem article:1 uid:1 # 获取 文章 1 的点赞用户 id smembers article:1 # 获取 文章 1 的点赞数量 scard article:1 # 判断 用户 1 是否对文章 1 进行了点赞 sismember article:1 uid:1 📐 共同关注 Set 支持交集运算，可以用来计算共同关注的好友，公众号等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 # id 为 1、2 的用户关注的公众号 sadd uid:1 5 6 7 8 9 sadd uid:2 7 8 9 10 11 # 获取共同关注 sinter uid:1 uid:2 # 给 uid:2 推荐 uid:1 关注的公众号 sdiff uid:1 uid:2 # 验证某个公众号是否被同时关注 sismember uid:1 5 # -\u0026gt; 1 关注 sismember uid:2 5 # -\u0026gt; 0 未关注 📐 抽奖活动 key-\u0026gt;活动名，value-\u0026gt;用户名，存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。\n1 2 3 4 5 6 7 8 9 sadd lucky Tom Jerry John Sean Marry Lindy Sary Mark # 抽取 1 个一等奖： srangememeber lucky 1 # 抽取 2 个二等奖： srangememeber lucky 2 # 不允许重复获奖 spop lucky 1 🦥 Zset Zset（有序集合，从小到大） 相比于 Set 类型多了一个排序分值 socre。\n对于有序集合 ZSet 来说，每个存储的元素由两个值组成，一个是有序集合的元素值，一个是排序值。\nZset 中元素不能重复，分数值可以重复，并且可以排序。\n🎗️ 常用命令 🧩 常用操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 向有序集合中加入带分值的元素 zadd key socre number [[score number] ...] # 从有序集合中删除元素 zrem key number [number ...] # 返回有序集合中元素的分数 zscore key number # 返回有序集合中元素的个数 zcard key # 为有序集合中 member 的分值加上 increment zincrby key increment member # 正序获取有序集合中 start-\u0026gt;end 的下表元素 zrange key start end [withscores] # 倒序获取有序集合中 start-\u0026gt;end 的下标元素 zrevrange key start end [withscores] 🎡 实现方式 有序集合 Zset 底层使用 （1）压缩列表 或 （2）跳表 作为数据结构。\n压缩列表：有序集合中元素小于 128 个，并且每个元素的值小于 64 字节时，使用压缩列表作为底层数据结构。\n跳表：不满足上述条件，使用调表。\n🧵 使用场景 📐 排行榜 例如游戏积分排行榜，视频播放排名，电商系统中商品的销量排名。\nkey-\u0026gt;排行榜的类型；member-\u0026gt;需排行的内容（如文章id）；score-\u0026gt;点击数、点赞数等\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # emery 发的id=1的文章获得了 200 个赞 zadd user:emery:ranking 200 arcticle:1 # 给文章 1 点赞 zincrby user:emery:ranking 1 article:1 # 查看某篇文章的点赞数 zscore user:emery:ranking article:1 # 查看点赞数最多的 3 篇文章 zrevrange user:emery:ranking 0 2 withscores # 获取 100 赞到 200 赞的文章 zrangebysocre user:emery:ranking 100 200 withscores 📐 延时队列 利用 score 存储延时执行的时间，使用 zrangebysocre 查询所有符合条件的待处理任务，再进行处理。\n🔗 参考 https://xiaolincoding.com/redis/data_struct/command.html ","date":"2022-06-01T01:52:45+08:00","image":"https://emerywan.github.io/blog/p/redis/data-struct/redis_hu9919f7b3f46635b6673d32d5992520f9_29030_120x120_fill_q75_box_smart1.jpg","permalink":"https://emerywan.github.io/blog/p/redis/data-struct/","title":"Redis 常见数据结构"},{"content":"使用 ZooKeeper 实现 原理 持久节点（红色）\n瞬时节点（黄色）：不可再有子节点，会话结束后瞬时节点会自动消失\n利用 Zookeeper 的瞬时有序节点的特性，多线程并发创建瞬时节点时，得到有序的序列\n序号最小的线程获得锁，其他的线程则监听自己序号的前一个序号；当前一个线程执行完成，删除自己序号的节点；下一个序号的线程得到通知，将继续执行\n创建节点时，已经确定了线程的执行顺序\n实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 public class ZkLock implements AutoCloseable, Watcher { private ZooKeeper zooKeeper; private String znode; // 当前线程创建的路径 public ZkLock(String connectString, int sessionTimeout) throws IOException { this.zooKeeper = new ZooKeeper(connectString, sessionTimeout, this); } /** * try-catch-with-resource */ public void clode() throws Exception { zooKeeper.delete(znode, -1); zooKeeper.close(); log.info(\u0026#34;释放锁\u0026#34;); } /** * 观察器 */ @Override public void process(WatchedEvent watchedEvent) { // 当前一个节点被删除时，可唤醒获取锁的等待，表示当前线程获取了锁 if (watchedEvent.getType() == Event.EventType.NodeDeleted) { synchronized (this) { notify(); } } } /** * 获取锁 */ public boolean getLock(String businessCode) { try { String path = \u0026#34;/\u0026#34; + businessCode; Stat stat = zooKeeper.exists(path, false); if (null == stat) { // 当前业务若没有持久节点 // 先创建一个持久节点，在持久节点里创建瞬时节点 zooKeeper.create( path, businessCode.getBytes(StandardCharsets.UTF_8), ZooDefs.Ids.OPEN_ACL_UNSAFE, // 公开权限，不使用用户名密码就能访问这个节点 CreateMode.PERSISTENT ); } // 创建瞬时有序节点 String subPath = \u0026#34;/\u0026#34; + businessCode + \u0026#34;/\u0026#34; + businessCode + \u0026#34;_\u0026#34;; znode = zooKeeper.create( subPath, businessCode.getBytes(StandardCharsets.UTF_8), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL ); // 获取该业务下的所有瞬时节点，进行比较排序 List\u0026lt;String\u0026gt; childrenNodes = zooKeeper.getChildren(path, false); Collections.sort(childrenNodes); // 如果列表中的第一个是当前创建的节点，直接获取锁 String firstNode = childrenNodes.get(0); if (znode.endsWith(firstNode)) { return true; } // 监听前一个节点，等待获取锁 String lastNode = firstNode; for (String node : childrenNode) { // 找到当前节点，监听前一个节点 if (znode.endWith(node)) { zooKeeper.exists(\u0026#34;/\u0026#34; + businessCode + \u0026#34;/\u0026#34; + lastNode, this); break; } else { lastNode = node; } } synchronized (this) { // 让当前线程阻塞，并且会释放锁 // 上面的同步代码块才会获得锁并执行 notify() wait(); } return true; } catch (KeeperException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } return false; } } 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Slf4j @RestController public class ZkLockController { @GetMapping(\u0026#34;/zkLock\u0026#34;) public String zkLock() { log.info(\u0026#34;进入方法\u0026#34;); try (ZkLock zklock = new ZkLock(\u0026#34;127.0.0.1:2181\u0026#34;, 10000)) { if (zkLock.getLock(\u0026#34;order\u0026#34;)) { log.info(\u0026#34;获取了锁\u0026#34;); try { TimeUtil.SECONDS.sleep(10); // 模拟业务 } catch (InterruptedException e) { e.printStackTrace(); } } log.info(\u0026#34;完成业务\u0026#34;); } catch (Exception e) { e.printStackTrace(); } return \u0026#34;success\u0026#34;; } } Curator 依赖配置 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-recipes\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Slf4j public class DemoTest { @Test public void test() { String zookeeperConnectionString = \u0026#34;127.0.0.1:2181\u0026#34;; RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3); CuratorFramework client = CuratorFrameworkFactory.newClient(zookeeperConnectionString, retryPolicy); client.start(); String lockPath = \u0026#34;/order\u0026#34;; InterProcessMutex lock = new InterProcessMutex(client, lockPath); try { // 获取互斥锁，阻塞直到可用，或给定时间到期 // 同一个线程调用 acquire() 可重入 if (lock.acquire(30, TimeUnit.SECONDS)) { try { log.info(\u0026#34;获取锁\u0026#34;); } finally { // 必须通过 release() 释放锁 lock.release(); } } } catch (Exception e) { e.printStackTrace(); } } } ","date":"2022-05-11T21:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/2.jpeg","permalink":"https://emerywan.github.io/blog/p/distributed/lock/zookeeper/","title":"使用 ZooKeeper 实现分布式锁"},{"content":"Redis NX 实现 利用 NX 的原子性，多个线程并发时，只有一个线程可以设置成功，设置成功即获取了锁。\n如果没有获取锁，不会阻塞当前方法，直接跳过任务。\n获取锁 1 2 # set key unique_value NX PX 30000 set product:stock:clothes UUID NX PX 30000 key 根据不同的业务，区分不同的锁 unique_value 保证每个线程的随机值都不同，用于释放锁时的校验 NX key 不存在时设置成功，key 存在则不成功 PX 自动失效时间。若出现异常，没有主动释放锁，可以保证超时后，锁可以过期失效（毫秒） 释放锁 释放锁将该 key 删除，在释放锁之前需要校验设置的随机数，相同才表示是该线程加的锁，能释放。\n需要采用 LUA 脚本，del 命令没有提供校验值的功能。\nredis 执行命令是按照一条指令完成之后，再执行下一条，用 lua 脚本，能保证 redis 执行完这个脚本才执行下一条，所以能保证判断 和 删除是原子性的\n1 2 3 4 5 if redis.call(\u0026#34;get\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;, KEYS[1]) else return 0 end 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Slf4j @RestController public class RedisLockController { @Autowired private RedisTemplate redisTemplate; @GetMapping(\u0026#34;/redisLock\u0026#34;) public String redisLock() { // 获取分布式锁 Boolean lock = redisTemplate.execute((RedisCallback\u0026lt;Boolean\u0026gt;) redisConnection -\u0026gt; { Expiration expiration = Expiration.seconds(30); // NX RedisStringCommands.SetOption setOption = RedisStringCommands.SetOption.ifAbsent(); // 需要使用 redisTemplate 中的序列化器 byte[] redisKey = redisTemplate.getKeySerializer().serialize(key); byte[] redisValue = redisTemplate.getValueSerializer().serialize(value); return redisConnection.set(redisKey, redisValue, expiration); }); if (lock) { // 获取到了锁 log.info(\u0026#34;获取到了锁\u0026#34;); try { TimeUnit.SECONDS.sleep(15); // 模拟业务处理 } catch (InterruptedException e) { e.printStackTrace(); } finally { String script = \u0026#34;if redis.call(\\\u0026#34;get\\\u0026#34;,KEYS[1])==ARGV[1] then\\n\u0026#34; + \u0026#34;\\treturn redis.call(\\\u0026#34;del\\\u0026#34;,KEYS[1])\\n\u0026#34; + \u0026#34;else\\n\u0026#34; + \u0026#34;\\treturn 0\\n\u0026#34; + \u0026#34;end\u0026#34;; RedisScript\u0026lt;Boolean\u0026gt; redisScript = RedisScript.of(script, Boolean.class); boolean result = redisTemplate.execute(redisScript, Arrays.asList(key), value); log.info(\u0026#34;释放锁 {}\u0026#34;, result); } } log.info(\u0026#34;业务完成\u0026#34;); return \u0026#34;success\u0026#34;; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 @Slf4j @RestController public class RedisLock { private RedisTemplate redisTemplate; // 锁名称，不同业务可能锁不同 private String key; private String value; // 锁过期时间，单位秒 private int expireTime; public RedisLock(RedisTemplate redisTemplate, String key, int expireTime) { this.redisTemplate = redisTemplate; this.key = key; this.expireTime = expireTime; // value 可以不暴露出去，每个线程都是不一样的 this.value = UUID.randomUUID().toString(); } /** * 获取锁 */ public boolean getLock() { // 获取分布式锁 Boolean lock = (Boolean) redisTemplate.execute((RedisCallback\u0026lt;Boolean\u0026gt;) redisConnection -\u0026gt; { Expiration expiration = Expiration.seconds(expireTime); // NX RedisStringCommands.SetOption setOption = RedisStringCommands.SetOption.ifAbsent(); // 由于这里需要接受 byte, 不能暴力的使用 string.getBytes() // 要使用模板里面的 key\\value 序列化器来实现 byte[] redisKey = redisTemplate.getKeySerializer().serialize(key); byte[] redisValue = redisTemplate.getValueSerializer().serialize(value); Boolean result = redisConnection.set(redisKey, redisValue, expiration, setOption); return result; }); return lock; } /** * 释放锁 */ public boolean unLock() { // lua 脚本 String script = \u0026#34;if redis.call(\\\u0026#34;get\\\u0026#34;,KEYS[1])==ARGV[1] then\\n\u0026#34; + \u0026#34;\\treturn redis.call(\\\u0026#34;del\\\u0026#34;,KEYS[1])\\n\u0026#34; + \u0026#34;else\\n\u0026#34; + \u0026#34;\\treturn 0\\n\u0026#34; + \u0026#34;end\u0026#34;; RedisScript\u0026lt;Boolean\u0026gt; redisScript = RedisScript.of(script, Boolean.class); Boolean result = (Boolean) redisTemplate.execute(redisScript, Arrays.asList(key), value); return result; } } Redisson 依赖配置 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Slf4j @RestController public class RedissonLockController { @Autowired private RedissonClient redissonClient; @GetMapping(\u0026#34;/redissonLock\u0026#34;) public String redissonLock() { log.info(\u0026#34;执行方法\u0026#34;); final String key = \u0026#34;redisson\u0026#34;; RLock lock = redissonClient.getLock(key); // 锁超时时间，如果未获得锁，会阻塞等待获取到锁（-1 表示没有超时时间） lock.lock(30, TimeUnit.SECONDS); log.info(\u0026#34;获取锁\u0026#34;); try { TimeUnit.SECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } finally { log.info(\u0026#34;释放锁\u0026#34;); lock.unlock(); } log.info(\u0026#34;完成业务\u0026#34;); return \u0026#34;success\u0026#34;; } } ","date":"2022-05-11T12:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/1.jpeg","permalink":"https://emerywan.github.io/blog/p/distributed/lock/redis/","title":"使用 Redis 实现分布式锁"},{"content":"原理 CyclicBarrier 通过可重入锁 CyclicBarrier 实现，内部使用静态内部类 Generation 维护 broken 标记，表示屏障是否可用。\n通过构造方法传入等待线程数 parties。\n每次有一个线程到达屏障， count - 1，直到 count = 0，会释放屏障，唤醒所有等待的线程，并使用 nextGeneration() 对 count 和 generation 进行重置，进行下一轮循环。\n有三种情况会造成屏障破坏：\nCyclicBarrier Runnable command 方法抛出异常\n在释放条件还未达到时，某个线程抛出了异常\nawait() 等待超时\n源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 public class CyclicBarrier { // 内部类，存放 broken 标记，表示屏障是否被损坏，损坏后无法正常工作 private static class Generation { boolean broken = false; } // 可重入锁 private final ReentrantLock lock = new ReentrantLock(); private final Condition trip = lock.newCondition(); // 屏障阻挡的线程数，构造方法传入的初始化值 private final int parties; // 屏障释放时执行的方法 private final Runnable barrierCommand; // 当前的 Generation 对象，每一轮都会有一个新的 Generation 对象，存放 broken 标记 private Generation generation = new Generation(); // 当前还需要阻挡几个线程，每次 -1 private int count; // 开启下一轮屏障（count==0 或 reset） private void nextGeneration() { // 唤醒所有等待线程 trip.signalAll(); // 重置 count count = parties; generation = new Generation(); } // 破坏当前屏障，变为不可用状态，可以使用 reset 恢复 private void breakBarrier() { generation.broken = true; count = parties; trip.signalAll(); } private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException { final ReentrantLock lock = this.lock; // 加锁，有多个线程会调用 await() 只有一个线程能够进入同步方法 lock.lock(); try { final Generation g = generation; if (g.broken) // 屏障是否损坏 throw new BrokenBarrierException(); if (Thread.interrupted()) { breakBarrier(); throw new InterruptedException(); } int index = --count; if (index == 0) { // 达到条件，可打破屏障 boolean ranAction = false; try { final Runnable command = barrierCommand; if (command != null) // 执行打破屏障的命令 command.run(); ranAction = true; nextGeneration(); // 开启下一轮循环，里面会唤醒所有等待的线程 return 0; } finally { if (!ranAction) // (1) 假如 command 出现异常，破坏屏障 breakBarrier(); } } // 当前还未达到冲破屏障的的条件 // 一直循环等待，直到到达打破屏障的条件，中断，或超时 for (;;) { try { if (!timed) trip.await(); // 未达到超时时间，进行等待，直到被唤醒 else if (nanos \u0026gt; 0L) nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { // (2) 等待到达条件时，线程被中断，破坏屏障 if (g == generation \u0026amp;\u0026amp; ! g.broken) { breakBarrier(); throw ie; } else { // We\u0026#39;re about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // \u0026#34;belong\u0026#34; to subsequent execution. Thread.currentThread().interrupt(); } } if (g.broken) // 线程被唤醒之后，屏障被破坏，直接抛出异常 throw new BrokenBarrierException(); if (g != generation) // 返回当前线程是第几个到达的线程 return index; if (timed \u0026amp;\u0026amp; nanos \u0026lt;= 0L) { // (3) 等待超时，破坏屏障 breakBarrier(); throw new TimeoutException(); } } } finally { lock.unlock(); } } public CyclicBarrier(int parties, Runnable barrierAction) { if (parties \u0026lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction; } public CyclicBarrier(int parties) { this(parties, null); } public int getParties() { return parties; } // 开始等待 返回当前线程是第几个到达的线程 public int await() throws InterruptedException, BrokenBarrierException { try { return dowait(false, 0L); } catch (TimeoutException toe) { throw new Error(toe); // cannot happen } } public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException { return dowait(true, unit.toNanos(timeout)); } // 判断屏障是否被破坏 public boolean isBroken() { final ReentrantLock lock = this.lock; lock.lock(); // 需加锁访问，其他线程可能在执行 dowait() try { return generation.broken; } finally { lock.unlock(); } } // 重置操作 先破坏屏障，再进行下一轮循环屏障 public void reset() { final ReentrantLock lock = this.lock; lock.lock(); try { breakBarrier(); // break the current generation nextGeneration(); // start a new generation } finally { lock.unlock(); } } // 获取等待线程数 public int getNumberWaiting() { final ReentrantLock lock = this.lock; lock.lock(); try { return parties - count; } finally { lock.unlock(); } } } ","date":"2022-05-03T23:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/14.jpeg","permalink":"https://emerywan.github.io/blog/p/thread/cyclicbarrier/","title":"Java 并发 - CyclicBarrier 实现原理"},{"content":"基本实现思路： 利用 共享锁 实现\n初始化时，state=count 即已经上了 count 次共享锁\nawait() 即加共享锁，必须 state=0 时才能加锁成功，否则按照 AQS 机制，进入等待队列阻塞\ncountDown() 解一次锁，直到为 0\n源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 public class CountDownLatch { // 内部类实现 AQS private static final class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 4982264981922014374L; Sync(int count) { // 使用 AQS 的 state 作为计数器 setState(count); } int getCount() { return getState(); } // 采用 **共享锁** 机制，因为可以被不同的线程 countdown protected int tryAcquireShared(int acquires) { return (getState() == 0) ? 1 : -1; } protected boolean tryReleaseShared(int releases) { // 每次执行将 state-1，直到 state=0 for (;;) { int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) // 通过 CAS 改变 state 的值，失败会进行下一轮循环 return nextc == 0; } } } private final Sync sync; public CountDownLatch(int count) { if (count \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;count \u0026lt; 0\u0026#34;); this.sync = new Sync(count); } // 通过 acquireSharedInterruptibly 获取共享锁 // 若 state!=0 会被持续阻塞 public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1); // 1 这里是随意的参数，在 coutdownlatch 中无意义 } public boolean await(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); } // 解锁一次 public void countDown() { sync.releaseShared(1); } // 获取当前计数 public long getCount() { return sync.getCount(); } public String toString() { return super.toString() + \u0026#34;[Count = \u0026#34; + sync.getCount() + \u0026#34;]\u0026#34;; } } ","date":"2022-05-03T14:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/6.jpeg","permalink":"https://emerywan.github.io/blog/p/thread/countdownlatch/","title":"Java 并发 - CountDownLatch 实现原理"},{"content":"🌱 介绍 许多平台都提供了免费的静态页面托管的服务，如 Github Pages，Vercel，Netlify等。但在国内由于一些“原因”，这些国外的服务在国内的访问并不稳定。\n国内的免费托管平台如 Gitee 限制很多，不可以自定义域名而且之前出现了防盗链问题，访问也不是很快，不太推荐作为托管平台。\n腾讯云推出的云开发 CloudBase 也有静态页面托管服务。其实它相比这些静态托管平台，有更多强大的功能，甚至能够搭一整套系统。虽然是付费服务，但是在按量付费的情况下资费不是很高，在博客访问量不是很高的情况下十分合适。\n目前在腾讯云中暂时还没有 Hugo 的模板。目前有两种方式可以达到自动部署的功能：\n🌰 使用 Github Actions 编译，通过 Tencent CloudBase Github Action 自动部署到 CloudBase。\n🌰 使用 Github Actions 编译，推送到 Web 应用托管（webify） 的简易静态页面模板。\n🏖 使用 CloudBase 使用 CloudBse 时，使用按量计费环境会有一些免费用量。\n☁️ 腾讯云 创建环境 在 云开发 CloudBase 新建一个应用，选择 空模板，根据自身需求填写信息。\n创建成功后，获得 环境ID。\n获取 API 密钥 为部署新建一个密钥对。在 访问管理 -\u0026gt; 用户列表 -\u0026gt; 新建用户 -\u0026gt; 自定义创建 -\u0026gt; 可访问资源并接收消息。🔗 传送门\n根据自己的需要，新建用户名后选择 编程访问，点击下一步。\n在自定义策略中勾选：\nQcloudAccessForTCBRole：授予云开发（TCB）对云资源的访问权限； QcloudAccessForTCBRoleInAccessCloudBaseRun：供云开发（TCB）服务角色（TCB_QcsRole）进行关联，用于 TCB 访问其他云服务资源。包含私有网络 VPC、云服务器 CVM 相关操作权限。 点一下一步后，新建用户成功。可以获得 SecretId 和 SecretKey。\n⚙️ Github Actions 设置 Github Secrets 在项目的 Settings -\u0026gt; Secrets -\u0026gt; Actions 中添加上述得到的 ENV_ID，SECRET_ID，SECRET_KEY（名称可以自定义）。\n添加 workflows 可以在仓库的 Actions 中 new workflow，或者在项目中 .github/workflows 添加。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name: Tencent CloudBase on: push: branches: - main jobs: hugo-publish: name: publish content to static website runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: latest extended: true - name: Build run: hugo --minify --gc # 使用云开发 Github Action 部署 - name: Deploy to Tencent CloudBase uses: TencentCloudBase/cloudbase-action@v2 with: secretId: ${{ secrets.QCLOUD_SECRET_ID }} secretKey: ${{ secrets.QCLOUD_SECRET_KEY }} envId: ${{ secrets.QCLOUD_ENV_ID }} 🚧 提示：\n这里使用了 TencentCloudBase/cloudbase-action@v2，需要在项目根目录添加 cloudbaserc.json。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \u0026#34;envId\u0026#34;: \u0026#34;{{env.ENV_ID}}\u0026#34;, // 这里需要更改为你的 环境ID，或者在 .env 文件中配置 \u0026#34;$schema\u0026#34;: \u0026#34;https://framework-1258016615.tcloudbaseapp.com/schema/latest.json\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;framework\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hugo-blog\u0026#34;, \u0026#34;plugins\u0026#34;: { \u0026#34;client\u0026#34;: { \u0026#34;use\u0026#34;: \u0026#34;@cloudbase/framework-plugin-website\u0026#34;, \u0026#34;inputs\u0026#34;: { \u0026#34;outputPath\u0026#34;: \u0026#34;public\u0026#34;, \u0026#34;ignore\u0026#34;: [ \u0026#34;.git\u0026#34;, \u0026#34;.github\u0026#34;, \u0026#34;cloudbaserc.js\u0026#34; ] } } } } } 🚧 提示：\n这里也可以选择 Tencent CloudBase Github Action V1。🙋‍♂️ （推荐）\nV2 比 V1 有更多功能，比如拉取代码在腾讯云端编译，但目前没有 Hugo 模板。我们已经在 Github Actions 产出了静态文件，直接推送即可。所以目前对于 hugo 来说，没什么区别，使用甚至 V1 更快更简洁。\n1 2 3 4 5 6 7 8 # 将上述 jobs 内替换为 - name: Deploy to Tencent CloudBase uses: TencentCloudBase/cloudbase-action@v1.1.1 with: secretId: ${{ secrets.QCLOUD_SECRET_ID }} secretKey: ${{ secrets.QCLOUD_SECRET_KEY }} envId: ${{ secrets.QCLOUD_ENV_ID }} staticSrcPath: public 🏝 使用 webify 使用 Web 应用托管（webify）主要是利用 Github Actions 生成 静态页面到另一个分支，再托管这个分支的内容。\n☁️ 创建服务 在 Web 应用托管 -\u0026gt; 新建应用 新建一个简易静态页面模板。根据需求填写信息。选择纯静态页面。\n在 应用列表 -\u0026gt; 应用设置 中配置仓库信息，并根据自身情况选择静态文件的部署分支。（如果当前没有生成静态页面的分支，可完成后面操作后再进行此步骤）。\n⚙️ Github Actions 设置 Github Token 在用户的 Settings -\u0026gt; Developer settings -\u0026gt; Personal access tokens -\u0026gt; Generate new token 获取一个 Repo Token。🔗 传送门\n在项目的 Settings -\u0026gt; Secrets -\u0026gt; Actions 中添加上述得到的 Token。\n添加 workflows 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 name: Tencent CloudBase on: push: branches: - main jobs: hugo-publish: name: publish content to static website runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: latest extended: true - name: Build run: hugo --minify --gc - name: Deploy to Branch uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.ACCESS_TOKEN }} keep_files: false publish_branch: gh-pages # 更改为你想要生成的分支 publich_dir: ./public commit_message: ${{ github.event.head_commit.message }} ⛓ 参考 🔗 https://blog.wangjunfeng.com/post/hugo-cloudbase/ 🔗 https://cloud.tencent.com/document/product/1210/43389 🔗 https://github.com/TencentCloudBase/cloudbase-action 🔗 https://github.com/TencentCloudBase/cloudbase-action/blob/3354b442713265aa9d7c5bf03b0b8cb0173f546f/README.md ","date":"2022-05-02T21:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/3.jpeg","permalink":"https://emerywan.github.io/blog/p/hugo-in-cloudbase/","title":"使用 Github Actions 在腾讯云 CloudBase 部署 Hugo"},{"content":"说明 Ubuntu 有些第三方软件只提供二进制执行文件（压缩包或 AppImage），而不是安装包或者 apt 源，这时候需要我们去自己解压文件，放在自定义目录，并进行配置。\n平常使用桌面环境的话，这样安装后，更新还是有点麻烦的，一更新就要修改很多地方。\n这里介绍我平常的配置方式，每次更新后，只需要修改软链接即可，感觉还是挺方便的。\n方式 以 cfw 安装为例，Linux 提供 .tar.gz 的执行文件。\n我通常都把这样的软件都统一放到 ~/Applications 中。\n🏕️ 首先创建一个安装的软件的文件夹 1 mkdir -p ~/Application/clash 🏞️ 将下载的文件解压到该文件夹中 1 tar -xzvf Clash.for.Windows-0.19.12 -C ~/Application/clash 🏜️ 创建启动文件的软连接 1 ln -s ./Clash\\ for\\ Windows-0.19.12-x64-linux/cfw ./clash 通过这种方式，每次启动应用都使用这个软链接进行操作，当需要升级应用时，只需要创建新的软链接，指向新的启动文件。\n不需要每次升级版本，都改其他地方，而且可以通过文件夹命名很清楚地知道当前使用地版本号。👍\n最后的效果如下：\n1 2 3 4 5 $ tree . -L 1 . ├── clash -\u0026gt; ./Clash for Windows-0.19.12-x64-linux/cfw ├── Clash for Windows-0.19.12-x64-linux └── Clash for Windows-0.19.2-x64-linux 🏖️ 添加桌面图标 1 vim ~/.local/share/applications/clw.desktop 添加以下内容：\n1 2 3 4 5 6 7 8 9 [Desktop Entry] Name=Clash for Linux Icon=/home/emery/Applications/icon/clash_icon.png # 替换为自己的目录 Comment=Clash for Linux Exec=\u0026#34;/home/emery/Applications/Clash/clash\u0026#34; %u # 替换为自己的目录 Type=Application Categories=Network Terminal=false StartupNotify=true ","date":"2022-05-02T02:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/4.jpeg","permalink":"https://emerywan.github.io/blog/p/ubuntu-software-install/","title":"在 Ubuntu 优雅地安装 zip 应用 🤔"},{"content":"Nvdia 驱动 首先，请确保在系统中安装了英伟达显卡驱动，可以使用 nvidia-msi 命令查看显卡对应信息。\n如果没有安装驱动，可以参考该章节。传送门➡️\n推荐使用系统自带软件 软件和更新 安装显卡驱动。打开应用后，点击 附加驱动 选项，会对所有可选的附加驱动进行搜索。\n其中，Nouveau 为英伟达显卡开源驱动（默认安装），选择需要的 NVIDIA drive 驱动选项，点击 应用更改。\n等待进度条结束后，重启电脑，即完成了显卡驱动的安装。\nCUDA 你可以在 这里 看到显卡驱动版本与 CUDA 版本的对应关系。\n🌰 在这里的显卡驱动版本为 470.103.01，根据对应表可知，最高可选的 CUDA Toolkit 的版本号为 CUDA 11.4 Update 4。\n之后，可在官网 该页面 中，选择对应的 CUDA Toolkit。\n可根据当前系统环境，选择对应的下载选项（推荐下载 .drunfile，.deb 会覆盖系统安装的显卡驱动）：\n下载完成后，使用以下命令进行安装：\n1 2 3 4 cd ${DOWNLOAD_DIR} chmod +x ./cuda_{Version}_linux.run sudo sh ./cuda_{Version}_linux.run ::: warning 警告 🚧 注意：在安装过程中，请取消勾选安装驱动选项。 :::\n配置环境变量，在对应配置文件中添加如下内容：\n1 2 3 # bash -\u0026gt; .bashrc / zsh -\u0026gt; .zshrc export CUDA_HOME=/usr/local/cuda-{Version} export PATH=${CUDA_HOME}/bin:${PATH} cuDNN 你可以在官网 此链接 下载 CUDNN，需要注册开发者账号，可能还需要一个“良好的网络环境”。\n选择与 CUDA 相对应用的 cuDNN，推荐下载压缩包格式。\n下载完成后，解压文件夹，并根据以下命令复制解压后文件夹中的 lib64 include 文件夹：\n1 2 3 4 tar -xzvf cudnn-linux-{Version}.tar.gz sudo cp cudnn-linux-{Version}/lib64/* /usr/local/cuda/lib64 sudo cp cudnn-linux-{Version}/include/* /usr/local/cuda/include 复制完成后，可以通过以下命令查看 cuDNN 版本信息：\n1 cat /usr/local/cuda-10.1/include/cudnn.h | grep CUDNN_MAJOR -A 2 ","date":"2022-05-02T02:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/11.jpeg","permalink":"https://emerywan.github.io/blog/p/cuda/","title":"在 Ubuntu 中搭建 CUDA 环境"},{"content":"🚧 遗留的安全集合 如：\nHashtable Vector 这些集合的实现方式简单粗暴，在方法上直接使用 synchronized 进行修饰，在进行读写等操作时，会锁住整个对象，并发性能不太好。\n📦 Collections 安全集合 如：\nCollections.synchronizedCollection(Collection c) Collections.synchronizedList(List list) Collections.synchronizedMap(Map\u0026lt;K,V\u0026gt; m) Collections.synchronizedSet(Set s) \u0026hellip; 使用该方法，传入一个线程不安全的集合，返回一个 Collections 内部的静态类对象，用于将一个不安全的集合变成一个线程安全的集合。\n该方法会将传入的集合作为成员变量，每次操作时，都使用 synchronized 加锁，锁住 mutex（Map 中为当前对象 this）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 private static class SynchronizedMap\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt;, Serializable { private static final long serialVersionUID = 1978198479659022715L; private final Map\u0026lt;K,V\u0026gt; m; // Backing Map final Object mutex; // Object on which to synchronize SynchronizedMap(Map\u0026lt;K,V\u0026gt; m) { this.m = Objects.requireNonNull(m); mutex = this; } SynchronizedMap(Map\u0026lt;K,V\u0026gt; m, Object mutex) { this.m = m; this.mutex = mutex; } public int size() { synchronized (mutex) {return m.size();} // 操作都会锁住 mutex } // ... 其他方法 } 🛠 JUC 安全集合 java.util.concurrent 下提供的线程安全的集合类，可以分为三类：\nConcurrent 系列（适合写多的场景，内部使用 CAS 优化） CopyOnWrite 系列（适合于读多写少的场景） Blocking 系列（阻塞队列） ✍ Concurrent ConcurrentHashMap\nConcurrentLinkedQueue / ConcurrentLinkedDeque\nConcurrentSkipListMap / ConcurrentSkipListSet\n📖 CopyOnWrite CopyOnWriteArrayList 采用了写入时拷贝的思想，更改操作会将底层数组拷贝一份，更改在新的数组上执行，并发时读写操作达到读写分离。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); // 替换数组 return true; } finally { lock.unlock(); } } 读操作不进行加锁。适合于读多写少的场景。\n1 2 3 4 5 6 7 8 @SuppressWarnings(\u0026#34;unchecked\u0026#34;) private E get(Object[] a, int index) { return (E) a[index]; } public E get(int index) { return get(getArray(), index); } CopyOnWriteArraySet CopyOnWriteArraySet 内部由 CopyOnWriteArrayList 实现\n1 2 3 4 5 6 public class CopyOnWriteArraySet\u0026lt;E\u0026gt; extends AbstractSet\u0026lt;E\u0026gt; implements java.io.Serializable { public CopyOnWriteArraySet() { al = new CopyOnWriteArrayList\u0026lt;E\u0026gt;(); } } 🚧 Blocking 有界队列：有固定大小的队列。\n无界队列：没有固定大小的队列\nArrayBlockingQueue\n有界带缓冲阻塞队列，数组实现 LinkedBlockingQueue\n由界带缓冲阻塞队列 (Integer.MAX_VALUE)，链表实现，可以自定义上限 LinkedBlockingDeque\n双端队列 DelayQueue\n延时无界阻塞队列，只允许存放可以延时的元素，队列 head 是最先到期的，如果队列中元素没有到期，就算队列中有元素也不能获取到 SynchronousQueue\n没有容量的同步队列，不存储元素，每一个 put 必须要等待一个 take 操作 PriorityBlockingQueue\n无界优先阻塞队列，PriorityQueue 的线程安全版，不允许存放 null 常用方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public interface BloockingQueue\u0026lt;E\u0026gt; extends Queue\u0026lt;E\u0026gt; { // 队列满抛出异常 boolean add(E e); // 无元素抛出异常 boolean remove(Object o); // // 队列满返回 false 成功添加 true boolean offer(E e); // 队列为空返回 null E poll(); // 阻塞时等待 // 队列满时，阻塞进行等待 boolean put(E e) throws InterruptedException; // 队列为空时，阻塞进行等待 E take() throws InterruptedException; } LinkedBlockingQueue 在 LinkedBlockingQeque 中使用了 dummy 节点和两把锁，在同一时刻，可以允许两个线程分别执行 put 和 take。\n1 2 3 private final ReentrantLock putLock = new ReentrantLock(); private final ReentrantLock takeLock = new ReentrantLock(); put 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); int c = -1; Node\u0026lt;E\u0026gt; node = new Node\u0026lt;E\u0026gt;(e); final ReentrantLock putLock = this.putLock; // 计数 final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { // 如果容量已满，进行等待 while (count.get() == capacity) { notFull.await(); } // 容量未满，进行入队 enqueue(node); c = count.getAndIncrement(); // 入队后队列还有空位, 唤醒其他 put 线程 if (c + 1 \u0026lt; capacity) notFull.signal(); // 只唤醒一个，减少竞争 } finally { putLock.unlock(); } // 如果队列中有一个元素, 唤醒 take 线程 if (c == 0) // notEmpty.signal() 而不是 notEmpty.signalAll()；减少竞争 signalNotEmpty(); } take 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public E take() throws InterruptedException { E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { while (count.get() == 0) { notEmpty.await(); } x = dequeue(); c = count.getAndDecrement(); if (c \u0026gt; 1) notEmpty.signal(); } finally { takeLock.unlock(); } // 如果队列中只有一个空位时, 叫醒 put 线程 // 如果有多个线程进行出队, 第一个线程 c == capacity, 后续线程 c \u0026lt; capacity if (c == capacity) // notFull.signal() 而不是 notFull.signalAll()，减少竞争 signalNotFull(); return x; } ","date":"2022-04-29T14:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/16.jpeg","permalink":"https://emerywan.github.io/blog/p/thread/collection/","title":"Java 并发 - 并发安全的容器"},{"content":"AQS AQS AbstractQueuedSynchronized 是一个用来构建锁和同步器的框架，是对 CAS 的一种封装和丰富，AQS 引入了独占锁，共享锁等性质。\n使用 AQS 能够基于 Java API，简单高效地构建出应用广泛的大量同步器，用于 Java 多线程之间的同步。\n核心思想 AQS 使用一个 volatile int state 成员变量表示同步状态。\n使用 CAS compareAndSetState 对该同步状态进行原子操作，实现对其值的修改。\n1 2 // 共享变量，使用 volatile 保障可见性 private volatile int state; AQS 通过内置的 FIFO 双向队列来完成同步状态的管理，获取资源线程的排队工作。\n1 2 private transient volatile Node head; private transient volatile Node tail; 当请求的共享资源空闲时，将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态。\n如果被请求的共享资源被占用，将暂时获取不到锁的线程构造成一个 Node 加入到队列中。\n资源的共享方式 独占 当一个线程以独占模式获取锁时，其他任何线程都必须等待。\nReentrantLock 共享 当一个线程以共享模式获取锁时，其他也想以共享模式获取锁的线程也能够一起访问共享资源，但其他想以独占模式获取锁的线程需要等待。\nCountDownLatch CyclicBarrier Semaphore 实现 CountDownLatch CountDownLatch 同步工具允许一条或多条线程，等待其他线程中的一组操作完成后，再继续执行。\nCountDownLatch 任务分为 n 个子线程执行，state 将被初始化为 n，这 n 个线程将会并发执行，每个子线程执行完后调用 countDown() 方法，state 会通过 CAS - 1。当所有的子线程都执行完之后，state=0，会 unpack 主线程，继续后续动作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 public class Demo { static class SearchTask implements Runnable { private Integer id; private CountDownLatch latch; public SearchTask(int id, CountDownLatch latch) { this.id = id; this.latch = latch; } // **子线程** // 各自寻找相应目标的龙珠 @Override public void run() { System.out.println(\u0026#34;🏃‍♂️ 开始寻找\u0026#34; + id + \u0026#34;号龙珠\u0026#34;); int seconds = ThreadLocalRandom.current().nextInt(20); try { Thread.sleep(seconds * 1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;👏 花了\u0026#34; + seconds + \u0026#34;秒，找到了\u0026#34; + id + \u0026#34;号龙珠\u0026#34;); // 每当一个任务完成，就调用一次 countDown() 方法 latch.countDown(); } } // **主线程** // 等子线程都执行完毕后，找到所有龙珠，召唤神龙 public static void main(String[] args) { List\u0026lt;Integer\u0026gt; idList = Arrays.asList(1, 2, 3, 4, 5, 6, 7); // state 初始化为任务的个数 CountDownLatch latch = new CountDownLatch(idList.size()); for (int id : idList) { Thread thread = new Thread(new SearchTask(id, latch)); thread.start(); } try { latch.await(); // 等待其他线程完成 } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;找到所有龙珠了！召唤神龙 🐲\u0026#34;); } } 在这个例子中，任务分为 7 个子线程执行，将 CountDownLatch 的值初始化为与线程相同的次数。主线程通过 await() 等待其他任务完成。\n这几个子任务并发执行，每个子线程执行完成后 countDown() 一次，state 会通过 CAS 操作 -1。\n直到所有的子线程都执行完毕之后，state=0，主线程会结束等待，继续执行后续任务。\nCyclicBarrier CyclicBarrier 用于多个线程相互等待对方执行到某个状态后，这些线程再继续执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 public class Demo { private static int count = 5; // CyclicBarrier 可以设置子线程全部到达 barrier，执行的任务 private static CyclicBarrier barrier = new CyclicBarrier(count, () -\u0026gt; { System.out.println(\u0026#34;👌 人员到齐！准备爬山！\u0026#34;); }); public static void main(String[] args) { // 子线程，模拟 5 个同学相约爬山 for (int i = 1; i \u0026lt;= 5; i++) { final String name = i + \u0026#34;同学\u0026#34;; new Thread(() -\u0026gt; { System.out.println(\u0026#34;👋 \u0026#34; + name + \u0026#34;准备出发去集合点了。\u0026#34;); int time = ThreadLocalRandom.current().nextInt(10); try { TimeUnit.SECONDS.sleep(time); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\u0026#34;🦶 \u0026#34; + name + \u0026#34;花了 \u0026#34; + time + \u0026#34; 秒到达集合点。\u0026#34;); try { // 等待所有的同学（子线程）运行到此处 barrier.await(); // 当 await 的线程足够，再继续执行线程后续任务 } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } System.out.println(name + \u0026#34;和大家一起爬山了。⛰\u0026#34;); }, i + \u0026#34;同学\u0026#34;).start(); } } } 在这个例子中，有 5 个子线程分别开始执行（5 个同学从家里出发），每个线程到达某个状态后 await() 进行等待（每个同学到达集合点会等待其他同学到达），当线程全部达到之后，“屏障”会释放，线程将继续执行（人员到齐后开始爬山）。\nCyclicBarrier 可以多次使用，可以自动或手动重置计数。 使用 barrier.reset() 会进行重置，等待的线程会抛出 BrokenBarrierException\n1 2 3 4 5 // CyclicBarrier 的计数 count = 5 // 子线程的数量 i = 10 将子线程的数量设置为 10，循环屏障设置为 5，将会得到如下结果：每有 5 个，线程到达“屏障”点，就会释放一次。\nSemaphore 通过使用 Semaphore，我们可以决定某个资源同一时间能够被访问的最大线程数，它相当于对某个资源的访问进行了流量控制。\n是一个可以被 n 个线程占用的排它锁，可以在最开始设定 Semaphore 许可证数量，每个线程都可以获得 1 个或多个许可证，当许可证耗尽或不足以供其他线程获取时，其他线程将被阻塞。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public static void main(String[] args) { Semaphore semaphore = new Semaphore(2); // 有三个许可，假设每个线程只获取一个许可时，最多两个线程可访问资源 for (int i = 0; i \u0026lt; 3; i++) { new Thread(() -\u0026gt; { try { try { semaphore.acquire(); // 无参为申请一个许可证，没有许可的线程会进行等待 } catch (InterruptedException e) { e.printStackTrace(); } try { System.out.println(\u0026#34;申请许可证成功\u0026#34;); TimeUnit.SECONDS.sleep(5); // 模拟任务耗时 } finally { semaphore.release(); } } catch (InterruptedException e) { e.printStackTrace(); } }).start(); } } ReentrantLock 相比于 synchronized，都支持 ✨可重入，还具备如下特点：\n✨ 等待可中断 ✨ 可以设置超时时间 ✨ 公平锁 ✨ 支持多个条件变量 ReentrantLock 需要使用 try-finally 手动加锁和解锁\n1 2 3 4 5 6 reentrantLock.lock(); try { // 临界区 } finally { reentrantLock.unlock(); } ReentrantLock 默认实现为非公平锁\n1 2 3 public ReentrantLock() { sync = new NonfairSync(); } 可重入 一个线程获取了🔒 锁之后，可以多次获取同一把锁。\n一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则改线程可以直接获取锁，并执行该方法，可重入锁可有效地避免死锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public static void main(String[] args) { method1(); } private static ReentrantLock lock = new ReentrantLock(); public static void method1() { lock.lock(); // 第一次获取🔒 锁 try { System.out.println(\u0026#34;do something in method 1\u0026#34;); method2() } finally { lock.unlock(); } } public static void method2() { lock.lock(); // 第二次获取🔒 锁（重入） try { System.out.println(\u0026#34;do something in method 2\u0026#34;); } finally { lock.unlock(); } } 等待可中断 lock.lockInterruptibly()\n没有竞争就会获取锁 有竞争进入阻塞队列，但是可以被中断（throw InterruptedException） 使用 lock.lock()，即使进行 interrupt() 也不会让线程等待中断。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public static void main(String[] args) { ReentrantLock lock = new ReentrantLock(); Thread thread = new Thread(() -\u0026gt; { try { lock.lockInterruptibly(); // 尝试获取可中断锁 } catch (InterruptedException e) { System.out.println(\u0026#34;锁在等待过程中被其他线程中断\u0026#34;); return; } try { System.out.println(\u0026#34;成功获得了锁 🔒\u0026#34;); } finally { lock.unlock(); } }); lock.lock(); System.out.println(\u0026#34;主线程获取了锁 🔒\u0026#34;); thread.start(); try { Thread.sleep(1000); System.out.println(\u0026#34;主线程打断 thread\u0026#34;); thread.interrupt(); Thread.sleep(1000); } finlaly { lock.unlock(); } } 超时时间 boolean tryLock()：获取锁失败，立即返回 boolean tryLock(long timeout, TimeUnit unit)：获取锁失败，等待超时时间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Thread thread = new Thread(() -\u0026gt; { try { if (!lock.tryLock(2, TimeUnit.SECONDS)) { System.out.println(\u0026#34;等待 2s 后，成功获取了锁\u0026#34;); return; } } catch (InterruptedException e) { e.printStackTrace(); } try { System.out.println(\u0026#34;成功获取了锁\u0026#34;); } finally { lock.unlock(); } }); 公平锁 ReentrantLock 默认是非公平锁\n1 2 3 4 5 6 7 public ReentrantLock() { sync = new NonfairSync(); } public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } 公平锁：获取锁的线程根据进入等待队列的顺序获取锁 非公平锁：新线程先尝试插队获取锁，插队失败再进入等待队列排序等待 1 2 // 获取公平锁 ReentrantLock lock = new ReentrantLock(true); 多个条件变量 ReentrantLock 支持多个条件变量，可以对等待的线程进行精准唤醒。\n使用 await()，线程会释放获取的锁，进入对应的 conditionObject 进行等待；被 singnal() 唤醒后，线程重新去竞争锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 // 三个线程循环打印 ABC 10 次 public class ThreadDemo { static ReentrantLock lock = new ReentrantLock(); static Condition conditionA = lock.newCondition(); static Condition conditionB = lock.newCondition(); static Condition conditionC = lock.newCondition(); // 0-\u0026gt;print A 1-\u0026gt;print B 2-\u0026gt;print C static int commonState = 0; static class MyTread implements Runnable { private int state; public MyThread(int state) { this.state = state; } @Override public void run() { for (int i = 0; i \u0026lt; 10; i++) { lock.lock(); try { if (state == 0) { while (commonState != 0) { conditionA.await(); } System.out.println(\u0026#34;A\u0026#34;); commonState = 1; conditionB.singnal(); } if (state == 1) { while (commonState != 1) { conditionB.await(); } System.out.println(\u0026#34;B\u0026#34;); commonState = 2; conditionC.singnal(); } if (state == 2) { while (commonState != 2) { conditoinC.await(); } System.out.println(\u0026#34;C\u0026#34;); commonState = 0; conditionA.singnal(); } } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } } } public static void main(String[] args) { new Thread(new MyThread(0)).start(); new Thread(new MyThread(1)).start(); new Thread(new MyThread(2)).start(); } } ReentrantReadWriteLock 参考 https://tech.meituan.com/2018/11/15/java-lock.html ","date":"2022-04-13T14:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/6.jpeg","permalink":"https://emerywan.github.io/blog/p/thread/aqs/","title":"Java 并发 - AQS"},{"content":"单例模式所要实现的目标：保持一个类有且只有一个实例。\n出于性能的考虑，不少单例模式都会采用延迟加载的方式。根据是否延迟创建对象，可以分为：\n🤩 饿汉式\n😪 懒汉式\n😪 懒汉式 单线程的单例模式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public final class Singleton { private static Singleton instance = null; // 构造器私有，其他类无法通过 new 初始化 private Singleton() { } // 创建并返回该类的唯一实例 public static Singleton getInstance() { if (null == instance) { instance = new Singleton(); } } public void someService() { // 一些业务代码 } } 🔒 加锁的单例模式 使用 synchronized 加锁实现线程安全。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public final class Singleton { private static Singleton instance = null; private Singleton() { } // public static synchronized getInstance() public static Singleton getInstance() { synchronized (Singleton.class) { // 不推荐 🙅‍♂️ 每次判空操作，都要获取锁，开销极大 if (null == instance) { instance = new Singleton(); } } return instance; } } 使用双重检验判断\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class Singleton { private volatile static Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; } } 使用 volatile 修饰实例，利用了以下两个作用：\n(1) 保障可见性：\n一个线程初始化了 instance 的值，其他线程可以读取到相应的值。\n(2) 保障有序性：\n保障一个线程读取到的 instance 引用的实例已经初始化完毕。\n对象实例化会分解成以下几个子操作：\n分配对象所需的空间 初始化 instance 引用的对象 将对象的引用写入共享变量 由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-\u0026gt;3-\u0026gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。\n例如：线程 T1 执行了 1 和 3 后，此时 T2 调用 getInstance() 后发现 instance 不为空，因此直接返回，但此时 instance 还未被初始化。\n静态内部类的单例模式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public final class Singleton { private Singleton() { } private static class InstanceHolder { // 静态内部类 // 保存外部类的唯一实例 private final static Singleton INSTANCE = new Singleton(); } public static Singleton getInstance() { return InstanceHolder.INSTANCE; } public void someService() { // ... } public static void main(String[] args) { Singleton.getInstance().someService(); } } 当外部类加载时，内部类不会加载，并且静态变量只会有默认值（null）。\n类的静态变量被初次访问才会触发 Java 虚拟机对该类进行初始化，会变为其初始值。\n枚举单例 1 2 3 4 5 6 7 8 9 10 public enum Singleton { INSTANCE; Singleton() { // 私有构造器 } pubilc void someService() { // 业务代码 } } 字段 INSTANCE 是枚举类的唯一实例。在 Singleton.INSTANCE 初次被引用时才会被初始化。\n🤩 饿汉式 1 2 3 4 5 6 7 8 9 10 pubilc final class Singleton { // 在创建时直接初始化，天生线程安全 private static Singleton instance = new Singleton(); println Singleton() { } pubilc staitc Singleton getInstance() { return instance; } } ","date":"2022-04-11T18:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/8.jpeg","permalink":"https://emerywan.github.io/blog/p/desgin-pattern/singleton/","title":"单例模式"},{"content":"在并发情况下，多个线程会对同一个资源进行争抢，可能会导致数据不一致的问题。\n为了解决这个问题，通过引入锁机制🔒，使用一种抽象的锁，对资源进行锁定，达到同步访问的目的。\n实现 Java 采用了两种实现方式：\n阻塞同步（😢 悲观锁）\n📝 适合于写多读少的场景。先加锁，保证写操作时的数据正确。\n基于 Object 的 synchronized 内部锁 🔒\n基于 API 类库的 java.util.concurrent.locks.Lock 🔒\n非阻塞同步（😁 乐观锁）\n📖 适合于读多写少的场景。不加锁，可以大幅提高读的性能。\n基于 CAS 的乐观锁 😢 悲观锁 在 Java 中，每个对象（Object），都拥有一把锁，存放在对象头中，记录了当前对象被哪个线程所占用。\n🔐 内部锁 synchronized synchronized 关键字可以用来同步线程，其被编译后，会生成 monitorenter 和 moniterexit 两个字节码指令，用来进行线程的同步。\n这两个字节码指令都需要一个 reference 类型的参数来指明要锁定和解锁的对象。\n如果 Java 源码中的 synchronized 明确指定了对象参数，那就以这个对象的引用作为 reference；\n如果没有明确指定，就根据 synchronized 修饰的方法类型（实例方法或类方法），来决定是取代码所在的对象实例还是取类型对应的 Class 对象来作为线程要持有的锁。\n加锁方式 对象锁\n修饰实例方法\npubilc sychronized void method() { ... }\n代码块锁住当前对象\nsynchronized(this)\n类锁\n修饰静态方法\npublic static synchronized void method() { ... }\n代码块锁定 class 对象\nsynchronized(MyClass.class) { ... }\nsynchronized 是非公平锁。一把锁只能被一个线程获取，没有获得锁的线程只能等待。线程对内部锁的申请和释放由 JVM 负责实施。\nsynchronized 是可重入锁。持有锁的对象，可以多次获得锁。\nsynchronized 修饰的方法，无论方法正常执行完还是抛出异常，都会释放锁。\n🌸 JDK 1.6 对 synchronized 的优化 synchronized 依赖于 JVM，使用的是操作系统底层的 Mutex Lock 实现。\nJava 中的线程都是与操作系统的原生线程一一对应的，如果要阻塞或唤醒一个线程，都需要依靠操作系统来实现。 操作系统线程之前的切换，都需要从用户态到内核太的转换，都是很耗时的操作，所以使用 synchronized 的成本较高。\nJDK 1.6 对锁的实现引入了大量的优化，如 锁粗化，锁消除，轻量级锁，偏向锁，自旋锁，适应性自旋等。 并且，对象锁也引入了四种状态，会随着竞争情况逐渐升级（不可以降级），提高获取锁和释放锁的效率。\n无锁 -\u0026gt; 偏向锁 -\u0026gt; 轻量级锁 -\u0026gt; 重量级锁\n🔒 无锁状态\n不对资源进行锁定\n某些资源不会出现多线程竞争的情况，随意多个线程调用 🔒 偏向锁\n只有一个线程访问同步代码块的场景 在一些情况下，没有多线程的竞争，每次都是同一个线程多次获取锁，那么对象锁会“记住”这个线程，只要是这个线程过来，就直接把锁交出去\n如果对象发现目前不是只有一个线程，而是有多个线程在竞争锁，偏向锁就会升级为轻量级锁\n🔒 轻量级锁\n适合同步代码块的执行速度非常快的场景 当锁升级为轻量级锁的时候，其他线程会通过 CAS 进行自旋等待来获取锁，不会阻塞，从而提高性能（并且会根据等待时间调整 CAS 的时间）\n🔒 重量级锁\n适合同步代码块执行速度较长的场景 对象锁状态被标记为重量级锁，通过 Monitor 来对线程进行控制\n😁 乐观锁 CAS 在一些情况下，同步代码块执行的时间远远小于线程切换的耗时。所以希望能够在用户态中对线程的切换进行管理，这样效率更高。\n我们让线程“乐观地”反复尝试获取共享资源，当发现空闲时便进行使用，否则继续“乐观地”进行重试。\n基于以上想法，诞生了 CAS (Compare And Swap) 算法：比较并交换。\nCAS算法涉及到三个操作数：\n需要读写的内存值 addr 进行比较的值 oldValue 要写入的新值 newValue 1 2 3 4 5 6 7 8 int cas(long *addr, long oldValue, long newValue) { /* Executes atomically. */ if(*addr != old) return 0; *addr = new; return 1; } 这个 cas() 函数看起来没有任何同步措施，似乎还是存在线程不安全的问题。\n当 A 线程比较了 oldValue 的值是想要的，但是这个瞬间，B 线程突然抢到了时间片，更改了值；但是 A 线程并不知道，将值改成了 newValue，这就出现了线程安全问题，A B 两个线程同时获得了资源。\n所以，CAS 的操作必须是 原子性 的。这个原子操作，由计算机处理器指令集提供，直接由硬件保障。\nJava 中的原子变量类 基础数据类型\nAtomicInteger AtomicLong AtomicBoolean 数组类型\nAtomicIntegerArray AtomicLongArray AtomicReferenceArray 字段更新类型\nAtomicIntegerFieldUpdater AtomicLongFieldUpdater AtomicReferenceFieldUpdater 引用类型\nAtomicReference AtomicStampedReference AtomicMarkableReference 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class Demo { private static AtomicInteger n = new AtomicInteger(0); public static void main(String[] args) { for (int i = 0; i \u0026lt; 3; i++) { new Thread(() -\u0026gt; { while (n.get() \u0026lt; 1000) { System.out.println( Thread.currentThread().getName() + \u0026#34; : \u0026#34; + n.incrementAndGet() ); } }, \u0026#34;Thread\u0026#34; + i).start(); } } } AtomicInteger 主要由一个 Unsafe 类型的实例 unsafe 和 Long 类型的 offset 实现。\nJava 通过 Unsafe 的 CAS 操作来对 volatile int 值进行更新。根据 value 在对象中的偏移量，CAS 操作内存数据，执行一些底层，和平台相关的方法。\n1 2 3 4 5 6 7 8 9 10 11 // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclareFiele(\u0026#34;value\u0026#34;)); } catch (Exception e) { throw new Error(ex); } } private volatile int value; 例如 incrementAndGet()。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // AtomicInteger.java public final int incrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, 1) + 1; } // Unsafe.java public final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); } while (!compareAndSwapInt(o, offset, v, v + delta)); // 自旋，可以通过启动参数配置，默认是 10 return v; } public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x); 缺点：\n循环开销大\n只能处理一个共享变量\n封装成对象 AtomicReference ABA\nABA 问题 CAS 需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。\n如果内存值原来是 A，后来变成了 B，然后又变成了 A，那么 CAS 进行检查时会发现值没有发生变化，但是实际上是有变化的。\nA -\u0026gt; B -\u0026gt; A\n可以为共享变量引入一个修订号（时间戳），每次更新都会更新相应的修订号，判断变量的值是否被其他线程给修改过。AtomicStampedReference\n[A, 0] -\u0026gt; [B, 1] -\u0026gt; [A, 2]\n1 2 3 4 5 6 7 8 9 10 11 public static void main(String[] args) { String a = \u0026#34;Hello\u0026#34;; String b = \u0026#34;World\u0026#34;; // initialRef initialStamp AtomicStampedReference\u0026lt;String\u0026gt; reference = new AtomicStampedReference\u0026lt;\u0026gt;(a, 1); // expectedReference newStamp reference.attemptStamp(a, 2); // 对版本号进行修改 // expectedReference newReference expectedStamp newStamp reference.compareAndSet(a, b, 2, 3); // CAS 操作需要同时提供 预期值 新值 预期版本号 新版本号 } 参考 https://tech.meituan.com/2018/11/15/java-lock.html https://www.bilibili.com/video/BV1xT4y1A7kA ","date":"2022-04-11T14:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/7.jpeg","permalink":"https://emerywan.github.io/blog/p/thread/lock/","title":"Java 并发 - 锁机制"},{"content":"👨‍🏭 创建 1 2 3 4 5 6 7 8 9 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { // ... } 🧩 corePoolSize 核心线程数\n每次向线程池提交一个多线程任务，都会创建一个新的核心线程，无论是否有空闲线程，直到创建的线程数量到达核心线程数，才会开始复用线程资源 使用 prestartAllCoreThreads() 直接初始化全部线程 🧩 maximumPoolSize 最大线程数\n当所有线程都处于运行状态，且等待队列已满，会开始创建非核心线程，但不超过最大线程数 🧩 keepAliveTime 线程最大空闲时间\n非核心线程超过最大空闲时间，会自动销毁 🧩 unit 最大空闲时间单位\n🧩 workQueue 线程等待队列\n核心线程数已满时，会将任务暂存到等待队列，直到线程资源可用；当等待队列已满时，会开始创建非核心线程 🧩 threadFactory 线程创建的工厂\n🧩 handler 拒绝策略\n当等待队列已满，并且达到最大线程数，新的任务会进行拒绝处理 线程池的大小设计 线程池中线程数量太少 -\u0026gt; 当有大量任务处理时，队列会堆积大量任务，导致相应变慢。\n线程池中线程数量太多 -\u0026gt; 会有大量的线程抢占 CPU 资源，导致频繁的上下文切换，反而会增加任务的执行时间，影响执行效率。\n💻 CPU 密集型 主要是执行计算任务，相应很快，CPU 利用率高。推荐：核心线程数 = CPU 核心数 + 1\n💽 IO 密集型 主要是进行 IO 操作，如硬盘读取数据等，IO 操作时间长，CPU 利用不高，推荐：核心线程数 = 2 * CPU 核心数。\n拒绝策略 ❌ AbortPolicy\n拒绝任务，并抛出异常 RejectedExecutionException ❌ DiscardPolicy\n不抛出异常，直接丢弃新任务 ❌ DiscardOldestPolicy\n丢弃最老的任务 ❌ CallerRunsPolicy\n将任务交给调用线程执行 使用 1 2 3 4 // execute 无返回值 executor.execute(() -\u0026gt; { // do ... }); 1 2 3 4 5 6 7 // submit 有返回值 Future\u0026lt;String\u0026gt; future = executor.submit(() -\u0026gt; { // do... return \u0026#34;返回值\u0026#34;; }); String res = future.get(); 👓 常见的线程池 🌊 newSingleThreadExecutor 只有一个线程的线程池 唯一线程可以保证所提交的任务顺序执行 核心线程数 = 最大线程数 = 1\n1 2 3 4 5 6 public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService( new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;())); } 🌊 newFixedThreadPool 固定线程数的线程池 核心线程数 = 最大线程数 = n\n1 2 3 4 5 public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThread, nThread, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } 🌊 newCachedThreadPool 根据任务会不断创建新线程的线程池 当提交新任务时，如果线程池为空或没有空闲线程，则创建新线程执行任务。线程空闲时间超过 keepAliveTime=60s，会自动释放线程资源。长时间空闲的 CachedThreadPool 不会持有任务任何线程资源。\n核心线程数 = 0\n最大线程数 = Integer.MAX_VALUE\nSynchronousQueue 不存储元素的阻塞队列，每一个 put() 都会等待一个 take() 操作\n1 2 3 4 5 public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;Runnable\u0026gt;()); } ScheduledThreadPoolExecutor ScheduledThreadPoolExecutor 可以用来提交定时任务，extends ThreadPoolExecutor。\n1 2 3 public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize); } ScheduledThreadPoolExecutor 最大线程池容量为 Integer.MAX_VALUE；都是采用的DelayedWorkQueue 作为等待队列。\n1 2 3 4 5 ScheduledExecutorService executor = Executors.newScheduledThreadPool(1); // 延迟 3 s 后执行任务 executor.schedule(() -\u0026gt; System.out.println(\u0026#34;定时任务\u0026#34;), 3, TimeUnit.SECONDS); executor.shutdown(); 1 2 3 4 ScheduledExecutorService executor = Executors.newScheduledThreadPool(2); // 延迟 3 s 后，每 1 s 执行一次任务 executor.scheduleAtFixedRate(() -\u0026gt; System.out.println(\u0026#34;定时任务\u0026#34;), 3, 1, TimeUnit.SECONDS); ForkJoinPool Fork -\u0026gt; 拆分 Pool -\u0026gt; 合并\n把大任务拆分为多个小任务，最后汇总多个小任务的结果，得到整大任务的结果。这些小任务都是同时进行，可提高运算效率。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class Demo { public static void main(String[] args) { ForkJoinTask\u0026lt;Integer\u0026gt; task = new SubTask(1, 1000); int res = ForkJoinPool.commonPool().invoke(task); System.out.println(res); } private static class SubTask extends RecursiveTask\u0026lt;Integer\u0026gt; { private final int start; private final int end; public SubTask(int start, int end) { this.start = start; this.end = end; } @Override protected Integer compute() { if (end - start \u0026lt; 125) { // 任务足够小，直接计算 System.out.println(Thread.currentThread().getName() + \u0026#34; 开始计算 \u0026#34; + start + \u0026#34;-\u0026#34; + end + \u0026#34;的值\u0026#34;); int result = 0; for (int i = start; i \u0026lt;= end; i++) { result += i; } return result; } // 任务太大，拆分成子任务 SubTask subTask1 = new SubTask(start, (end + start) / 2); subTask1.fork(); SubTask subTask2 = new SubTask((end + start) / 2 + 1, end); subTask2.fork(); return subTask1.join() + subTask2.join(); } } } 工作窃取：\n子任务会被放到不同的队列中，每个队列会有对应的线程运行任务。\n若某个队列中的任务计算完毕，但其他的任务队列中还有任务，会从其他队列中“窃取”任务继续执行。\n参考 https://segmentfault.com/a/1190000039267451 ","date":"2022-03-30T16:02:02+08:00","image":"https://emerywan.github.io/blog/p/thread/threadpool/1_hu09e646313a866764776d5602df0c4035_178519_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/thread/threadpool/","title":"Java并发 - 线程池"},{"content":"🐭 进程与线程 进程是指内存中运行的程序，是向操作系统申请资源的基本单位，每个进程都有自己独立的内存空间。\n线程是进程中可独立执行的最小单位，线程本身不可以独立存在。\n一个进程可以包括多个线程，同一进程中所有线程共享该进程中的资源。\n无处不在的线程 main 线程 垃圾回收线程 Web 服务器请求处理线程 🐹 并发与并行 并发 Concurrent\n指在一段时间内，交替的完成多个任务（一个 CPU 核心交替执行多个任务） 并行 Parallel\n齐头并进地执行多个任务（多个 CPU 核心同时执行多个任务） 🦊 同步与异步 同步\n需要等待结果返回，才能继续运行 异步\n不需要等待结果返回，就能继续运行 🐻 线程的创建 extends Thread 1 2 3 4 5 6 7 8 9 10 class MyThread extends Thread { @Override public void run() { System.out.println(Thread.currentThread().getName()); } public static void main(String[] args) { new Thread().start(); } } implement Runnable 1 2 3 4 5 6 7 8 9 10 class RunnableThread implement Runnable { @Override public void run() { System.out.println(Thread.currentThread().getName()); } public static void main(String[] args) { new Thread(new RunnableThread()).start(); } } implement Callable Callable 可以有返回值，返回值通过 FutureTask 进行封装。\ncall() 方法允许抛出异常。\n1 2 3 4 5 6 7 8 9 10 11 12 class CallbaleThead implement Callbale\u0026lt;Integer\u0026gt; { @Override public Integer call() throws Exception { return 666; } public static void main(String[] args) { FutureTask\u0026lt;Integer\u0026gt; futureTask = new FutureTask\u0026lt;\u0026gt;(new CallbaleThead()); new Thread(futureTask).start(); int result = futureTask.get(); } } 线程池 1 2 3 4 5 6 7 8 9 public class Demo { public static void main(String[] args) { ExecutorService executorService = Executors.newFixThreadPool(10); for (int i = 0; i \u0026lt; 10; i++) { executorService.execute(() -\u0026gt; System.out.println(Thread.currentThread().getName())); } } } 1 2 3 4 5 6 7 8 9 10 11 12 public class Demo { public static void main(String[] args) { ExecutorService executorService = Executors.newFixThreadPool(10); Future\u0026lt;Integer\u0026gt; future = executorService.submit(() -\u0026gt; { Thread.sleep(1000); return 666; }); int result = future.get(); } } 🐼 线程的生命周期 1 2 3 4 5 6 7 8 9 10 public class Thread implements Runnable { public enum State { NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED; } } 新建 New 创建后尚未启动。\n可运行 Runnable 可能正在运行，也可能正在等待 CPU 时间片。\n阻塞 Blocked 等待获取一个排它锁，如果其线程释放了锁就会结束此状态。（未获取过锁）\n无限期等待 Waiting 等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。（获取过锁，但是放弃了锁）\n限期等待 Timed Waiting 无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。\n死亡 Terminated 线程结束任务之后自己结束，或者产生了异常而结束。\n🦊 守护线程 Java 中的线程可以分为两类：\n用户线程 user Thread\n守护线程 daemon Thread\nJava 程序的入口是由 JVM 启动的 main 线程（主线程），main 线程可以启动其他线程。当所有用户线程运行都结束时，程序终止，只要有一个用户线程没有退出，程序就不会终止。\n守护线程（Daemon Thread）是一种在后台为其他线程服务的线程。在 JVM 中，只要用户线程执行完毕，无论守护线程是否执行完成，都会退出程序。\n1 thread.setDaemon(true); JVM 的垃圾回收线程就是一种守护线程。\n🐻‍❄️ 查看进程 Linux ps ps -ef ：查看所有进程\ntop 命令下可通过按 H 切换是否显示线程\ntop -H -p 4262 ： 查看 PID=4262 进程的所有线程信息\nJava jps 查看所有 Java 进程\njstack jstack 4262 ： 查看 PID=4262 的 Java 进程的所有线程信息\n参考 https://pdai.tech/md/java/thread/java-thread-x-thread-basic.html#%e5%ae%9e%e7%8e%b0-callable-%e6%8e%a5%e5%8f%a3 ","date":"2022-03-30T14:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/9.jpeg","permalink":"https://emerywan.github.io/blog/p/thread/thread/","title":"Java 多线程"},{"content":"☘️ 通用程序设计 Effective Java 阅读笔记。本章主要讨论了 Java 语言的具体细节。包括：\n局部变量 控制结构 类库 数据结构 不是由语言本身提供的机制 优化和命名惯例。 57. 将局部变量的作用域最小化 🌸 建议 🌱 最小化局部变量的范围，可提高代码的可读性和可维护性，降低出错的可能性。在第一次使用它的地方声明变量。\n🍀 每个局部变量声明都应该包含一个初始化表达式。try-catch 语句除外。\n如果一个变量初始化，会抛出一个 checked 异常，必须在 try 中初始化（除非所包含的方法可以抛异常）。\n如果该值必须在 try 块之外使用，那么它必须在 try 块之前声明，此时它还不能“合理地初始化“。\n1 2 3 4 5 Set\u0026lt;String\u0026gt; set = null; try { set = cons.newInstance(); } catch () { } 🍀 循环结束后不再需要循环变量，for 循环就优于 while 循环（for 循环允许声明循环变量）。\n🌱 保持方法小而集中，每个操作都用一个方法来完成。避免一个操作相关的局部变量可能在另一个操作中。\n🌻 案例 🌾 遍历集合的首选习惯用法\n1 2 3 for (Element e : c) { // do something with e } 💐 需要访问 Iterator / 调用 Iterator 的 remove()，首选 for\n1 2 3 4 for (Iterator\u0026lt;Element\u0026gt; i = c.iterator(); i.hasNext(); ) { // i is loop variable Element e = i.next(); // do something with i and e } 💐 循环习惯用法：最小化局部变量的范围\n1 2 3 4 // 每次循环都会调用 expensiveComputation()，且返回结果相同 for (int i = 0, n = expensiveComputation(); i \u0026lt; n; i++) { // do something with i } 它有两个循环变量：i 和 n，都具有完全正确的作用域。第二个变量 n 用于存储第一个变量的极限，避免了每次迭代中冗余计算的成本。 如果循环涉及一个方法调用，并且保证在每次迭代中返回相同的结果，应该使用这个习惯用法。\n58. for-each 循环优于传统的 for 循环 🌸 建议 🌱 for-each 隐藏迭代器或索引变量，可消除混乱和出错。\n🌱 : 表示 “在\u0026hellip;里面”。使用 for-each 循环不会降低性能。\n🥀 以下情况不应该使用 for-each：\n🌰 破坏性过滤。如果需要遍历一个集合并删除选定元素，需要使用显式的迭代器，以便调用其 remove()。\n🌰 转换。遍历时需要替换其中元素的值，需要 List 迭代器或数组索引来替换元素的值。\n🌰 并行迭代。如果需要并行遍历多个集合，那么需要显式地控制迭代器或索引变量，以便所有迭代器或索引变量都可以同步执行。\n🌻 案例 💐 使用 Collection.removeIf() 可避免显式的遍历（Java8）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public interface Collection\u0026lt;E\u0026gt; extends Iterable\u0026lt;E\u0026gt; { default boolean removeIf(Predicate\u0026lt;? super E\u0026gt; filter) { Objects.requireNonNull(filter); boolean removed = false; final Iterator\u0026lt;E\u0026gt; each = interator(); while (each.hasNext()) { if (filter.test(each.next)) { each.remove(); removed = true; } } return removed; } } 59. 了解并使用库 🌸 建议 能用库方法就用库方法。\n具有算法背景的高级工程师花了大量时间设计、实现和测试库方法，然后将库方法展示给该领域的几位专家，以确保库方法是正确的。 这些库方法经过 beta 测试、发布，并被数百万程序员广泛使用了近 20 年。\n🌱 使用标准类库的好处：\n🌰 利用编写它的专家的知识和以前使用它的人的经验。 🌰 不必浪费时间为那些与你的工作无关的问题编写专门的解决方案。 🌰 随着时间的推移，它们的性能会不断提高，无需付出任何努力。（版本更新） 🌰 可以将代码放在主干中。这样的代码更容易被开发人员阅读、维护和复用。 🌱 在每个主要版本中，都会向库中添加许多特性，了解这些新增特性是值得的。\n🍀 每个程序员都应该熟悉 java.lang、java.util 和 java.io 的基础知识及其子包。 其他库的知识可以根据需要获得。尤其是：\n🌰 java.util.Collections 🌰 java.util.Streams 🌰 java.util.concurrent 🍀 如果你在 Java 平台库中找不到你需要的东西，你的下一个选择应该是寻找高质量的第三方库，比如谷歌的优秀的开源 Guava 库。如果你无法在任何适当的库中找到所需的功能，只能自己实现它。\n🌻 案例 💐 从 Java 7 开始，就不应该再使用 Random。\n🌰 在大多数情况下，选择的随机数生成器现在是 ThreadLocalRandom。 它能产生更高质量的随机数，而且速度非常快。ThreadLocalRandom.current().nextInt(100)\n🌰 对于 Fork Join Pool 和并行 Stream，使用 SplittableRandom。\n假设你想要生成 0 到某个上界之间的随机整数，许多程序员会编写一个类似这样的小方法：\n1 2 3 4 5 // 有严重缺陷 static Random rnd = new Random(); static int random(int n) { return Math.abs(rad.nextInt()) % n; } 它有三个缺点:\n🌩 n 是小的平方数，随机数序列会在相当短的时间内重复 🌩 如果 n 不是 2 的幂，那么平均而言，一些数字将比其他数字更频繁地返回 🌩 在极少数情况下会返回超出指定范围的数字 Integer.MAX_VALUE 应该直接使用类库 Ramdom.nextInt(n) ，而不是自己封装\n1 public int nextInt(int n); 🌾 Linux curl in Java 9\n假设你想编写一个程序来打印命令行中指定的 URL 的内容（这大致是 Linux curl 命令所做的）。在 Java 9 之前，这段代码有点乏味，但是在 Java 9 中，transferTo() 被添加到 InputStream 中。这是一个使用这个新方法执行这项任务的完整程序：\n1 2 3 4 5 public static void main(String[] args) throws IOException { try (InputStream in = new URL(args[0]).openStream()) { in.transferTo(System.out); } } 60. 若需要精确答案就应避免使用 float double 🌸 建议 🌱 float 和 double 类型特别不适合进行货币计算，因为不能将 0.1（或 10 的任意负次幂）精确地表示。 1 2 // 0.6100000000000001 System.out.println(1.03 - 0.42); 🍀 数值不是太大，可以使用 int 或 long 🌰 如果数值不超过 9 位小数，可以使用 int 🌰 如果不超过 18 位，可以使用 long 🌰 如果数量可能超过 18 位，则使用 BigDecimal 例如：在微信支付的 Java SDK 中，货币的类型为 int，结算单位为 分； 在支付宝支付的 Java SDK 中，货币的类型为 String，结算单位为 元\n🌱 使用 BigDecimal 类型代替 double / float。注意，使用 BigDecimal 的 String 构造函数而不是它的 double / float 构造函数。 61. 基本数据类型优于包装类 🌸 建议 🌱 Java 类型系统由两部分组成：\n🌰 基本类型（primitive type）：int double boolean 🌰 引用类型（reference type）：String List 每个基本类型都有一个对应的引用类型，称为包装类型。 🌱 基本类型和包装类型之间有三个主要区别：\n🌰 基本类型只有它们的值，而包装类型具有与其值不同的标识 🌰 基本类型只有全功能值，而每个包装类型除了对应的基本类型的所有功能值外，还有一个非功能值，即 null 🌰 基本类型比包装类型更节省时间和空间 🍀 要有选择，就应该优先使用基本类型，而不是包装类型。基本类型更简单、更快。\n🥀 以下情况必须使用包装类型：\n🌰 作为集合中的元素、键和值 🌰 必须使用包装类型作为类型参数，Java 不允许使用基本类型。如 ThreadLocal\u0026lt;Integer\u0026gt; 🌰 进行反射方法调用时，必须使用包装类型 🌻 案例 🌾 以下三个例子为常见的包装类型问题：\n🌩 将 == 操作符应用于包装类型几乎都是错误的\n1 2 🙅‍♂️ Comparator\u0026lt;Integer\u0026gt; naturalOrder =(i, j) -\u0026gt; (i \u0026lt; j) ? -1 : (i == j ? 0 : 1); 表达式 i \u0026lt; j 会使 i 和 j 引用的 Integer 实例自动拆箱。 表达式 i == j 对两个对象引用执行比较，返回 false。\n1 2 3 4 5 🙆 Comparator\u0026lt;Integer\u0026gt; naturalOrder = (iBoxed, jBoxed) -\u0026gt; { int i = iBoxed, j = jBoxed; // 自动拆箱 return i \u0026lt; j ? -1 : (i == j ? 0 : 1); }; 🌩 NullPointerException\n1 2 3 4 5 6 7 public class Unbelievable { static Integer i; public static void main(String[] args) { if (i == 42) System.out.println(\u0026#34;Unbelievable\u0026#34;); } } 计算表达式 i == 42 时抛出 NullPointerException。空对象引用自动拆箱，将得到一个 NullPointerException。\n🌩 严重的性能问题\n1 2 3 4 5 6 7 public static void main(String[] args) { Long sum = 0L; for (long i = 0; i \u0026lt; Integer.MAX_VALUE; i++) { sum += i; } System.out.println(sum); } 局部变量 sum，它是包装类型 Long，而不是基本类型 long。变量被反复装箱和拆箱（超出缓存部分时），导致产生明显的性能下降。\n62. 其他类型更合适时，应避免使用字符串 🌸 建议 🌱 当存在或可以编写更好的数据类型时，应避免将字符串用来表示对象。\n🌱 如果使用不当，字符串比其他类型更麻烦、灵活性更差、速度更慢、更容易出错。\n🍀 字符串不适合代替其他的值类型。\n🌰 如果是数值类型，则应将其转换为适当的数值类型，如 int、float 或 BigInteger。 🌰 如果是问题的答案，如“是”或“否”这类形式，则应将其转换为适当的 Enum 或 boolean。 🌰 更一般地，如果有合适的值类型，无论是基本类型还是对象引用，都应该使用它；如果没有，应该写一个。 🌱 字符串不适合代替枚举类型。\n🌱 字符串不适合代替聚合类型。\n如果一个实体有多个组件，将其表示为单个字符串通常是很不合适的。 例如，下面这行代码来自一个真实的系统标识符：\n1 String compoundKey = className + \u0026#34;#\u0026#34; + i.next(); 这种方法有很多缺点：如果用于分隔字段 # 的字符出现在其中一个字段中，可能会导致混乱。要访问各个字段，你必须解析字符串。不能提供 equals、toString 或 compareTo 方法，但必须接受 String 提供的行为。 更好的方法是编写一个类来表示聚合，通常是一个私有静态成员类。（Item-24）。\n🍀 字符串不适合代替 capabilities\n有时，字符串用于授予对某些功能的访问权。\n例如，考虑线程本地变量机制的设计。这样的机制提供了每个线程都有自己的变量值。 这种方法的问题在于：字符串键表示线程本地变量的共享全局名称空间。 为了使这种方法有效，客户端提供的字符串键必须是唯一的：如果两个客户端各自决定为它们的线程本地变量使用相同的名称，它们无意中就会共享一个变量，这通常会导致两个客户端都失败。 而且安全性很差。恶意客户端可以故意使用与另一个客户端相同的字符串密钥来非法访问另一个客户端的数据。\n63. 当心字符串连接引起的性能问题 🌸 建议 🌱 不要使用字符串连接操作符合并多个字符串，除非性能无关紧要。使用字符串串联运算符 +，重复串联 n 个字符串，需要 n 的平方级时间。\n🍀 使用 StringBuilder 代替 String\n64. 通过接口引用对象 🌸 建议 🍀 优先使用接口而不是类来引用对象。如果存在合适的接口类型，那么应该使用接口类型声明参数、返回值、变量和字段。\n🌱 使用接口作为类型的习惯，程序将更加灵活。\n🥀 以下情况使用 类 来引用对象：\n🌰 没有合适的接口存在 String 和 BigInteger 🌰 框架的基本类型是类，不是接口 java.io 🌰 实现接口的类提供了接口中不存在的额外方法 PriorityQueue 中实现了 Queue 不存在的 comparator 🌻 案例 🌾 优先使用接口作为类型 1 2 3 4 5 🙆 Set\u0026lt;Son\u0026gt; sonSet = new LinkedHashSet\u0026lt;\u0026gt;(); 🙅‍♂️ LinkedHashSet\u0026lt;Son\u0026gt; sonSet = new LinkedHashSet\u0026lt;\u0026gt;(); 65. 接口优先反射机制 🌸 建议 🌱 核心反射机制 java.lang.reflect 提供对任意类的编程访问。给定一个 Class 对象，可以获得 Constructor、Method、Filed 实例。\n🌱 通过过调用 Constructor、Method、Filed 实例上的方法，可以构造底层的实例、调用底层类的方法、访问底层类中的字段。\n🌰 Method.invoke() 🥀 反射允许一个类使用另一个类，即使在编译前者时后者并不存在。然而，这种能力是有代价的：\n🌰 失去了编译时类型检查的所有好处，包括异常检查。 🌰 执行反射访问所需的代码既笨拙又冗长。写起来很乏味，读起来也很困难。 🌰 性能降低。 🍀 如果你对应用程序是否需要反射有任何疑问，那么它可能不需要。\n🌱 如果必须用到在编译时无法获取的类，在编译时存在一个适当的接口或超类来，可以用反射方式创建实例，并通过它们的接口或超类正常地访问它们。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public static void main(String[] args) { // Translate the class name into a Class object Class\u0026lt;? extends Set\u0026lt;String\u0026gt;\u0026gt; cl = null; try { cl = (Class\u0026lt;? extends Set\u0026lt;String\u0026gt;\u0026gt; cl = null) Class.forNmae(args[0]) // Unchecked cast } catch (ClassNotFoundException e) { fatalError(\u0026#34;Class not found.\u0026#34;); } // Get the constructor Constructor\u0026lt;? extends Set\u0026lt;String\u0026gt;\u0026gt; cons = null; try { cons = cl.getDeclaredConstructor(); } catch (NoSuchMethodException e) { fatalError(\u0026#34;No parameterless constructor\u0026#34;); } // Instantiate the set Set\u0026lt;String\u0026gt; s = null; // 🙋‍♂️ use interface try { s = cons.newInstance(); } catch (IllegalAccessException e) { fatalError(\u0026#34;Constructor not accessible\u0026#34;); } catch (InstantiationException e) { fatalError(\u0026#34;Class not instantiable.\u0026#34;); } catch (InvocationTargetException e) { fatalError(\u0026#34;Constructor threw \u0026#34; + e.getCause()); } catch (ClassCastException e) { fatalError(\u0026#34;Class doesn\u0026#39;t implement Set\u0026#34;); } // Exercise the set s.addAll(Arrays.asList(args).subList(1, args.length)); System.out.println(s); } 🥀 上例中反射机制的缺点\n🌰 产生 6 个运行时异常 🌰 根据类名生产实例需要 25 行冗长代码，而调用构造器只需要一行。 🌱 反射的合法用途（很少）是管理类对运行时可能不存在的其他类、方法或字段的依赖关系。\n🌱 如果编写的程序必须在编译时处理未知的类，则应该尽可能只使用反射实例化对象，并使用在编译时已知的接口或超类访问对象。\n66. 谨慎地使用本地方法 🌸 建议 🌱 非常不建议使用本地方法。JVM 变得更快了，并且 Java 平台的成熟，它提供了对许多以前只能在宿主平台中上找到的特性。 例如，Java 9 中添加的流 API 提供了对 OS 流程的访问。\n🥀 使用本地方法有严重的缺点： 🌰 本地语言不安全（Item-50），使用本地方法的应用程序不再能免受内存毁坏错误的影响。 🌰 Java 更依赖于平台，因此使用本地方法的程序的可移植性较差。 🌰 它们更难调试。 🌰 如果不小心，本地方法可能会降低性能，因为垃圾收集器无法自动跟踪本地内存使用情况，而且进出本地代码会产生相关的成本。 🌰 本地方法需要“粘合代码”，这很难阅读，而且编写起来很乏味。 67. 谨慎地进行优化 🌸 建议 🍀 优化弊大于利，尤其是如果过早地进行优化。在此过程中，你可能会生成既不快速也不正确且无法轻松修复的软件。\n🍀 不要为了性能而牺牲合理的架构。努力编写好的程序，而不是快速的程序。\n🍀 好的程序体现了信息隐藏的原则：在可能的情况下，它们在单个组件中本地化设计决策，因此可以在不影响系统其余部分的情况下更改单个决策\n🍀 不优化不意味着在程序完成之前可以忽略性能问题。实现上的问题可以通过以后的优化来解决，但是对于架构缺陷，如果不重写系统，就不可能解决限制性能的问题，特别是在设计API、线路层协议和持久数据格式时。\n🍀 再多的底层优化也不能弥补算法选择的不足。\n68. 遵守被广泛认可的命名约定 🌸 建议 🌱 Java 平台有一组完善的命名约定，其中许多约定包含在《The Java Language Specification》\n🌰 typographical 字面约定 🌰 grammatical 语法约定 🌱 字面惯例示例：\nIdentifier Type Example Package or module org.junit.jupiter.api, com.google.common.collect Class or Interface Stream, FutureTask, LinkedHashMap, HttpClient Method or Field remove(), groupingBy(), getCrc() Constant Field MIN_VALUE, NEGATIVE_INFINITY Local Variable i, denom, houseNum Type Parameter T, E, K, V, X, R, U, V, T1, T2 🌱 语法命名约定比排版约定更灵活，也更有争议。\n","date":"2022-03-30T14:02:02+08:00","image":"https://emerywan.github.io/blog/p/effective-java/general-programming/effective-java_hu8285674e0bb74a2ea271ae0a19ba75ab_128063_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/effective-java/general-programming/","title":"通用程序设计"},{"content":" 🚲 转到 https://nlp.letout.cn 🔔 Long Shorter Term Memory ➡️\n这一节，将介绍 LSTM (Long Shorter Term Memory)，以及用 pytorch 实现 LSTM 。\nLSTM 是一种 RNN 模型，是对 simple RNN 的改进，LSTM 可以避免梯度消失的问题，可以有更长的记忆。LSTM 的论文在 1997 年发表。\nHochreiter and Schmidhuber.\tLong short-term\tmemory. Neural computation, 1997.\n🔖 LSTM LSTM 也是一种循环神经网络，原理跟 simple RNN 差不多，每当读取一个新的输入 $x$，就会更新状态 $h$。\nLSTM 的结构比 simple RNN 要复杂很多，simple RNN 只有一个参数矩阵， LSTM 有四个参数矩阵。接下来我们具体来看看 LSTM 的内部结构。\n🚠 传送带 LSTM 最重要的设计是这个传送带 Conveyor belt，即为向量 $C$。过去的信息通过传送带，直接送到下一个时刻，不会发生太大的变化。LSTM 就是靠传送带来避免梯度消失的问题。\nLSTM 中有很多个门 gate，可以有选择的让信息通过。\n🚪 Forgate Gate 首先介绍 forget gate 遗忘门。遗忘门由 ☘️ sigmoid 函数，和 🍀 元素积 element wise multiplication 两部分组成。\n🌼 输入 sigmoid 的是一个向量 $a$，sigmoid 作用到向量 $a$ 的每一个元素上，把每一个元素都压到 0 和 1 之间。\n举个例子，假如向量 $a$ 是：[1, 3, 0, -2]，那么，sigmoid 函数将分别作用在这四个元素上。然后分别输出：[0.73, 0.95, 0.5, 0.12] 。\n输入的向量 $a$，与输出的向量 $f$ 应该有相同的维度，这个例子里，向量 $a$ 是四维的，向量 $f$ 也会是四维的。\n🌸 算出 $f$ 向量之后，计算传送带向量 $c$ 与遗忘门向量 $f$ 的元素积。元素积 element wise multiplication 是这样算的：\n$c$ 和 $f$ 都是四维的向量，将它们的每一个元素分别相乘。所以元素积的结果也是个四维的向量。\n这个遗忘门 $f$，有选择的让传送带 $c$ 的值通过：\n🌰 假如 $f$ 的一个元素是 $0$，那么 $c$ 对应的元素不能通过，对应的输出是 $0$；\n🌰 假如 $f$ 的一个元素是 $1$，那么 $c$ 对应的元素就全部通过，对应的输出是 $c$ 本身。\n遗忘门 $f$ 具体是这么算出来的：首先看这张结构图，$f_t$ 是上一个状态 $h_{t-1}$，与当前输入 $x$ 的函数。\n把状态 $h_{t-1}$ 与输入 $x_t$ 做拼接 concatnation，得到更高维度的向量。然后计算矩阵 $w_f$ 与这个向量的乘积，得到一个向量，再用 sigmoid 函数，得到向量 $f_t$，$f_t$ 的每一个元素都介于 0 和 1 之间，遗忘门有一个参数矩阵 $w_f$，需要通过 反向传播 从训练数据里学习。\n🚪 Input Gate 刚才讲了遗忘门，现在来看一看 input gate 输入门。在这张结构图里，输入门 $i_t$，依赖于旧的状态向量 $h_{t-1}$，和新的输入 $x_t$。\n输入门 $i_t$ 的计算类似于遗忘门，把旧的状态 $h_{t-1}$，与新的输入 $x_t$ 做拼接 concatnation，得到更高维的向量。\n然后计算矩阵 $w_i$ 与这个向量的乘积得到一个向量，最后使用激活函数 sigmod，得到向量 $i_t$（$i_t$ 的每一个元素都介于 $0$ 和 $1$ 之间）。\n输入门也有自己的参数矩阵，计作 $W_i$，$W_i$ 也需要从训练数据中学习。\n🆕 New Value 还需要计算新的输入值 new value $\\widetilde{c}_t$，$\\widetilde{c}_t$ 是个向量，计算方法跟遗忘门和输入门都很像。也是把旧状态 $h_{t-1}$，与新输入 $x_t$ 做拼接，再乘到参数矩阵上。\n区别在于激活函数不是 sigmoid，而是双曲正切函数 tanh，所以算出的向量 $\\widetilde{c}_t$ 的元素都介于 (-1, +1)。\n计算 new value $\\widetilde{c}_t$，也需要一个单独的参数矩阵矩阵 $w_c$。\n🚂 更新 传输带 我们已经算出了遗忘门 $f_t$，输入门 $i_t$，以及新的输入值 $\\widetilde{c}_t$，我们还知道传送带旧的值 $c_{t-1}$，现在可以更新传送带 $c$ 了。\n1️⃣ 计算遗忘门 $f_t$ 和传送带旧的值 $c_{t-1}$ 的元素积。\n遗忘门 $f_t$，和传送带 $c_{t-1}$ 是维度相同的向量，算出的乘积也是个向量。遗忘门 $f_t$，可以选择性的遗忘 $c_{t-1}$ 中的一些元素，如果 $f_t$ 中的一个元素是 $0$，那么 $c_{t-1}$ 相应的元素就会被遗忘。\n上一步通过 🚪 遗忘门 选择性删除掉了传送带 $c_{t-1}$ 的一些元素，现在要往传送带上添加新的信息。\n2️⃣ 计算输入门 $i_t$，和新的输入值 $\\widetilde{c}_t$ 的元素积。\n输入门 $i_t$ 和新的值 $\\widetilde{c}_t$ 都是维度相同的向量，他们的乘积也是维度相同的向量，把乘积加到传送带上，这样就完成了对传送带的一轮更新。\n用遗忘门删除了传送带上的一些信息，然后用遗忘门输入加入新的信息，得到了传送带新的值 $c_t$，到现在，已经更新完传送带 $c$ 。\n🚪 Output Gate 最后一步是计算 LSTM 的输出，也就是状态向量 $h_t$。\n$h_t$ 是这么计算的：首先计算输出门 $o_t$，输出门 $o_t$ 跟前面的遗忘门，输入门的计算基本一样。\n把旧的状态 $h_{t-1}$，与新的输入 $x_t$ 做拼接，得到更高维的向量，然后算矩阵 $W_o$ 与这个向量的乘积，得到一个向量，最后使用激活函数 sigmod 得到向量 $o_t$。$o_t$ 的每一个元素都介于 (0, 1)，输出门也有自己的参数向量 $W_o$，$W_o$ 也需要从训练数据中学习。\n现在计算状态向量 $h_t$，对传送带 $c_t$ 的每一个元素求双曲正切tanh，把元素全都压到 (-1, +1) 区间。\n然后，求这两个向量的元素积，这个红色向量是刚刚求出的输出门 $o_t$，这样就得到了状态向量 $h_t$。\n看一下结构图，$h_t$ 他有两份 copys，$h_t$ 的一份 copy 传输到了下一步，另一份 copy 成了 LSTM 的输出。\n到第 t 步为止，一共有 t 个向量 $x$ 被输入了 LSTM，我们可以认为所有这些 $x$ 向量的信息，都积累在了状态 $h_t$ 里面。\n🧮 LSTM 的参数数量 我们来算一下 LSTM 的参数数量，LSTM 有 ❶ 遗忘门；❷ 输入门；❸ 新的输入；❹ 输出门。\n这四个模块都有各自的参数矩阵 $w$，所以一共有 4 个参数矩阵，矩阵的行数是：$shape(h)$，列数是： $shape(h)+shape(x)$\n所以，LSTM 参数的数量是：\n$4 * shape(h) * [ shape(h) + shape(x)]$\n🛠 实现 LSTM Doing\n🎐 总结 总结一下这一节的内容，这节介绍了 LSTM 模型和用 PyTorch 的实现。\nLSTM 和 simple RNN 主要的区别，是用了一条传送带，让过去的信息可以很容易传输到下一时刻，这样就有了更长的记忆。\nLSTM 的表现总是比 simple RNN 要好，所以当我们想使用 RNN 的时候就用 🙋‍♂️ LSTM 模型，而不要用 🙅‍♂️ simple RNN 模型。\nLSTM 有四个组件，分别是：\n🚪 Forget Gate 遗忘门 🚪 Input Gate 输入门 🆕 New Value 新的输入 🚪 Output Gate 输出门 这四个组件各自有一个参数矩阵，所以一共有四个参数矩阵，LSTM 参数的数量是：\n$4 * shape(h) * [ shape(h) + shape(x)]$\n下一节将介绍：\nstacked RNN bi-directional RNN 预训练 ⛓ 参考 🔗 https://github.com/wangshusen/DeepLearning/blob/master/Slides/9_RNN_3.pdf 🔗 https://colah.github.io/posts/2015-08-Understanding-LSTMs/ 🔗 https://www.youtube.com/watch?v=vTouAvxlphc 🔗 https://www.bilibili.com/video/BV1UK4y1d7xa ","date":"2022-03-19T20:36:14+08:00","image":"https://nlp.letout.cn/img/banner.png","permalink":"https://emerywan.github.io/blog/p/nlp-in-action/long-short-term-memory/","title":"Long Shorter Term Memory"},{"content":" 🚲 转到 https://nlp.letout.cn 🔔 文本处理与词嵌入 ➡️\n本节主要内容为 文本处理 Text Processing 和 词嵌入 Word Embedding。本节和下面两节内容都会使用 IMDb 电影评论的数据，用来搭建机器学习模型分析电影评论。\n🌱 IMDb IMDb 是最有名的电影评论网站，用户可以在 IMDb 上给电影打分，1 分是非常讨厌，10 分是非常喜欢，如果乐意，还可以写一段电影评论。\n如果不给你看分数，只给你看评论，你大概能猜到用户打的分数，但你的猜测可能不太准确。如果换种方式，让你判断电影评论是 正面 positive 的还是 负面 negative 的，你应该会有很高的准确率。有人从 IMDb 上爬了 5 万条电影评论，这些评论都是很极端的，都是强烈的喜欢，或者强烈反感。这个二分类问题对于人来说很简单，人读一下电影评论就能轻易知道这是正面评价还是负面评价，人应该能有 100% 的准确率，这个数据集被分成两半，2 万 5 千条作为训练数据 Train，另外 2 万 5 千条作为测试数据 Test。\n你可以在下面的链接中获取到数据集：https://ai.stanford.edu/~amaas/data/sentiment/\n🔖 文本处理文本处理 在词嵌入 Word Embedding 和搭建机器学习模型之前，首先要进行文本处理，将文本变成序列 Sequence，文本处理很无聊，但我们应该重视它，文本处理的好坏，会直接影响机器学习模型的准确率。\n🚀 Tokenization 文本处理的第一步是 Tokenization，把文本分割成很多 tokens，这里我们把文本分割成很多单词，一个 token 就是一个单词（假如你把文本分割成字符，那么一个 token 就是一个字符），做完 Tokenization，一个很长的字符串就被分割成一个很多单词的列表。\nTokenization 看起来很简单，但是讲究很多。比如：\n🌰 是否应该把大写变成小写？ 通常情况下应该把大写变成小写，大小写单词通常是一个意思；但有时候会混淆单词（Apple -\u0026gt; apple），比如 Apple 是苹果公司，apple 是水果，大小写的 apple 并不是相同的单词。\n🌰 去除停用词。stop word 有些应用会去除 stop word，它是 the、a、of 等最高频的单词，这些词几乎出现在所有的句子里，对这个二分类问题几乎是没有帮助。\n🌰 拼写纠错。 用户发电影评论的时候，大部分情况下并不会仔细检查，所以写的东西难免会有拼写错误，所以做拼写纠错通常是有用的。\n这里只是举了几个例子，实际上做 Tokenization 的时候需要做大量的工作，Tokenization 看似简单，但实际上并不容易。\n🧰 Build Dictionary 第二步是建立一个字典。可以先统计词频，去掉一些低频词，让后让每个单词对应一个正整数，比如让 the -\u0026gt; 1; cat -\u0026gt; 2; sat -\u0026gt; 3。有了这个字典，就可以把每个单词对应到一个整数，这样一来，一句话就可以用正整数的列表表示，这个列表被称为序列 Sequences。\n如果有必要的话，还得进一步做 one-hot encoding，把单词表示成 one-hot 向量。\n在电影评论的例子里，数据是 5 万条电影评论，每条电影评论可以表示成一个字符串。做完 Tokenization 和 Encoding 后，每条电影评论都会转换成一个 Sequences，也就是一个正整数的列表。\n电影评论有长有短，有人只能写几个字的评论，有人能洋洋洒洒写几千字，所以得到的这些 Sequences 的长度也各不相同。比如这两条 Sequences 的长度分别是 52 和 90。\n这就造成了一个问题，训练数据没有对齐，每条 Sequences 都有不同的长度。做机器学习的时候，我们需要把数据存储到矩阵或者张量里，每条序列都得有相同的长度，需要把序列对齐。\n解决方案是这样的：我们可以固定长度为 $w$。假如一个序列长度太长，超过了 $w$ 个词，就砍掉前面的词，只保留最后面 $w$个词（当然保留最前面 $w$ 个词也同样可以）；假如一个序列太短，不到 $w$ 个词，那么就做 zero padding 用 0 来补齐，把长度增加到 $w$。\n这样一来，所有序列的长度都是 $w$，可以存储到一个矩阵里。\n🍀️ 词嵌入 文本处理已经完成了，现在每个词都用一个正整数来表示，下一步是 Word Embedding，把每个词都表示为一个一维向量。\n现在每个单词都用一个数字来表示，该怎么把这些 Categorical 特征表示为数值向量呢？\n显然可以做 one-hot encoding，用一个 one-hot 向量来表示一个单词。 比如 good: index = 2，于是使用标准正交积 $e_2$ 来表示，它的第二个元素是 1，其余元素都是 0，$e_2=[0, 1, 0, 0, \u0026hellip;, 0]$\n假如 vocabulary = v，也就是说字典里一共有 $v$ 个单词，那么就需要维度 dimension = v 的 one-hot 向量，要是字典里有 1 万个单词，那么这些 one-hot 向量都是 1 万维的，这样的向量维度是在太高了。下一节介绍 RNN 的时候你会看到，RNN 的参数数量正比于输入向量的维度，我们肯定不想让输入的向量是 1 万维的，否则一层 RNN 将会有好几十万个参数。所以我们要做 Word Embedding，把这些高维 one-hot 向量映射到低维向量。\n具体做法是吧 one-hot 向量 $e_i$ 乘到参数矩阵 $P^T$ 上，矩阵 $P^T$ 的大小是 $d*v$。其中 $d$ 是词向量的维度，由用户自己决定；$v$ 是 vocabulary，表示字典里单词的数量。\n矩阵的乘法的结果记做向量 $x_i$，$x_i$ 就是一个词向量，维度是 $d*1$，如果 one-hot 向量 $e$ 的第三个元素是 1，那么 $x_i$ 就是 $P^T$ 矩阵的第三列，可以看出，$P^T$ 矩阵每一列都是一个词向量。\n同理，下面这个参数矩阵 $P$ 的每一行都是一个词向量。这个矩阵的行数是 $v$，也就是 vocabulary；每一行对应一个单词，矩阵的列数是 $d$，$d$ 是用户决定的，$d$ 的大小会影响机器学习模型的表现，应该用 交叉验证 Cross Validation 用来选择一个比较好的 $d$。\n字典里的第一个词的是 movie，那么第一行就是 movie 的词向量；字典里的第二个词是 good，那么第二行就是 good 的词向量。\n我们的任务是判断电影评论是正面的还是负面的，这个参数矩阵是从训练数据中学习出来的，所以这些词向量都带有感情色彩，假如这些词向量都是二维的，我们就可以在平面坐标系中标出这些词向量。\nfantastic; good; fun 这些词向量都带有正面情感，所以这三个词的词向量学出来都比较接近；同理，poor; boring; mediocre 这些词带有负面情感，所以学出来的词同样也应该比较接近，但是这些词的词向量应该远离正面色彩的词向量。像 movie; is 这样的中性词，没有感情色彩，它们应该在中间。\n🎐 总结 最后总结一下这一章的内容。\n这一节上半部分，说明了文本处理是什么样的。给我们一条电影评论，首先做 Tokenization，把电影评论分割成很多单词，然后把很多单词编码成数字，这样一整条电影评论就可以很多正整数来表示，我们把这个正整数序列叫做 Sequences，就是神经网络中 Embedding 层的输入。由于电影评论的长短不一，得到的 Sequence 的长短也不一样，没办法存储在一个矩阵里，解决方案是 Alignment 对齐。假设最大长度为 20，如果长度大于20，就只保留最后 20 个单词；如果长度不到 20，就用 0 补齐，把长度增加到 20。这样一来，每个 Sequences 长度都相同。\n","date":"2022-03-11T21:14:45+08:00","image":"https://nlp.letout.cn/img/banner.png","permalink":"https://emerywan.github.io/blog/p/nlp-in-action/text-processing-and-word-embedding/","title":"文本处理与词嵌入"},{"content":" 🚲 转到 https://nlp.letout.cn 🔔 RNN ➡️\n这一节我们来学习循环神经网络Recurrent Neural Networks。本节的内容是 Simple RNN，以及用 Pytorch 编程实现 Simple RNN。\n🌱 简介 现在 RNN 没有以前流行，尤其是在自然语言处理上，RNN 已经有一些过时了，如果训练的数据足够多，RNN 的效果不如 Transformer 模型，但是在小规模的问题上，RNN 还是很有用的。\n🔖 如何建模时序数据？ 机器学习中经常用到文本、语音等 时序数据sequential data（按时间顺序记录的数据列，有长度不固定的特点）。\n首先思考一个问题，怎么对这样的时序数据进行建模？ 在上一小节中，我们将一段文字整体输入到一个逻辑回归 Logistic Regression 模型中，让模型来做二分类，这属于一个 one-to-one 模型，一个输入对应一个输出。\n全连接神经网络和卷积神经网络都属于 one-to-one 模型。\n人脑并不会使用 one-to-one 模型处理时序数据，不会把一整段文字全部输入到大脑，我们在阅读的时候，会从左到右阅读一段文字，不断地在大脑里积累信息，阅读一段话之后，你脑子里就积累了一段文字的大意。\none-to-one 模型要求一个输入对应一个输出，比如：输入一张图片，输出每一类的概率值，one-to-one 的模型比较适合这类图片问题，但是不太适合文本问题。\n对于文本问题，输入和输出的长度并不固定，一段话可长可短，所以输入的长度并不固定；输出的长度也不固定，比如将英语翻译成汉语，一句英语有十个单词，翻译成汉语可能有十个字，可能有八个字，也可能是四个字的成语，输出汉语的字数并不固定，由于输入和输出的长度不固定，one-to-one 模型就不太适合了。\n对于时序数据，更好的是 many-to-one 或者是 many-to-many 模型，RNN 就是这样的模型，输入和输出的长度都不固定。所以 RNN 很适合语音，文本等时序序列数据。\n🍀️ RNN RNN 和跟人的阅读习惯很类似：人每次看一个词，会逐渐在大脑里积累信息；RNN 每看一个词，会用状态向量 $h$ 来积累阅读过的信息。\n首先，我们将输入的每个词用 词嵌入word embedding 变成一个词向量 $x$。\n每次把一个词向量输入 RNN，就会更新状态 $h$ ，把新的输入积累到状态 $h$ 里面。\n在 $h_0$中，包含了第一个词 the 的信息，在 $h_1$ 里面，包含了前两个 the cat 的信息；以此类推，状态 $h_2$ 包含 了前三个词 the cat sat 的信息，最后一个状态 $h_t$ 包含了整句话的信息，可以把 $h_t$ 看做 RNN 从整句话 the cat sat on the mat 抽取的特征向量，在更新状态 $h$ 的时候，需要用到参数矩阵 $A$。\n注意：整个 RNN 只有一个参数矩阵 $A$。无论这条链有多长，参数 $A$ 只有一个，$A$ 随机初始化，然后利用训练数据来学习 $A$。下面首先讲解 Simple RNN Model。\n🚀 Simple RNN 我们具体看看，Simple RNN 简单循环神经网络是怎么把输入的词向量 $x$，结合到状态 $h$ 中的。\n我们将上一个状态记做 $h_t-1$，新输入词向量记做 $x_t$，将这两个向量做拼接 concatenation，得到一个更高维的向量。\n图中这个矩阵 $A$ 是 RNN 的模型参数，这里计算矩阵 $A$ 和这个向量的乘积（拼接后的向量），矩阵和向量的乘积是一个向量，然后使用激活函数 tanh 作用在向量的每一个元素上，最后把激活函数的输出记做新的状态 $h_t$。\n这个激活函数式 双曲正切函数 hyperbolic tangent function，输入是任意实数，输出在 $(-1, +1)$ 之间。由于用了双曲正切激活函数，向量 $h_t$ 的每一个元素都在 $(-1, +1)$ 之间。\n这个神经网络的结构图可以这样理解：新的状态 $h_t$，是旧状态 $h_{t-1}$ 和新的输入 $x_t$ 的函数，神经网络模型的参数是 $A$：新的状态 $h_t$，依赖于向量 $h_{t-1}$, 向量 $x_t$ 以及矩阵 $A$。\n🎨 为什么需要使用 tanh 作为激活函数？ 我们思考这样一个问题：为什么需要使用 tanh 作为激活函数？能否将这个激活函数去掉，去掉之后会发生什么呢？\n首先我们做个简化，假设输入的词向量的元素都是 $0$。如图，这等同于输入的词向量 $x_t$ 都去掉，把矩阵 $A$ 右边一半也去掉。\n$x_0 = x_1 = \u0026hellip; = x_{100} = 0$\n这么一来，第 100 维的特征向量 $h_{100} = Ah_{99} = A^2h_{98} = \u0026hellip; = A^{100}h_0$。\n🌰 假设矩阵 $A$ 最大的特征值略小于 1 比如，最大的特征值等于 0.9。那么会发生什么呢？\n$0.9^{100}$ 非常接近于 0 了，所以矩阵 $A^{100}$ 非常接近于 0，那么新的特征向量 $h_{100}$ 也几乎也是一个全零的向量。\n🌰 假设矩阵 $A$ 最大的特征值略大于 1 比如，最大的特征值等于 1.2。\n$1.2^{100}=82817974.522$，所以矩阵 $A^{100}$ 的元素都超级大，$A^{100}$的每个元素都很大，假如循环的次数更多一些，或者 $A$ 的特征值再大一些，状态向量的值就会爆炸。\n假如没有这个激活函数 tanh，数值计算的时候很有可能会出问题，要么计算出的结果全部等于 0，要么爆炸了全部是 NaN: Not a Number。通过使用这个激活函数，每次更新状态 $h$ 后，都会做一个标准化操作 normalization，让 $h$ 恢复到 $(-1, +1)$ 这个合适的区间里。\n🏝️ Simple RNN 模型参数数量 我们来数一下 Simple RNN 有多少个模型参数。\n如图，先看一下这个拼接后向量，这个向量的维度是 $h_{t-1}$ 的维度加上 $x_t$ 的维度：\n所以 $A$ 一定要有 $shape(h)+shape(x)$ 维度这么多列：\n$A$ 的行数等于 $h$ 的维度：\n所以，最终矩阵 $A$ 的大小等于：\n$parameter(A) = shape(h) * [shape(h) + shape(x)]$\n这个乘积 $parameter(A)$ 就是 simple RNN 的最终的参数数量。\n我们来搭一个简单的网络。最底层是一个词嵌入层 Word Embedding Layer，它可以把词映射为词向量。\n词向量的维度由自己设置（这是一个超参数，我们应该使用交叉验证 cross validation 选择最佳的维度），这里设置 $x$ 的维度是 $32$。\n然后下一层是 Simple RNN Layer，输入的是词向量 $x_i$，输出的是状态 $h_i$。\n$h$ 的维度也是由自己设置，我们设置 $h$ 维度为 $32$。这里 $x$ 和 $h$ 的维度都是 $32$，这只是一个巧合而已，$h$ 和 $x$ 的维度通常不一样。\n前面说过，状态向量 $h$ 会积累输入的信息，比如：$h_0$ 包含第一个单词 I 的信息，$h_1$ 包含前两个词 I love 的信息，最后一个状态 $h_t$ 包含整句话 I love the movice so much 的信息。\n我们可以从 PyTorch 中获取所有的状态 $h={h_1, h_2, \u0026hellip;, h_t}$，也可以只获得最后一个状态向量 $h_t$ 的信息。\n$h_t$ 积累了整句话的信息，所有通常使用 $h_t$ 这一个向量就够了，这里我们只使用 $h_t$，把前面的所有状态 ${h_1, h_2, \u0026hellip;, h_{t-1}}$ 全部都丢掉。\n$h_t$ 相当于从文本中提取的特征向量，把 $h_t$ 输入这个分类器 $sigmoid(v^T h_t)$，分类器就会输出一个 0 或 1 之间的数值，0 代表了负面电影评价，1 代表正面电影评价。\n然后我们设置超参数：\n设置 vocabulary = 1000，意思是词典里有 10000 个词汇； embedding_dim = 32，意思是词向量 $x$ 的维度是 $32$； word_num = 500，意思是每条电影评价有 500 个单词，如果超过 500 个单词，就会被截掉，只保留 500 个，如果不够 500，就用 zero_padding 将句子补成长度为 500； state_dim = 32，意思是状态 $h$ 的维度等于 $32$。 👩‍🚒 PyTorch 实现 接下来开始搭网络，首先我们定义一个类 Model，我们让它继承 nn.Model 父类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import torch import torch.nn as nn class Model(nn.Module): def __init__(self, vocabulary_size, embedding_dim, state_dim): super(Model, self).__init__() self.vocabulary_size = vocabulary_size self.embedding_dim = embedding_dim self.state_dim = state_dim self.Embedding = nn.Embedding(self.vocabulary_size, self.embedding_dim) self.RNN = nn.RNN(self.embedding_dim, self.state_dim) self.fc = nn.Linear(self.state_dim, 1) self.sigmoid = nn.Sigmoid() def forward(self, x): x = x.transpose(0, 1) embedded = self.Embedding(x) output, h_n = self.RNN(embedded) h_n = torch.squeeze(h_n, dim=0) result = self.fc(h_n) return self.sigmoid(result) 接下来，我们在构造函数 __init__ 中定义我们的模型结构，并重载 forword 方法。\n首先是词嵌入层 nn.Embedding()，它是把词映射成向量。\n然后是 simple RNN 层 nn.RNN()，需要指定词向量的维度 embedding_dim 和状态向量 $h$ 的维度 state_dim；\n最后是一个全连接层 nn.Linear()，并且会使用 nn.Sigmoid() 作用于它的结果，输入最后一个状态向量 $h$，输出一个 0、1 之间的数。\nPyTorch 中的 RNN 会有两个返回值：output，h_n。\noutput 是 RNN 所有时刻的状态向量集合（矩阵）； h_n 是 RNN 中最后一个状态向量。 这是模型的一个概要， 词嵌入层 Embedding 的输出是一个 $500*32$ 的矩阵，500 的意思是每个句子有 $500$ 个词，32 的意思是每个词用 $32$ 维的词向量表示。\n1 2 3 4 5 6 7 8 9 10 11 ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== Model -- -- ├─Embedding: 1-1 [500, 1, 32] 320,000 ├─RNN: 1-2 [500, 1, 32] 2,112 ├─Linear: 1-3 [1, 1] 33 ├─Sigmoid: 1-4 [1, 1] -- ========================================================================================== Total params: 322,145 Trainable params: 322,145 Simple RNN 每个状态的输出 $h_t$ 都是一个 32 维的向量。我们看一下 RNN 的参数，他有 2080 个参数，它是这样算出来的：\n$shape(h) * (shape(h)+shape(x)) = 32*(32+32)+32 = 2080$\n这是矩阵 $A$ 的大小，后面的 $32$ 的维度来自 intercept，也叫 bias，偏移量。RNN 会默认使用 intercept，但这个不重要，这里暂时不管它。\n剩下的 32 个参数来自于最后一个状态，因为 PyTorch 中的 RNN 会同时输出所有时刻的状态向量集合和最后一个状态向量。\n🧑‍🔧 运行模型 搭好模型之后，初始化模型，然后用训练数据拟合模型。\n我们指定算法是 optim.Adam，损失函数是 nn.BCELoss()，评价标准是准确率 accuracy。\n然后用训练数据拟合模型，我让算法训练 3 个 epochs，只让算法运行 3 个 epochs，是出现了过拟合，3 个 epochs 之后，validate accuracy 会变差。提前让算法停止运行称为 early stoping 提前终止训练，使 validate accuracy 变差之前就停止。\n最后，用测试数据评价模型的表现，把测试数据作为输入，调用 model.evaluate()，返回 loss 和 accuracy，测试的 accuracy，测试的 accuracy 是 84.36%，比上一节中的 逻辑回归好很多（75%）。\n刚才搭模型的时候，只使用了RNN最后一个状态 $h_t$，把之前的状态都丢掉了，想用 $h_0$ 到 $h_t$ 所有状态也可以，但并没有太大区别。\n我们让 RNN 的第一个输出 output，它是一个矩阵，矩阵每一行就是一个状态向量 $h$。\n如果用所有状态，就要加一个 flatten 层，将状态矩阵变成一个向量，然后把这个向量作为分类器的输入，来判断电影是正面的，还是负面的。只要把网络稍作改动就可以了。\n1 torch.flatten(output, start_dim=1, end_dim=2) 🧰 simple RNN 的缺陷 下面看一下 simple RNN 这种简单的模型有什么缺陷。\n举个栗子 🌰 ，现在有这样一个问题，给定半句话，要求预测下一个单词。\n输入是 clouds are in the，正确的输出应该是 sky，如果在大量文本中预测 RNN，应该是有能力做出这样的预测的。在这个例子里，RNN 只需要看最近的几个词，尤其是 clouds are，并不需要更多的上下文看的更远。\n这个例子是对 simple RNN 十分有利，simple RNN 特别擅长这种 short-term dependence，simple RNN 不擅长的是 long-term dependence。\nRNN 的状态 $h$，和之前所有的输入 $x$ 都有函数依赖关系，照理来说，如果改变输入的单词 $x_1$，所有的状态 $h$ 都会发生变化，但实际上，simple RNN 并没有这种性质，所以很不合理。如果把第 100 个状态向量 $h_{100}$，关于输入 $x_1$ 求导，你会发现导数几乎等于 0。\n$\\frac{\\partial h_{100}}{\\partial x_1} \\approx 0$\n导数几乎等于 0 说明什么呢？说明当我们改变 $x_1$时，$h_{100}$ 几乎不会发生任何变化，也就是说状态 $h_{100}$ 和 100 步之前的输入 $x_1$ 几乎没有关系，这显然不合理，说明状态 $h_{100}$ 几乎把很多步之前的输入都给忘记了，simple RNN 的这种遗忘会给后续操作造成很多问题。\n再举个栗子 🌰 ，这是很长的一段话，一开始是 I grow up in China when I was a child, ... ... 到了很多句话之后，有这样一句，I speak fluent ...。\n下一个词应该是 Chinese，我小时候在中国，所有会说流利的中文，然而 simple RNN 不太可能会做出 Chinese 这个正确的预测，因为 RNN 已经把前文给忘记了。simple RNN 擅长的是 short-term dependence，RNN 看到最近的单词是 speak fluent，所以 RNN 知道下一个单词可能是某种语言，可能是 Chinese、English、French、Japanese 等等，但正确答案是 Chinese，因为上文有 I grow up in china when i was child，simple RNN 就像金鱼一样记忆力只有 7 秒，RNN 根本就不记得上文有这句话，所以 I speak fluent ... 预测单词可能是 English , French 等任何一种语言，未必是 Chinese。\n🎐 总结 最后总结一下这一节的内容：\nRNN 是一种神经网络，但是他的结构不同于全连接网络和卷积网络，RNN 适用于文本，语音等时序序列数据，RNN 按照顺序读取每一个词向量，并且在状态向量 $h$ 中积累看到过得信息，$h_0$ 中包含了 $x_0$ 的信息，$h_1$ 中包含了 $x_0$ 和 $x_1$ 的信息，$h_t$ 中积累了之前所有 $x={x_0, x_1, \u0026hellip;, x_t}$ 的信息。\n有一种错误的看法是 $h_t$ 中只包含了 $x_t$ 的信息，这是不对的，$h_t$ 中包含了之前所有输入的信息，可以认为 $h_t$ 代表了 RNN 从整个序列中抽取的特征向量，所有我们只需要 $h_t$ 就可以判断电影评价是正面的还是负面的。\nsimple RNN 有一个参数矩阵 $A$，它可能还会一个 intercept 参数向量 $b$，上面的介绍中忽略了这个参数向量 $b$，这个参数矩阵 $A$ 的维度是：\n$shape(h) * [shape(h) + shape(x)]$\n参数矩阵 $A$ 一开始随机初始化，然后从训练数据上学习。注意：simple RNN 只有一个参数矩阵，不管这个序列有多长，参数矩阵只有一个，所有模块里的参数都是一样的。\nRNN 有一个缺点，RNN 的记忆比较短，会遗忘很久之前的输入 $x$，如果这个时间序列很长，有好几十步，最终 RNN 就会忘记了之前的输入。下一节将介绍 LSTM，LSTM 的记忆会比 simple RNN 长很多，但是 RNN 也还是会有遗忘的问题。\n","date":"2022-03-08T20:36:14+08:00","image":"https://nlp.letout.cn/img/banner.png","permalink":"https://emerywan.github.io/blog/p/nlp-in-action/simple-rnn/","title":"RNN"},{"content":" 🚲 转到 https://nlp.letout.cn 🔔 数据处理基础 ➡️\n🌱 类别特征 机器学习的数据通常有 类别特征 Categorical Features ，我们需要把类别特征 Categorical Features 转化成机器学习模型能理解的数值特征，下面使用一个例子来具体讲解类别特征数据的处理。\n这张表的每一行是一个人的数据，包括：年龄、性别、国籍，我们需要把这些数据变成机器学习模型可以理解的数值特征。\n表格的第一列是年龄，年龄本身就是数值特征，所以可以不用做处理，数值特征的特点是可以比较大小，比如 35 岁的人比 31 岁的年龄大。\n第二列是性别，性别是二元特征，我们可以用一个数来表示性别。用 0 表示女性，用 1 表示男性。这样一来，性别就表示为一个标量：0 / 1。\n第三列是国籍，比如中国，美国，印度。国籍是类别特征，机器学习并不理解国籍，所以我们要把国籍编码成数值向量。世界上约有 197 个国家，我们先用一个 [1 - 197] 的整数表示一个国家。可以建立一个字典，把国籍映射成一个 [1 - 197] 的整数。比如：China:1; US:2; India:3; Japan:4; Germany:5。\n我们要从 1 开始计算，而不能从 0 开始计算。\n做这种映射，国籍就表示成 [1 - 197] 之间的整数。仅仅把国籍表示成 [1 - 197] 的整数还是不行，一个整数只是一种类别，它们之间不能比较大小。US:2; India:3 这个数字并不表示印度大于美国，这些整数只是类别而已，并不是真正的数值特征。\n所以要进一步对国籍做 one-hot encoding ，用 one-hot 向量来表示国籍：\n1 2 China -\u0026gt; 1 -\u0026gt; [1,0,0,0,...,0] US -\u0026gt; 2 -\u0026gt; [0,1,0,0,...,0] 比如，中国对应 1，所以用 197 维的 one-hot 向量 [1,0,0,0...,0] 来表示，其中第一个元素为 1，其余元素都是 0；美国对应 2，这个 197 维的向量 [0,1,0,0...,0] 第二个元素是 1，其余元素都是 0。这样一来，每个国籍就由一个 one-hot 向量表示，一共有 197 个国家，所以每个向量都是 197 维的。\n我们要从 1 开始计算，而不能从 0 开始计算。 因为我们要把 0 保留，用来表示未知或者缺失的国籍。数据库里面经常会有缺失的数据（比如用户没有填写国籍），这样缺失的国籍就用 0 来表示，它的 one-hot 向量就是一个全 0 的向量[0,0,0,0...,0]。\n下面这个例子中，我们用一个 199 维表示一个人的特征。比如这个人 28 岁，女性，国籍是中国。\n其中，一个维度表示年龄，一个维度表示性别，一个 197 维的 one-hot 向量表示国籍。\n这个例子里，这个 36 岁，男性，国籍未知的人的特征是这个 199 维的向量，我们用一个 197 维的全 0 向量表示未知国籍。\n🔖 为什么要用 one-hot 向量表示特征 在处理类别特征的时候，我们使用 one-hot 向量表示国籍，每个国籍都用 197 维的向量表示。为什么要用 one-hot 向量而不用一个数字表示呢？比如用 1 表示中国，2 表示美国，3 表示印度。这样一来，名字就变成了数字，可以做数值计算，而且用一个数字表示的话，可以节省 197 倍的存储空间。当然这是不行的。否则我们就不需要 one-hot encoding 了。\n假设我们使用 1 -\u0026gt; China; 2 -\u0026gt; US; 3 -\u0026gt; India。那么将中国 1 和美国 2 的特征加起来：1+2=3 ，相当于 “中国 + 美国 = 印度”。这样的特征完全不合理。\n使用 one-hot 特征向量更合理。将 China 和 US 的 one-hot 向量加起来，得到 [1,1,0,0,...,0]，第一个和第二个元素都是 1，其余元素都是 0，这个特征向量的解释是：既有中国国籍，又有美国国籍。\n所以做机器学习的时候，不能用一个标量来表示一个类别特征，这种特征做法求和等数值计算是没有意义的。正确的做法是使用 one-hot 向量来表示类别特征。\n🚀 处理文本数据的流程 在自然语言处理的应用中，数据就是文本 document，文本可以分割成很多单词，我们需要把单词表示成数值向量。其中每个单词都是一个类别，如果字典里有一万个单词，那么就有一万的类别，显然单词就是类别特征。我们需要使用处理类别特征的方法，把单词变成数值向量。\n文本处理主要分为三个步骤：\n🔔 把文本分割成单词 🔔 计算每个单词出现的次数 🔔 进行 one-hot 编码 文本处理的第一步是把文本分割成单词。一段话，一篇文章或者一本书可以表示为一个字符串，可以把文本分割成很多单词，这个步骤称为 Tokenization。\n比如说这句话 ... to be or not to be ...， 可以分割成这些单词 [to, be, or, not, to, be]。Tokenization 就是把文本变成单词的列表。\n文本处理的第二步是计算词频，也就是每个单词出现的次数。我们可以用一个哈希表 hash Map 来计算，计算开始之前，哈希表是空的，我们根据以下方式更新哈希表：如果单词 w 不在表里面，说明到目前为止，w 还没有出现在文本里，所以我们要把 w 加入哈希表，并让它的词频等于 1；如果 w 在哈希表里面，说明 w 之前在文本里出现过，只需要把 w 的词频加 1 即可。\n接下来举个例子，我们将挨个处理这个列表里的单词。当处理到单词 to 的时候，首先查一下哈希表，发现哈希表里面有 to，它的词频是 398，说明 to 在文章里已经出现过 398 次了，现在这个单词又出现了一次，于是把表里的词频加 1，变成了 399；当处理到单词 or的时候，在表里找不到，这说明文章里还没有出现过 or 这个单词，第一次出现在文章里，于是我们把 or 插入表里，将词频设置为 1。\n完成统计词频之后，需要把哈希表做一个排序，按照词频递减的顺序进行排列，表的最前面是词频最高的，表最后是词频最低的。然后就把词频换成下标 index，从 1 开始数计数，词频最高的词的 index 是 1。这个例子里，一共有 8 个单词，每个词对应一个 [1, 8] 之间的正整数。这个表称为字典 ，可以把单词映射为一个数字。\n字典里单词的个数称为词汇量 vocabulary。这例子里词汇量等于 8。\n英语里大概有 1 万个常用词，但是统计词频之后，你会发现字典会有几十万甚至上百万个单词。统计词频的目的就是保留常用词，去掉低频词。比如，我们可以保留词频最高的 1 万个单词，删掉其余单词。\n为什么要删掉低频词呢？\n🌰 低频词通常没有意义 很多低频词都是名字实体 name entities，比如我们的名字就是个名字实体，假如我们的名字出现在一个数据集里面，他的频率肯定会很低，在大多数的应用里名字实体没有意义。\n低频词很多都是拼写错误造成的，如果把 prince 的 c 误写成 s，prinse，那么就创造了一个新的单词，这种词的频率也很低，在很多应用里，去掉这种词没有危害。\n🌰 去掉低频词的另一个原因是我们不希望 vocabulary 太大。 下一个步骤做 one-hot encoding 的时候，向量的维度就是字典的大小。字典越大，向量的维度就越高，这会让计算变慢。下一节详细说明词嵌入 Word Embedding 的时候就会看到，字典越大，模型的参数就越会越多，就会容易造成过拟合 overfitting，删掉低频词就会大幅减小 vocabulary。\n文本处理的第三步就是对单词做 one-hot encoding，通过查字典，把单词映射成一个正整数，一个单词的列表就映射成了一个正整数的列表；如果有必要就继续把这些正整数变成 one-hot 向量。这些 one-hot 向量的维度正好等于 vocabulary，在这个例子里面，字典的长度是 8，所以 one-hot 维度就等于 8。\n上面说过，字典里的低频词可能会被删掉，所以有些词在字典里找不到，例如把 be 错误拼写成单词 bi，这个词在字典里找不到，one-hot encoding 时，可以忽略这个词，也可以把它编码成全 0 向量。\n🎐 总结 最后总结一下这一节的内容。\n部分机器学习的数据会具备类别特征 Categorical Features，机器学习模型无法理解，我们需要将其转换成数值特征。类别特征的类别会被映射成一个从 1 开始计算的整数，0 被用来表示缺失或者未知的类别，并且使用 one-hot 向量，能很好的表示类别特征的意义。\n文本处理主要有三个步骤，第一步 tokenization 把文本分割成单词的列表；第二步建立了一个字典vocabulary，把单词映射成一个正整数；第三步进行 one-hot encoding，将分割后的单词列表映射成正整数的列表或变成 one-hot 向量。\n","date":"2022-03-01T02:02:02+08:00","image":"https://nlp.letout.cn/img/banner.png","permalink":"https://emerywan.github.io/blog/p/nlp-in-action/data-processing/","title":"数据处理基础"},{"content":"注解 内置注解 @Override\n@Deprecated\n@SuppressWarning\n元注解 元注解的作用是：注解其他注解。Java 中定义了四个元注解类型，用来对其他注解类型做说明。\n@Target 描述注解的使用范围，是用于类、方法还是属性等。\n1 2 3 4 5 6 7 8 9 10 11 12 // 该注解的作用范围为 // TYPE 描述类、接口(包括注解类型) 或enum声明 // FIELD 描述域即类成员变量 // METHOD 描述方法 // PARAMETER 描述参数 // CONSTRUCTOR 描述构造器 // LOCAL_VARIABLE 描述局部变量 @Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE}) @Retention(RetentionPolicy.SOURCE) public @interface SuppressWarning { String[] value(); } @Retention SOURCE 源文件中有效 CLASS class文件中有效 RUNTIME 运行时有效 注解的生命周期，在什么级别保留注解。\n1 2 3 4 @Target(ElementType.METHOD) @Retention(RetentionPolicy.SOURCE) // 源文件中有效 public @interface Override { } @Documented 说明该注解将被包含在 javadoc 中\n@Inherited 说明子类可以继承父类中的该注解\n自定义注解 使用 @interface 自定义注解，会默认继承 java.lang.annotation.Annotation 接口。\n只有一个参数，一般用 value 作为参数名。\n可以用 default 声明默认值。\nString value() default \u0026quot;\u0026quot;; 反射 反射机制允许程序在执行期间，使用反射 API 获取类的信息，并操作任意对象的内部属性及方法。\n类加载后，在方法区中会产生一个 java.lang.Class 类型的对象，包含了类的信息。反射通过这个类，可以获取类的结构与信息。\n在 JVM 中，每个类只存在一个 Class 对象，无论使用什么方式获取，都是一样的。（加载器每个类只会加载一次）\n1 2 3 4 5 Class c = Class.forName(\u0026#34;cn.letout.Person\u0026#34;); Class c = person.getClass(); Class c = Person.class; 获取类的信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 Class\u0026lt;?\u0026gt; clazz = Class.forName(\u0026#34;cn.letout.Test\u0026#34;); // 类的信息 clazz.getName(); // 包名 + 类名 clazz.getSimpleName(); // 类名 // 类的属性 Field[] publicFields = clazz.getFields(); // 获取 public 属性 Field[] fields = clazz.getDeclaredFields(); // 获取所有属性 Field nameField = clazz.getField(\u0026#34;name\u0026#34;); // 获得指定属性 String name = nameField.getName(); // 获得属性名 Class\u0026lt;?\u0026gt; type = nameField.getType(); // 获得属性类型 // 类的方法 Method[] publicMethods = clazz.getMethods(); Method[] methods = clazz.getDeclaredMethods(); Method getNameMethod = clazz.getMethod(\u0026#34;getName\u0026#34;); // 获得指定方法 Method setNameMethod = clazz.getMethod(\u0026#34;setName\u0026#34;, String.class); String name = setNameMethod.getName(); // 获取方法名 Class\u0026lt;?\u0026gt; type = setNameMethod.getReturnType(); // 获取方法返回类型 // 类的构造器 Constructor[] publicConstructors = clazz.getConstructors(); Constructor[] constructors = clazz.getDeclaredConstructors(); // 类的注解 Annotation[] annotations = clazz.getAnnotations(); Annotation testAnnotation = clazz.getAnnotation(TestAnnotation.class); String value = testAnnotation.value(); 创建类的对象 1 2 3 4 5 6 7 8 9 10 Class\u0026lt;Person\u0026gt; clazz = Person.class; Person person = clazz.getConstructor().newInstance(); Person person = clazz.getConstructor(String.class).newInstance(\u0026#34;name\u0026#34;); // 获取私有构造方法 // 使用 getDeclaredConstructor() 获取非 public 构造方法 Constructor\u0026lt;Person\u0026gt; constructor = clazz.getDeclaredConstructor(String.class); constructor.setAccessible(true); Person person = constructor.newInstance(\u0026#34;name\u0026#34;); 调用类的方法 使用反射机制，调用类的方法。\n1 2 3 4 5 6 7 8 9 10 11 Class clazz = Class.forName(\u0026#34;cn.letout.Person\u0026#34;); Object instance = clazz.newInstance(); // 获取 public 方法 Method method = clazz.getMethod(\u0026#34;test\u0026#34;, String.class); method.invoke(instance, \u0026#34;参数\u0026#34;); // 获取非 public 方法 Method privateMethod = clazz.getDeclaredMethod(\u0026#34;fun\u0026#34;, String.class); privateMethod.setAccessible(true); privateMethod.invoke(instance, \u0026#34;参数\u0026#34;); 修改类的属性 1 2 3 4 5 6 Class clazz = Class.forName(\u0026#34;cn.letout.Person\u0026#34;); Object instance = clazz.newInstance(); Field filed = clazz.getDeclaredField(\u0026#34;name\u0026#34;); field.setAccessible(true); field.set(instance, \u0026#34;Emery\u0026#34;); 反射可以修改 final 修饰的常量属性。 如果 JVM 没有进行内联优化，可直接获取对应的值。如果 JVM 对其进行了内联优化，编译阶段已经将其替换成了常量的值，原代码可能输出原值。\n1 2 3 4 // final name System.out.println(person.name); // 内联优化 System.out.println(\u0026#34;Emery\u0026#34;); 反射获取注解 1 2 3 4 5 6 7 8 9 10 11 12 13 // 获取类注解 Annotation[] annotations = clazz.getAnnotations(); Annotation\u0026lt;Test\u0026gt; testAnnotation = clazz.getAnnotation(Test.class); // 获取属性注解 Field[] declaredFields = clazz.getDeclaredFields(); for (Field field : declaredFields) { Annotation\u0026lt;Test\u0026gt; testAnnotation = field.getAnnotation(Test.class); if (testAnnotation ! = null) { String value = testAnnotation.value(); // ... ... } } ","date":"2022-01-28T01:02:02+08:00","permalink":"https://emerywan.github.io/blog/p/java/annotation-and-reflection/","title":"注解与反射"},{"content":"做自然语言处理写了挺久的 Python ，经常要处理数据。用 Python 中的处理数据真的挺爽的 🫣，我平常都喜欢把各种数据都往 dict（也就是 Java 中的 map） 和 json 上转，用 Python 处理这个各种方便。 最近再写 Java 就经常“手残”，所以总结一下 Java 中处理 Map。\n⭐️ 遍历方式 Java 遍历 Map，要么就是遍历它的 Map.Entry\u0026lt;K,V\u0026gt; \u0026lt;- entrySet()，要么就是遍历它的 key KeySet \u0026lt;- keySet()。主要可以用下面四种方式遍历：\nIterator\nForEach\nLambda\nStream\n除非特殊需要，尽量使用后 3 种遍历方式，使用 Iterator 可能更容易造成一些错误（Effective Java - 58：for-each 优先于 for 循环）。\n在一些 for-each 不能胜任的地方，其实也有很对内置方法能够完成操作，不仅更加直观，而且非常易用。比如删除操作：Collection#removeIf() Java 1.8+。\nForEach EntrySet 1 2 3 4 5 6 7 8 Set\u0026lt;Map.Entry\u0026lt;K, V\u0026gt;\u0026gt; entrySet(); // --- for (Map.Entry\u0026lt;String, String\u0026gt; entry : map.entrySet()) { String key = entry.getKey(); String value = entry.getValue(); } KeySet 1 2 3 4 5 6 7 Set\u0026lt;K\u0026gt; keySet(); // --- for (String key : map.keySet()) { String value = map.get(key); } Lambda 1 2 3 4 5 6 7 8 9 10 11 12 public class HashMap\u0026lt;K,V\u0026gt; extends AbstractMap\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt;, Cloneable, Serializable { @Override public void forEach(Biconsumer\u0026lt;? super K, ? super V\u0026gt; action) { } } // --- map.forEach((key, value) -\u0026gt; { // key // value }) Stream Steram 1 2 3 4 map.entrySet().stream().forEach((entry) -\u0026gt; { String key = entry.getKey(); String value = entry.getValue(); }) parallelStream 1 2 3 4 map.entrySet().parallelStream().forEach((entry) -\u0026gt; { String key = entry.getKey(); String value = entry.getValue(); }) Interator EntrySet 1 2 3 4 5 6 7 Iterator\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; iterator = map.entrySet().iterator(); while(iterator.hasNext()) { Map.Entry\u0026lt;String, String\u0026gt; entry = iterator.next(); String key = entry.getKey(); String value = entry.getValue(); } 根据 Effective Java - 57，更推荐以下这种写法：\n1 2 3 4 5 for (Iterator\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; iterator = map.entrySet().iterator(); iterator.hasNext(); ) { Map.Entry\u0026lt;String, String\u0026gt; entry = iterator.next(); String key = entry.getKey(); String value = entry.getValue(); } KeySet 1 2 3 4 for (Iteator\u0026lt;String\u0026gt; iterator = map.keySet().iterator(); iterator.hasNext(); ) { String key = iterator.next(); String value = map.get(key); } 🌟 一些操作 判空 1 2 3 4 5 🙋‍♂️ map.isEmpty(); 🙅‍♂️ boolean b = map.size() == 0; 计数 / merge() 1 2 public V merge(K key, V value, BiFunction\u0026lt;? super V, ? super V, ? extends V\u0026gt; remappingFunction) { } 1 map.merge(key, 1, Integer::sum); removeIf() 🚧 注意：\nMap 本身是没有 removeIf()。\n1 2 3 map.entrySet().removeIf(entry -\u0026gt; {}); map.keySet().removeIf(key -\u0026gt; {}); map.values().removeIf(value -\u0026gt; {}); absent 1 public V putIfAbsent(K key, V value); 1 2 3 4 5 6 7 // 不存在 key 时，按 mappingFunction 添加 value // 存在 key 不改变 public V computeIfAbsent(K key, Function\u0026lt;? super K, ? extends V\u0026gt; mappingFunction) { } public V computeIfPresent(K key, BiFunction\u0026lt;? super K, ? super V, ? extends V\u0026gt; remappingFunction) { } default 1 map.getOrDefault(key, 0); 🔗 参考 https://mp.weixin.qq.com/s/zQBN3UvJDhRTKP6SzcZFKw ","date":"2021-10-28T21:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/11.jpeg","permalink":"https://emerywan.github.io/blog/p/java-map-traversal/","title":"Java Map 操作"},{"content":"现有NER模型缺点：\n基于序列标注的NER模型（The sequence labeling-based NERmodels）\n长实体识别不佳，只关注词级信息 基于分段的NER模型（The segment-based NERmodels）\n处理分段，而非单个词，不能捕获分段中的词级依赖关系 边界检测（boundary detection）和类型预测（type pre-diction）可以相互配合，两个子任务可共享信息，相互加强。\n提出模块化交互网络模型MIN（Modularized Interaction Network）\n利用段级信息和词级依赖关系，结合一种交互机制，支持边界检测和类型预测之间的信息共享。\na recurrentneural network encoder-decoder framework with apointer network is used to detect entity segmentsfor segment information.\n","date":"2021-09-01T21:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/9.jpeg","permalink":"https://emerywan.github.io/blog/p/modularizedinteractionnetworkfornamed-entityrecognition/","title":"Modularized Interaction Network for Named Entity Recognition"},{"content":"借鉴图像领域的目标检测任务，将嵌套任务转化成span的预测，解决嵌套命名实体识别任务。\n具体是采用两阶段：\n第一步 Locate，即定位实体的边界 第二步 Label，即对识别span进行实体类型判断。 ","date":"2021-06-07T21:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/14.jpeg","permalink":"https://emerywan.github.io/blog/p/sequence-to-set/","title":"A Sequence-to-Set Network for Nested Named Entity Recognition"},{"content":"文中将每个 token 用 BERT 和 fastText 进行 embedding，拼接上用 CNN 编码的字符级别向量，送入一个双向 LSTM 编码上下文信息，获得每个词的表达。之后采用两个独立的 FFNN 来得到作为实体开始和结束的位置的表达。\n最后用一个仿射模型得到一个 $l×l×c$ 的 tensor，其中 l 是句子长度，c 是实体类别数量加一（表示无实体）。运用该矩阵，文中对于嵌套和非嵌套采用了两种不同的策略，从而得到了实体的起止位置。\ncode: https://github.com/juntaoy/biaffine-ner\n","date":"2021-06-01T21:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/7.jpeg","permalink":"https://emerywan.github.io/blog/p/namedentityrecognitionasdependencyparsing/","title":"Named Entity Recognition As Dependency Parsing"},{"content":"PyTorch 是什么？ 基于 Python 的科学计算包，服务于以下两种场景：\nNumpy 的替代品，可以使用 GPU 的强大计算力 提供最大的灵活性和高速的深度学习研究平台 Tensors Tensors 与 Numpy 中的 ndarrays 类似，但是在 PyTorch 中 Tensors 可以使用 GPU 进行计算。\n1 2 from __future__ import print_function import torch [ 1 ] 创建一个 5x3 的矩阵，但不初始化：\n1 2 3 4 5 6 7 x = torch.empty(5, 3) print(x) # tensor([[0.0000, 0.0000, 0.0000], # [0.0000, 0.0000, 0.0000], # [0.0000, 0.0000, 0.0000], # [0.0000, 0.0000, 0.0000], # [0.0000, 0.0000, 0.0000]]) [ 2 ] 创建一个随机初始化的矩：\n1 2 3 4 5 6 7 x = torch.rand(5, 3) print(x) # tensor([[0.6972, 0.0231, 0.3087], # [0.2083, 0.6141, 0.6896], # [0.7228, 0.9715, 0.5304], # [0.7727, 0.1621, 0.9777], # [0.6526, 0.6170, 0.2605]]) [ 3 ] 创建一个 0 填充的矩阵，数据类型为 long：\n1 2 3 4 5 6 7 x = torch.zero(5, 3, dtype=torch.long) print(x) # tensor([[0, 0, 0], # [0, 0, 0], # [0, 0, 0], # [0, 0, 0], # [0, 0, 0]]) [ 4 ] 创建一个 tensor 使用现有数据初始化：\n1 2 3 4 5 x = torch.tensor( [5.5, 3] ) print(x) # tensor([5.5000, 3.0000]) [ 5 ] 根据现有的 tensor 创建 tensor。这些方法将重用输入 tensor 的属性（如：dtype，除非设置新的值进行覆盖）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 利用 new_* 方法创建对象 x = x.new_ones(5, 3, dtype=torch.double) print(x) # tensor([[1., 1., 1.], # [1., 1., 1.], # [1., 1., 1.], # [1., 1., 1.], # [1., 1., 1.]], dtype=torch.float64) # 覆盖 dtype # 对象 size 相同，只是 值和类型 发生变化 print(x) # tensor([[ 0.5691, -2.0126, -0.4064], # [-0.0863, 0.4692, -1.1209], # [-1.1177, -0.5764, -0.5363], # [-0.4390, 0.6688, 0.0889], # [ 1.3334, -1.1600, 1.8457]]) [ 6 ] 获取 size：\n1 2 print(x.size()) # torch.Size([5, 3]) Tip:\ntorch.Size 返回 tuple 类型，支持 tuple 类型所有的操作。\n[ 7 ] 操作\n[ 7.1 ] 加法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 y = torch.rand(5, 3) print(x+y) # tensor([[ 0.7808, -1.4388, 0.3151], # [-0.0076, 1.0716, -0.8465], # [-0.8175, 0.3625, -0.2005], # [ 0.2435, 0.8512, 0.7142], # [ 1.4737, -0.8545, 2.4833]]) print(torch.add(x, y)) # tensor([[ 0.7808, -1.4388, 0.3151], # [-0.0076, 1.0716, -0.8465], # [-0.8175, 0.3625, -0.2005], # [ 0.2435, 0.8512, 0.7142], # [ 1.4737, -0.8545, 2.4833]]) 提供输出 tensor 作为参数：\n1 2 3 4 5 6 7 8 result = torch.empty(5, 3) torch.add(x, y, out=result) print(result) # tensor([[ 0.7808, -1.4388, 0.3151], # [-0.0076, 1.0716, -0.8465], # [-0.8175, 0.3625, -0.2005], # [ 0.2435, 0.8512, 0.7142], # [ 1.4737, -0.8545, 2.4833]]) [ 7.2 ] 替换：\n1 2 3 4 5 6 7 8 # add x to y y.add_(x) print(y) # tensor([[ 0.7808, -1.4388, 0.3151], # [-0.0076, 1.0716, -0.8465], # [-0.8175, 0.3625, -0.2005], # [ 0.2435, 0.8512, 0.7142], # [ 1.4737, -0.8545, 2.4833]]) {% note info %} _ 结尾的操作会替换原变量。 如：x_copy_(y)，x.t_() 会改变 x {% endnote %}\n[ 7.3 ] 使用 Numpy 中索引方式，对 tensor 进行操作：\n1 2 print(x[:, 1]) # tensor([-2.0126, 0.4692, -0.5764, 0.6688, -1.1600]) [ 8 ] torch.view 改变 tensor 的维度和大小 （与 Numpy 中 reshape 类似）：\n1 2 3 4 5 6 x = torch.randn(4, 4) y = x.view(16) z = x.view(-1, 8) # -1 从其他维度推断 print(x.size(), y.size(), z.size()) # torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) [ 9 ] 如果只有一个元素的 tensor，使用 item() 获取 Python 数据类型的数值：\n1 2 3 4 5 x = torch.randn(1) print(x) print(x.item()) # tensor([-0.2368]) # -0.23680149018764496 Numpy 转换 Torch Tensor 与 Numpy 数组之间进行转换非常轻松。\n1 2 3 4 5 a = torch.ones(5) b = a.numpy() print(a) # tensor([1., 1., 1., 1., 1.]) print(b) # [1. 1. 1. 1. 1.] Torch Tensor 与 Numpy 数组共享底层内存地址，修改一个会导致另一个的变化。\n1 2 3 4 a.add_(1) print(a) # tensor([2., 2., 2., 2., 2.]) print(b) # [2. 2. 2. 2. 2.] 1 2 3 4 5 6 7 import numpy as np a = np.ones(5) b = torch.from_numpy(a) np.add(a, 1, out=a) print(a) # [2. 2. 2. 2. 2.] print(b) # tensor([2., 2., 2., 2., 2.], dtype=torch.float64) Tip:\n所有的 Tensor 类型默认都是基于 CPU， CharTensor 类型不支持到 Numpy 的装换。\nCUDA 张量 使用 .to() 可以将 Tensor 移动到任何设备中。\n1 2 3 4 5 6 7 if torch.cuda.is_available(): device = torch.device(\u0026#39;cuda\u0026#39;) # CUDA 设备对象 y = torch.ones_like(x, device=device) # 直接从 GPU 创建张量 x = x.to(device) z = x + y print(z) # tensor([0.7632], device=\u0026#39;cuda:0\u0026#39;) print(z.to(\u0026#39;cpu\u0026#39;, torch.double)) # tensor([0.7632], dtype=torch.float64) Autograd 自动求导 autograd 包为 Tensor 上所有的操作提供了自动求导。它是一个运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。\n正向传播 反向传播 神经网络（NN）是在某些输入数据上执行嵌套函数的集合。 这些函数由参数（权重和偏差组成）定义，参数在 PyTorch 中存储在张量中。\n训练 NN 分为两个步骤：\n正向传播：在正向传播中，NN 对正确的输出进行最佳猜测。它通过每个函数运行输入数据以进行猜测。 反向传播：在反向传播中，NN 根据其猜测中的误差调整其参数。它通过从输出向后遍历，收集有关参数（梯度）的误差导数并使用梯度下降来优化参数来实现。 [ 1 ] 我们从 torchvision 加载了经过预训练的 resnet18 模型。创建一个随机数据张量来表示具有 3 个通道的单个图像，高度和宽度为 64，其对应的label初始化为一些随机值。\n1 2 3 4 5 import torch, torchvision model = torchvision.models.resnet18(pretrained=True) data = torch.rand(1, 3, 64, 64) labels = torch.rand(1, 1000) [ 2 ] 接下来，通过模型的每一层运行输入数据进行预测。正向传播。\n1 prediction = model(data) [ 3 ] 使用模型的预测（predication）和相应的标签（labels）来计算误差（loss）。 下一步通过反向传播此误差。我们在 loss tensor 上调用 .backward() 时，开始反向传播。Autograd 会为每个模型参数计算梯度并将其存储在参数 .grad 属性中。\n1 2 loss = (prediction - labels).sum() loss.backword() # backword pass [ 4 ] 接下来，我们加载一个优化器（SDG），学习率为 0.01，动量为 0.9。在 optim 中注册模型的所有参数。\n1 optim = torch.optim.SDG(model.parameters(), lr=1e-2, momentum=0.9) [ 5 ] 最后，调用 .step() 启动梯度下降。优化器通过 .grad 中存储的梯度来调整每个参数。\n1 optim.step() # gradient descent 神经网络的微分 这一小节，我们将看看 autograd 如何收集梯度。 我们在创建 Tensor 时，使用 requires_grad=True 参数，表示将跟踪 Tensor 的所有操作。\n1 2 3 4 5 6 7 import torch a = torch.tensor([2., 3.], require_grad=True) b = torch.tensor([6., 4.], require_grad=True) # 从 tensor a, b 创建另一个 tensor Q Q = 3*a**3 - b**2 假设 tensor a，b 是神经网络的参数，tensor Q 是误差。在 NN 训练中，我们想要获得相对于参数的误差，即各自对应的偏导：\n$$\\frac{\\partial Q}{\\partial a}=9a^2$$\n当我们在 tensor Q 上调用 .backward() 时，Autograd 将计算这些梯度并将其存储在各个张量的 .grad 属性中。\n我们需要在 Q.backword() 中显式传递 gradient 参数（与 Q 形状相同的张量，表示 Q 相对本身的梯度）。\n$$\\frac{\\partial Q}{\\partial b}=-2b$$\n1 2 3 4 5 6 7 8 external_grad = torch.tensor([1., 1.]) Q.backward(gradient=external_grad) # 最后，梯度记录在 a.grad b.grad 中，查看收集的梯度是否正确 print(9*a**2 == a.grad) # tensor([True, True]) print(-2*b == b.grad) # tensor([True, True]) 我们也可以将 Q 聚合为一个标量，然后隐式地向后调用，如：Q.sum().backward()。\n神经网络 上一节，我们了解到 nn 包依赖 autograd 包来定义模型并求导。下面，我们将了解如何定义一个网络。一个 nn.Module 包含个 layer 和一个 forward(input) 方法，该方法返回 output。\n如下，这是一个对手写数字图像进行分类的卷积神经网络：\n神经网络的典型训练过程如下：\n定义包含一些可学习的参数（权重）神经网络模型 在数据集上迭代 通过神经网络处理输入 计算损失（输出结果和正确值的差值大小） 将梯度反向传播回网络的参数 更新网络的参数（梯度下降）：weight = weight - learning_rate * gradient 定义网络 在模型中必须定义 forward()， backword（用来计算梯度）会被 autograd 自动创建。可在 forward() 中使用任何针对 Tensor 的操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Model): def __init__(self): super(Net, self).__init__() # 1 input image channel, 6 output channels, 3x3 square convolution # kernel self.conv_1 = nn.Conv2d(1, 6, 3) self.conv_2 = nn.Conv2d(6, 16, 3) # an affine operation: y = Wx + b self.fc1 = nn.Linear(16 * 6 *6, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # Max Pooling over a (2, 2) window x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # If the size is a square you can only specify a single number x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(sefl, x): size = x.size()[1: ] # all dimensions except the batch dimension num_features = 1 for s in size: num_features *= s return num_features net = Net() print(net) # Net( # (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) # (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) # (fc1): Linear(in_features=576, out_features=120, bias=True) # (fc2): Linear(in_features=120, out_features=84, bias=True) # (fc3): Linear(in_features=84, out_features=10, bias=True) # ) parameters() 返回可被学习的参数（权重）列表和值\n1 2 3 4 params = list(net.parameters()) print(len(params)) # 10 print(params[0].size()) # conv1 的 weight torch.Size([6, 1, 3, 3]) 测试随机输入 32x32。注：这个网络（LeNet）的期望的输入大小是 32x32，如果使用 MINIST 数据集来训练这个网络，请把图片大小重新调整到 32x32。\n1 2 3 4 5 input = torch.randn(1, 1, 32, 32) out = net(input) print(out) # tensor([[ 0.1120, 0.0713, 0.1014, -0.0696, -0.1210, 0.0084, -0.0206, 0.1366, # -0.0455, -0.0036]], grad_fn=\u0026lt;AddmmBackward\u0026gt;) 将所有的参数的梯度缓存清零，进行随机梯度的反向传播。\n1 2 net.zero_grad() out.backward(torch.randn(1, 10)) Tip:\ntorch.nn 仅支持小批量输入。整个 torch.nn 包都只支持小批量样本，而不支持单个样本。 如：nn.Conv2d接受一个4维 Tensor，分别维 sSamples * nChannels * Height * Width （样本数* 通道数 * 高 * 宽）。如果你有单个样本，只需要使用 input.unsqueeze(0) 来添加其他的维数。\n至此，我们大致了解了如何构建一个网络，回顾一下到目前为止使用到的类。\ntorch.Tensor： 一个多维数组。 支持使用 backward() 进行自动梯度计算，并保存关于这个向量的梯度 w.r.t.\nnn.Model： 神经网络模块。实现封装参数、移动到 GPU 上运行、导出、加载等。\nnn.Parameter： 一种张量。将其分配为 Model 的属性时，自动注册为参数。\nautograd.Function： 实现一个自动求导操作的前向和反向定义。每个 Tensor 操作都会创建至少一个 Function 节点，该节点连接到创建 Tensor 的函数，并编码其历史记录。\n损失函数 1 2 3 4 5 6 7 8 9 output = net(input) target = torch.randn(10) # 例子：一个假设的结果 target = target.view(1, -1) # 让 target 与 output 的形状相同 criterion = nn.MSELoss() loss = criterion(output, target) print(loss) 反向传播 要实现反向传播误差，只需要 loss.backward()。 但是，需要清除现有的梯度，否则梯度将累积到现有的梯度中。\n1 2 3 4 5 6 7 net.zero_grad() # 将所有的梯度缓冲归零 print(net.conv1.bias.grad) # conv1.bias.grad 反向传播前 tensor([0., 0., 0., 0., 0., 0.]) loss.backward() print(net.conv1.bias.grad) # 反向传播后 tensor([0.0111, -0.0064, 0.0053, -0.0047, 0.0026, -0.0153]) 更新权重 在使用 PyTorch 时，可以使用 torch.optim 中提供的方法进行梯度下降。如：SDG，Nesterov-SDG，Adam，RMSprop 等。\n1 2 3 4 5 6 7 8 9 10 11 import torch.optim as optim # 创建一个 optimizer optimizer = optim.SDG(net.parameters(), lr=0.01) # 在训练中循环 optimizer.zero_grad() # 将梯度缓冲区清零 output = net(input) loss = criterion(output, target) loass.backword() optimizer.step() # 更新 训练分类器 数据从哪里来？ 通常，需要处理图像、文本、音频或视频数据时，可以使用将数据加载到 NumPy 数组中的标准 Python 包，再将该数值转换为 torch.*Tensor。\n处理图像，可以使用 Pillow，OpenCV 处理音频，可以使用 SciPy，librosa 处理文本，可基于 Python 或 Cython 的原始加载，或 NLTK 和 SpaCy 对于图像任务，其中包含了一个 torchvision 的包，含有常见的数据集（Imagenet，CIFAR10，MNIST等）的数据加载器，以及用于图像的数据转换器（torchvision.datasets 和 torch.utils.data.DataLoader）。\n在本示例中，将使用 CIFAR10 数据集。其中包含 10 分类的图像：“飞机”，“汽车”，“鸟”，“猫”，“鹿”，“狗”，“青蛙”，“马”，“船”，“卡车”。图像的尺寸为 3 * 32 * 32，即尺寸为 32 * 32 像素的 3 通道彩色图像。\n接下来，作为演示，将按顺序执行以下步骤训练图像分类器：\n使用 torchvision 加载并标准化 CIFAR10 训练和测试数据集 定义 CNN 定义损失函数 根据训练数据训练网络 在测试数据上测试网络 加载并标准化 CIFAR10 1 2 3 import torch import torchvision import torchvision.transforms as transforms torchvision 的输出是 [0, 1] 的 PILImage 图像，我们要把它转换为归一化范围为 [-1, 1] 的张量。\n1 2 3 4 5 6 7 8 9 10 11 transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))] ) trainset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = trochvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, barch_size=4, shuffle=False, num_workers=2) classes = (\u0026#39;plane\u0026#39;, \u0026#39;car\u0026#39;, \u0026#39;bird\u0026#39;, \u0026#39;cat\u0026#39;, \u0026#39;deer\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;frog\u0026#39;, \u0026#39;horse\u0026#39;, \u0026#39;ship\u0026#39;, \u0026#39;truck\u0026#39;) 定义 CNN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # in_channels, out_channels, kernel_size # 输入的为 3 通道图像，提取 6 个特征，得到 6 个 feature map，卷积核为一个 5*5 的矩阵 self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) # 卷积层输出了 16 个 feature map，每个 feature map 是 6*6 的二维数据 self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net(s) 定义损失函数和优化器 这里我们使用交叉熵作为损失函数，使用带动量的随机梯度下降。\n1 2 3 4 import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SDG(net.parameters(), lr=0.001, momentum=0.9) 训练网络 接下来，只需要在迭代数据，将数据输入网络中并优化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 for epoch in range(2): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data # 获取输入 optimizer.zero_grad() # 将梯度缓冲区清零 outputs = net(inputs) # 正向传播 loss = criterion(outputs, lables) loss.backward() # 反向传播 optimizer.step() # 优化 running_loss += loss.item() if i % 2000 == 1999: # 每 2000 批次打印一次 print(\u0026#39;[]\u0026#39; % (epoch+1, i+1, running_loss / 2000)) running_loss = 0.0 在测试集上测试数据 在上面的训练中，我们训练了 2 次，接下来，我们要检测网络是否从数据集中学习到了有用的东西。通过预测神经网络输出的类别标签与实际情况标签对比进行检测。\n1 2 3 4 5 6 7 8 9 10 11 12 corrent = 0 total = 0 with torch.no_grad(): for data in testloader: images, lobels = data outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) corrent += (predicted == labels).sum().item() print(\u0026#39;Accuracy of the network on the 10000 test images: %d %%\u0026#39; % (100 *corrent / total)) # Accuracy of the network on the 10000 test images: 9% 在训练两次的网络中，随机选择的正确率为 10%。网络似乎学到了一些东西。\n那这个网络，识别哪一类好，哪一类不好呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class_corrent = list(0. for i in range(10)) class_total = list(0. for i in range(10)) with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1 for i in range(10): print(\u0026#39;Accuracy of %5s : %2d %%\u0026#39; % (classes[i], 100 * class_correct[i] / class_total[i])) # Accuracy of plane : 99 % # Accuracy of car : 0 % # Accuracy of bird : 0 % # Accuracy of cat : 0 % # Accuracy of deer : 0 % # Accuracy of dog : 0 % # Accuracy of frog : 0 % # Accuracy of horse : 0 % # Accuracy of ship : 0 % # Accuracy of truck : 0 % 使用 GPU 与将 tensor 移到 GPU 上一样，神经网络也可以移动到 GPU 上。 如果可以使用 CUDA，将设备定义为第一个 cuda 设备：\n1 2 3 4 device = torch.device(\u0026#39;cuda:0\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39;) print(device) # cuda:0 复制 nn 和 tensor 到 GPU 上。\n1 2 3 model = net.to(device) inputs, labels = data[0].to(device), data[1].to(device) Tip:\n使用 .to(device) 并没有复制 nn / tensor 到 GPU 上，而是返回了一个 copy。需要赋值到一个新的变量后在 GPU 上使用这个 nn / tensor。\n参考 https://pytorch.apachecn.org/#/docs/1.7/02 ","date":"2021-04-01T21:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/10.jpeg","permalink":"https://emerywan.github.io/blog/p/pytorch-handbook/","title":"PyTorch 火速上手"},{"content":"React Hooks 简介 Hook 含义 组件类和函数组件 useState 使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import React, { useState } from \u0026#39;react\u0026#39;; const Example() { // 声明了一个 count 的 state 变量，并初始化为 0 // setCount 设置 state 值 count 的方法 const [count, setCount] = useState(0); // 每次点击按钮，将 count 的值 +1 return ( \u0026lt;\u0026gt; \u0026lt;p\u0026gt;You clicked {count} times\u0026lt;/p\u0026gt; \u0026lt;button onClick={() =\u0026gt; setCount(count + 1)}\u0026gt; Click me \u0026lt;/button\u0026gt; \u0026lt;/\u0026gt; ) } export default Example; 语法 1 2 // 声明一个 state 变量，并同时初始化 const [state, setState] = useState(initialState) useState 返回一个包含两个元素的数组 state 变量，指向状态当前值 setState 更新 state 值的方法 initialState 状态初始值可以是数字，字符串，数组，对象等 与类中使用 setState 异同 相同点 在一次渲染周期中调用多次 setState，数据只改变一次 不同点 类组件中 setState 为合并 函数组件中 setState 为替换 useEffect useEffect 用来执行副作用。可以将 useEffect Hook 看做 componentDidMount, componentDidUpdate, componentWillMount 生命周期函数的组合。\n常用在：\n服务器请求 访问元素 dom 元素 本地持久化缓存 绑定/解绑事件 添加订阅 设置定时器 记录日志 等 useEffect 接收一个函数，该函数会在组件渲染完毕后才执行，该函数有要求：要么返回一个能清除副作用的函数，要么就不返回任何内容。\n不需要清除的 effect 在 React 更新 DOM 之后，我们想运行一些额外的代码。比如发送网络请求，手动变更 DOM，记录日志，这些都是常见的无需清除的操作。 因为我们在执行完这些操作之后，就可以忽略他们了。\n以下为使用 class 和 Hook 都是怎么实现这些副作用的对比。\n使用类组件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // 在 React 更新 DOM 操作后，立即更新 document 的 title 属性 class Example extends React.Component { constructor(props) { super(props); this.state = { count: 0 }; } // 组件加载时需要更新 componentDidMount() { document.title = `You clicked ${this.state.count} times`; } // 组件更新时需要更新 componentDidUpdate() { document.title = `You clicked ${this.state.count} times`; } // 在 render() 不能有任何副作用。应该在 react 更新 DOM 后再执行副作用。 render() { return ( \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;You clicked {this.state.count} times.\u0026lt;/p\u0026gt; \u0026lt;button onClick={() =\u0026gt; this.setState({ count: this.state.count + 1})}\u0026gt; click me. \u0026lt;/button\u0026gt; \u0026lt;div/\u0026gt; ) } } 使用 Hook 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import React, {useState, useEffect} from \u0026#39;react\u0026#39;; export default function Example() { const [count, setCount] = useState(0); useEffect(() =\u0026gt; { // 经过渲染或更新， DOM 更新完毕之后，会运行该 effect document.title = `You click ${count} times`; }); return ( \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;You clicked {this.state.count} times.\u0026lt;/p\u0026gt; \u0026lt;button onClick={() =\u0026gt; this.setState({ count: this.state.count + 1})}\u0026gt; click me. \u0026lt;/button\u0026gt; \u0026lt;div/\u0026gt; ); } 第一次渲染之后和每次更新之后都会执行 useEffect。且 React 保证每次运行 effect 的同时，DOM 已经更新完毕。 useEffect 放在组件内部让我们可以在 effect 中直接访问 state / props。我们不需要特殊的 API 来读取。 与 componentDidMount 或 componentDidUpdate 不同，使用 useEffect 调度的 effect 不会阻塞浏览器更新屏幕，这让你的应用看起来响应更快。大多数情况下，effect 不需要同步地执行。在个别情况下（例如测量布局），有单独的 useLayoutEffect Hook 供你使用，其 API 与 useEffect 相同。 需要清除的 effect 有一些副作用是需要清除的，如订阅外部数据源。这种情况下，清除工作是非常重要的，可以防止引起内存泄露！\n使用类组件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class FriendStatus extends React.Component { constructor(props) { super(props); this.state = { isOnline: null }; this.handleStatusChange = this.handleStatusChange.bind(this); } componentDidMount() { ChatAPI.subscribeToFriendStatus( this.props.friend.id, this.handleStatusChange ); } componentDidUpdate () { // ... } componentWillUnmount() { // 在组件卸载时，关闭订阅的数据源 ChatAPI.unsubscribeFromFriendStatus( this.props.friend.id, this.handleStatusChange ); } handleStatusChange(status) { this.setState({ isOnline: status.isOnline }); } render() { if (this.state.isOnline === null) { return \u0026#39;Loading...\u0026#39;; } return this.state.isOnline ? \u0026#39;Online\u0026#39; : \u0026#39;Offline\u0026#39;; } } 使用函数组件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import React, {useState, useEffect} from \u0026#39;react\u0026#39;; export default function FriendStatus(props) { const [isOnline, setIsOnline] = useState(null); useEffect(() =\u0026gt; { function handleStatusChange(status) { setIsOnline(status.isOnline); } ChatAPI.subscribeToFriendStatus(props.friend.id, handleStatusChange); // effect 可选清除副作用的函数，返回函数不一定需要命名 return function cleanup() { ChatAPI.unsubscribeFromFriendStatus(props.friend.id, handleStatusChange); }; }); if (isOnline === null) { return \u0026#39;Loading...\u0026#39;; } return isOnline ? \u0026#39;Online\u0026#39; : \u0026#39;Offline\u0026#39;; } React 会在组件卸载的时候执行清除操作。 多个 Effect 实现关注点分离 使用 Hook 的其中一个目的是要解决： class 生命周期函数中经常包含不相关逻辑，相关逻辑又分离在几个不同的方法中。\n如下为上文中计数器和好友状态指示器逻辑组合在一起的组件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class FriendStatusWithCounter extends React.Component { constructor(props) { super(props); this.state = { count: 0, isOnline: null }; this.handleStautsChange = this.handleStatusChange.bind(this); } // 相应的逻辑被分配在三个不同的生命周期函数中 componentDidMount() { // counter document.title = `You clicked ${this.state.count} times`; // friend status ChatAPI.subscribeToFriendStatus( this.props.fried.id, this.handleStatusChange ) } componentDidUpdate() { document.title = `You clicked ${this.state.count} times`; } componentWillUnmount() { ChatAPI.unsubscribeFromFriendStatus( this.props.friend.id, this.handleStatusChange ); } handleStatusChange(status) { this.setState({ isOnline: status.isOnline }); } // ... } 若使用 Hook，和使用多个 state 的 Hook 一样，通过使用多个 effect，将不相关的逻辑分离到不同的 effect 中。\nHook 允许按照代码的用途进行分离，不同于生命周期函数。将按照 effect 声明的顺序依次调用组件中的每一个 effect。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 export default const FriendStatusWithCounter = () =\u0026gt; { const [count, setCount] = useState(0); useEffect(() =\u0026gt; { document.title = `You clicked ${this.state.count} times`; }); const [isOneline, useIsOneline] = useState(null); useEffect(() =\u0026gt; { function handleStatusChange(status) { setIsOneline(status.isOneline); } ChatAPI.subscribeToFriendStatus(props.friend.id, handleStatusChange); return () =\u0026gt; { ChatAPI.unsubscribeFromFriendStatus(props.friend.id, handleStatusChange); }; }); // ... } 跳过 Effect 进行性能优化 在类组件中，我们可以通过 componentDidUpdate 中 prevProps 和 prevState 的 props / state 的变化比较，判断是否需要执行某些副作用。\n1 2 3 4 5 componentDidUpdate(prevProps, prevState) { if (prevState.count !== this.state.count) { document.title = `You clicked ${this.state.count} times`; } } 在 Hook 中，可以通过对 useEffect 传递数组作为第二可选参数，通知 React 跳过对 effect 的调用。\n1 2 3 4 5 useEffect(() =\u0026gt; { document.title = `You clicked ${count} times`; }, [count]); // 表示 count 更改时会进行更新 // {... , [5]} 当 count === 5 时，跳过 effect 若只想运行一次 effect（仅在组件挂载和卸载时执行），可传递一个空数组 [] 作为第二参数。 传入一个空数组（[]），effect 内部的 props 和 state 会一直拥有其初始值。 使用该优化，请确保数组中包含了所有外部作用域中会随时间变化且在 effect 中使用的变量，否则代码会用到先前渲染中的旧变量。 每次更新的时候都要运行 Effect 的原因 自定义 Hook 自定义 Hook 可以将组件逻辑提取到可重用的函数中。\n目前为止，在 React 中有两种流行的方式共享组件之间的状态逻辑：\nrender props 高阶组件 使用 Hook 可以在不增加组件的情况下解决相同的问题。 创建自定义 Hook 当我们想在函数间共享逻辑时，我们可以把它提取到另外一个函数中。由于组件和 Hook 都是函数，所以也同样使用于这种方式。\n自定义 Hook 是一个函数，其名称以 \u0026ldquo;use\u0026rdquo; 开头，函数内部可以调用其他的 Hook。\n以下是根据上文中 FriendStatus 实例，所提取的自定义 Hook。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import { useState, useEffect } from \u0026#39;react\u0026#39;; // 名称一定以 use 开头 function useFriendStatus(friendID) { const [isOnline, setIsOnline] = useState(null); useEffect(() =\u0026gt; { function handleStatusChange(status) { setIsOnline(status.isOneline); } ChatAPI.subscribeToFriendStatus(friendID, handleStatusChange); return () =\u0026gt; { ChatAPI.unsubcribeFromFriendStatus(friendID, handleStatusChange); }; }); return isOnline; } export default useFriendStatus; 在这个自定义 Hook 中，没有包含任何新内容（逻辑与组件中的完全一致）\n使用自定义 Hook 与组件一致，请确保只在自定义 Hook 的顶层无条件地调用其他 Hook。\n1 2 3 4 5 6 7 8 function FriendStatus(props) { const isOnline = useFriendStatus(props.friend.id); if (isOnline === null) { return \u0026#34;Loading...\u0026#34;; } return isOnline ? \u0026#39;Online\u0026#39; : \u0026#39;Offline\u0026#39;; } 这段代码与之前的工作方式完全一样，我们只是将函数中需要共享的逻辑提取到单独的函数中。\n自定义 Hook 是一种自然遵循 Hook 设计的约定，不是 React 的特性。 自定义 Hook 必须以 \u0026ldquo;use\u0026rdquo; 开头 不同组件中使用相同的 Hook 不会共享 state。 自定义 Hook 是重用状态逻辑的机制（例如设置为订阅并存储当前值），每次使用自定义 Hook 时，其中的所有 state 和副作用完全隔离。 在多个 Hook 之间传递信息 由于 Hook 本身就是函数，因此我们可以在它们之间传递信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 这是一个聊天消息接收者的选择器，它会显示当前选定的好友是否在线 function ChatRecipientPicker() { // 当前选择的好友 ID 保存在 recipientID 状态变量中 const [recipientID, setRecipientID] = useState(1); // 当更新 recipientID 状态变量时，useFriendStatus Hook 会取消订阅之前选中的好友，并订阅新选中的好友状态 const isRecipientOnline = useFriendStatus(recipientID); return ( \u0026lt;\u0026gt; \u0026lt;Circle color={isRecipientOnline ? \u0026#39;green\u0026#39; : \u0026#39;red\u0026#39;} /\u0026gt; \u0026lt;select // \u0026lt;select\u0026gt; 中选择其他好友时更新 recipientID value={recipientID} onChange={e =\u0026gt; setRecipientID(Number(e.target.value))} \u0026gt; { friendList.map(friend =\u0026gt; ( \u0026lt;option key={friend.id} value={friend.id}\u0026gt; {friend.name} \u0026lt;/option\u0026gt; )) } \u0026lt;/select\u0026gt; \u0026lt;/\u0026gt; ) } 我们将当前选择的好友 ID 保存在 recipientID 状态变量中，并会在用户从 \u0026lt;select\u0026gt; 中选择其他好友时更新这个 state。\n由于 useState 会提供 recipientID 状态变量的最新值，可以将它作为参数传递给自定义的 useFriendStatus Hook。当我们选择不同的好友并更新 recipientID 状态变量时，useFriendStatus Hook 会取消订阅之前选中的好友，并订阅新选中的好友状态。\nHook 规则 额外的 Hook 参考 https://juejin.im/post/6844903814349193229 https://juejin.im/post/6844903985338400782 https://www.ruanyifeng.com/blog/2019/09/react-hooks.html https://zh-hans.reactjs.org/docs/hooks-intro.html ","date":"2021-01-28T21:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/9.jpeg","permalink":"https://emerywan.github.io/blog/p/react-hooks/","title":"React Hooks"},{"content":"Ubuntu 耳机没有声音 笔记本使用 Ubuntu 插有线耳机后，并没有反应，该外放还是外放。\n感觉是适配问题，windows 下没有问题。找了一圈办法，只能通过软件手动切换了，效果还不错。\n1 sudo apt install pavucontrol 可以在这里切换输出设备：\n切换输入设备：\n","date":"2021-01-02T02:02:02+08:00","image":"https://emerywan.github.io/blog/imgs/5.jpeg","permalink":"https://emerywan.github.io/blog/p/ubuntu-sound/","title":"解决 Ubuntu 笔记本耳机没有声音的问题"},{"content":"数据类型 数组 numpy.array np.zeros 创建指定大小的数组，数组元素以 0 填充。\nnumpy.zeros(shape, dtype=None, order = \u0026lsquo;C\u0026rsquo;) shape 数组形状 dtype 数据类型 order \u0026lsquo;C\u0026rsquo; 用于 C 的行数组，或者 \u0026lsquo;F\u0026rsquo; 用于 FORTRAN 的列数组 1 2 3 4 5 6 7 8 9 10 11 12 13 np.zero(5) # [0. 0. 0. 0. 0.] np.zero(5, dtype=int) # [0 0 0 0 0] np.zero((3, 5)) # 三行五列 np.zero(shape=(3, 5)) # [ # [0., 0., 0., 0., 0.], # [0., 0., 0., 0., 0.], # [0., 0., 0., 0., 0.], # ] np.ones 创建指定大小的数组，数组元素以 1 填充。\nnumpy.ones(shape, dtype=None, order=\u0026lsquo;C\u0026rsquo;) np.full 创建指定大小和数据的数组\nnumpy.full(shape, fill_value, dtype=None, order=\u0026lsquo;C\u0026rsquo;) 1 2 # 创建一个 三行五列 值为 666.0 的矩阵 np.full((3, 5), 666.0) np.arange 在数组中，可以使用 range 创建指定范围的数组（不能传递浮点数）。\n1 2 3 4 # [0, 20) 步长为 2 [i for i in range(0, 20, 2)] # [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] 在 numpy 中，可以使用 arange 创建数组范围并返回 ndarray 对象。\nnumpy.arange(start, stop, step, dtype) start 起始值，默认为 0 stop 终止值，不包含 step 步长，默认为 1 dtype 数据类型 1 2 3 4 5 np.arange(0, 20, 2) # 可以传递浮点数 np.arange(0, 1, 0.2) # [0., 0.2, 0.4, 0.6, 0.8] np.linspace 创建一个一维数组，构成一个等差数列。\nnumpy.linspace(start, stop, num=50, endpoint=True, retstep=False,dtype=None, axis=0) start 起始值 stop 终止值（默认包含 endpoint=True） endpoint 当为 True 时，会包含 stop 的值 retstep 当为 True 时，生成的数组中会显示间距 dtype 数据类型 1 2 3 # 生成 [0, 20] 间距为 2 的 10 个数 np.linspace(0, 20, 11) # [0., 2., 4., 6., 8., 10., 12., 14., 16., 18., 20.] np.random numpy.random.randint(low, high=None, size=None, dtype=None) 生成指定的整数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 在 [0, 10) 间生成一个随机数 np.random.randint(0, 10) # 在 [0, 10) 间生成一个大小为 10 的一维数组 np.random.randint(0, 10, size=10) # [7, 7, 7, 7, 7, 4, 5, 6, 4, 7] # 在 [0, 10) 间生成一个 3行6列 的矩阵 np.random.randint(0, 10, size=(3, 5)) # 指定随机种子，使生成的数据在测试时保持一致 np.random.seed(666) numpy.random.random(size=None) 生成 [0.0, 1.0) 间的浮点数。\nnumpy.random.normal(loc=0.0, scale=1.0, size=None) 生成一个符合正态分布的浮点数。\nloc 均值 scale 方差 size 大小 1 2 3 4 5 # 生成 均值为 10 方差为 100 的浮点数 np.random.normal(10, 100) # 生成 均值为 0 方差为 1 的 3行5列的矩阵 np.random.normal(0, 1, (3, 5)) numpy.array 基本操作 假设有如下一个一维的数组 x 和 一个三行五列的矩阵 X：\n1 2 3 4 5 6 7 8 9 10 11 12 import numpy as np np.random.seed(0) x = np.arange(10) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] X = np.arange(15).reshape(3, 5) # [ # [ 0, 1, 2, 3, 4], # [ 5, 6, 7, 8, 9], # [10, 11, 12, 13, 14] # ] Reshape 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # 将 x 转置为 2行5列的 矩阵 A = x.reshape(2, 5) # [ # [0, 1, 2, 3, 4], # [5, 6, 7, 8, 9] # ] # 将向量装置成矩阵 B = x.reshape(1, 10) # [ # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # ] # -1：让 numpy 自己决定维度 # 10列 C = x.reshape(-1, 10) # [ # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # ] # 10行 D = x.reshape(10, -1) # [ # [0], # [1], # [2], # [3], # [4], # [5], # [6], # [7], # [8], # [9], # ] # 2行 E = x.reshape(2, -1) # [ # [0, 1, 2, 3, 4], # [5, 6, 7, 8, 9] # ] # 数据不能整除的情况下，不能 reshape F = x.reshape(3, -1) 基本属性 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # ndarray.ndim 秩，即轴的数量或维度的数量 x.ndim # 1 X.ndim # 2 # ndarray.shape 数组维度，对于矩阵为n行m列 x.shape # (10, ) X.shape # (3, 5) # ndarray.size 数组元素的总个数，对于矩阵为 n*m 个 x.size # 10 X.size # 15 数据访问 一维 numpy.array 可以和数组一样进行访问。\n多维 numpy.array 在访问时，推荐传入多个参数。\n1 2 3 # 一维 x[0] # 0 ","date":"2020-12-01T21:14:45+08:00","image":"https://emerywan.github.io/blog/imgs/3.jpeg","permalink":"https://emerywan.github.io/blog/p/numpy/","title":"NumPy"},{"content":"机器学习 基本术语 如图所示表格，是鸢尾花（lris）相关信息的数据，其中：\n数据整体称为数据集（data set） 每一行数据称为一个样本（sample） 每一列（除表格最后一列）表达样本的一个特征（feature） 最后一列，成为标记（label） 如图所示信息，其中 萼片长度、宽度，花瓣的长度、宽度称为 特征；每一行特征的值称为特征向量（数学上通常会将其表示为列向量）。\n若将该图中的数据表示为矩阵的方式，结果如图：\n选择两种鸢尾花的特征为例，将其表示为如图的二维空间（多维特征将其表示为多维空间）。\n我们将这样的空间称为 特征空间（feature space）。\n分类任务本质就是在特征空间切分，如图所示，在特征空间中，将鸢尾花根据两种特征分为了两类。\n机器学习的基本任务 机器学习的基本任务基本有两类，分别为：\n分类 回归 分类任务 一些算法只支持完成二分类的任务 多分类的任务可以转换成二分类的任务 一些算法天然的支持多分类问题 二分类 二分类问题的常见实例：\n判断邮件是垃圾邮件；不是垃圾邮件 判断发放给客户信用卡有风险；无风险 判断病患良性肿瘤；恶性肿瘤 判断某支股票涨；跌 多分类 多分类问题的常见实例：\n数字识别 图像识别 判断发放给客户信用卡的风险评级 围棋游戏等 自动驾驶识别 多标签分类 如图所示，为多标签分类问题的常见实例：\n回归任务 回归问题的结果与分类问题的结果不同，回归问题的结果是一个连续数字的值，而非一个类别。\n常见的回归问题有：\n房屋价格 市场分析 学术成绩 股票价格 在一些情况下，回归任务可以简化成分类任务。\n机器学习算法分类 监督学习 监督学习 supervised learning 主要处理的是分类问题和回归问题。\n监督学习的含义是给机器的训练数据中拥有“标记”或者“答案”。根据这些数据进行模型的训练。\n如根据图片判断猫狗（图像已经拥有了标定信息） 如更具手写字体识别数字（给出结果标记） 银行已经积累了一定的客户信息和他们信用卡的信用情况\n医院已经积累了一定的病人信息和他们最终确诊是否患病的情况。\n常见的监督学习算法有：\nk近邻 线性回归和多项式回归 逻辑回归 SVM 决策树和随机森林 非监督学习 非监督学习 unsupervised learning 给机器的训练数据没有任何“标记”或者“答案”。\n对没有“标记”的数据进行分类 \u0026ndash; 聚类分析。\n意义 对数据进行降维处理 特征提取：行用卡的信用评级和人的胖瘦无关？ 特征压缩：PCA 降维处理的意义：方便可视化\n我们无法理解四维以上空间，所以可以将其降维到三维或者二维空间，方便理解。\n异常检测 半监督学习 semi-supervised learning\n一部分数据有“标记”或者答案，另一部分数据没有\n常见的场景：各种原因产生的标记缺失。\n我们通常都先使用无监督学习手段对数据做处理，之后使用监督学习手段做模型的训练和预测。\n增强学习 根据周围环境的情况，采取行动，根据采取行动的结果，学习行动方式。\n无人驾驶 机器人 在增强学习中，监督学习和半监督学习是基础。\n机器学习的其他分类 在线学习和批量学习 在线学习 Online Learning\n优点：及时反映新的环境变化\n问题：新的数据可能带来不好的变化，错误的数据可能带来错误的结果\n解决方案：需要加强对数据的监控 也适用于数据量巨大，完全无法批量学习的环境\n批量学习（离线学习） Batch Learning / Offline Learning\n优点：简单\n问题：要考虑如如何适应环境变化\n解决方案：定时重新批量学习 缺点：每次重新批量学习，运行量巨大。在某些环境变化非常快的情况下，甚至是不可能的。\n参数学习和非参数学习 参数学习 Parametric Learning\n如图所示，为房屋面积与价格的关系曲线。\n特点：一旦学习到了参数，就不需要原有的数据集。\n非参数学习 Nonparametric Learning\n不对模型进行过多假设\n非参数不等于没有参数，而是对整个不进行建模，不学习一些参数\n","date":"2020-09-28T14:02:02+08:00","permalink":"https://emerywan.github.io/blog/p/mechine-learning-basics/","title":"机器学习基础"},{"content":"Spring Cloud Hystrix 在微服务架构中，我们将系统拆分成了一个个的服务单元，各单元应用间通过服务注册与订阅的方式互相依赖。由于每个单元都在不同的进程中运行，如果某个服务不可用，可能导致级联故障，造成整个系统不可用的情况（雪崩效应）。为了解决这样的问题，产生了断路器等一系列的服务保护机制。\n简介 Spring Cloud Hystrix，它是一个基于 Netflix 的开源框架，具有如下功能：\n服务降级 依赖隔离 服务熔断 监控（Hystrix Dashboard） 实现一个 Hystrix Server 添加依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-hystrix\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加注解 1 2 3 4 5 6 7 8 @EnableCircuitBreaker @EnableDiscoveryClient @SpringBootApplication public class HystrixApplication { public static void main(String[] args) { SpringApplication.run(HystrixApplication.class, args); } } 配置文件 1 2 3 4 5 6 7 8 9 10 11 spring: application: name: hystrix-server server: port: 8080 eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ Hystrix 应用 服务降级 假设现在有一个接口 /user/{id} 获取用户信息。\n1 2 3 public ResultVo\u0026lt;UserInfo\u0026gt; getUserInfo(@PathVariable String id) { return userService.getUserInfo(id); } 在 UserService 中添加调用方法的服务降级。\n1 2 3 4 5 6 7 8 9 10 11 12 @HystrixCommand(fallbackMethod = \u0026#34;userFallback\u0026#34;) public ResultVo\u0026lt;UserInfo\u0026gt; getUserInfo(String id) { // 正常的服务调用和业务 此处以 restTemplate 为例 // ... return restTemplate.getForObject(url + \u0026#34;/user/{1}\u0026#34;, ResultVo.class, id); } public ResultVo\u0026lt;UserInfo\u0026gt; userFallback() { // ... // 处理服务降级需要返回的内容 } 服务降级 OpenFiegn 配置文件 1 2 3 feign: hystrix: enabled: true OpenFeign Client 端实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @FeignClient( name = \u0026#34;user\u0026#34;, // 远程服务名 fallback = UserClientFallback.class // 指定 当服务降级时，采用的方法 ) public interface UserClient { @GetMapping(\u0026#34;/user/{id}\u0026#34;) ResultVo\u0026lt;UserInfo\u0026gt; getUserInfo(@PathVariable String id); } --- // 实现 UserClient 接口 @Component public class UserClientFallback implements UserClient { @Override ResultVo\u0026lt;UserInfo\u0026gt; getUserInfo(@PathVariable String id) { // ... // 实现降级内容 } } 依赖隔离 SpringCloud Hystrix 的 依赖隔离 类似于docker的“舱壁模式”。 docker通过”舱壁模式”实现进程隔离，使得容器之间互不影响。 而Hystrix使用该模式实现：“线程池隔离”，会为每一个HystrixCommand创建一个独立线程池，这样就算某个在Hystrix包装下的依赖服务出现延迟过高情况，也只是对该依赖服务的调用产生影响，并不会拖慢其他服务。\n使用 @HystrixCommand 来将某个函数包装成了 Hystrix 命令时，Hystrix框架自动地为这个函数实现了依赖隔离。所以依赖隔离，服务降级在使用时候都是一体化实现的，这样就可以实现服务容错保护。在编程模型上就会非常方便。\n服务熔断 ","date":"2020-07-29T21:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/spring-cloud-hystrix/","title":"Spring Cloud Hystrix 服务容错"},{"content":"Spring Cloud Zuul 在微服务架构中，后端服务往往不直接开放给调用端，而是通过一个API网关根据请求的url，路由到相应的服务。 当添加API网关后，在第三方调用端和服务提供方之间就创建了一面墙，这面墙直接与调用方通信进行权限控制，后将请求均衡分发给后台服务端。 Spring Cloud Zuul 是一个基于JVM路由和服务端的负载均衡器，提供动态路由，监控，弹性，安全等的边缘服务。\n简介 Zuul 的主要功能是路由转发和过滤器（Filter）。不同类型的 Filter 用于处理请求，可以实现以下功能：\n权限控制和安全性：可以识别认证需要的信息和拒绝不满足条件的请求 监控：监控请求信息 动态路由：根据需要动态地路由请求到后台的不同服务集群 压力测试：逐渐增大到集群的流量，以便进行性能评估 负载均衡：为每种类型的请求分配容量并丢弃超过限额的请求 限流 黑白名单过滤 静态资源处理：直接在zuul处理静态资源的响应而不需要转发这些请求到内部集群中 基础使用 创建一个 api-gateway 添加依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-zuul\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加注解 1 2 3 4 5 6 7 8 @EnableZuulProxy @EnableDiscoveryClient @SpringBootApplication public class ApiGatewayApplication { public static void main(String[] args) { SpringApplication.run(ApiGatewayApplication.class, args); } } 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 spring: application: name: api-gateway server: port: 9000 # 自定义路由规则 zuul: routes: user: path: /user/** serviceId: user 测试 通过以上配置文件配置，即可通过 api-gateway 服务去请求 user 服务。\n假设 user 服务的端口为 8080，其中包含一个 api 为 /info。 通过访问 http://localhost:9000/user/info，即可访问该 api。（若原接口包含路由前缀 /user，需要使用 /user/user/info 访问）\n常用功能 统一前缀 1 2 zuul: prefix: /proxy Header 过滤及重定向添加 Host 1 2 3 4 5 6 7 8 9 zuul: # 默认为该配置，会过滤 Cookie Set-Cookie Authorization 信息 # 设置为空即不会过滤 sensitive-headers: Cookie,Set-Cookie,Authorization --- zuul: add-host-header: true # 重定向会添加 host 请求头 查看路由信息 添加依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件 1 2 3 4 5 6 7 8 server: port: 9000 management: endpoints: web: exposure: include: \u0026#39;routes\u0026#39; 访问接口 访问 http://localhost:9000/actuator/routes 获取信息 访问 http://localhost:9000/actuator/routes/details 获取详细信息 Zuul 应用 Zuul Filter Filter是Zuul的核心，用来实现对外服务的控制。Filter有4个生命周期。\npre 在请求被路由到目标服务前执行。 比如权限校验、打印日志等功能。 routing 在请求被路由到目标服务时执行。 用于构建发送给微服务的请求，并使用 Apache HttpClient 或 Netfilx Ribbon 请求微服务。 post 这种过滤器在路由到微服务以后执行。 为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 error 其他阶段发生错误时执行该过滤器。 自定义 Filter 实现自定义 Filter，需继承 com.netflix.zuul.ZuulFilter，并覆盖继承的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Component public class MyFilter extends ZuulFilter { @Override String filterType() { // 定义filter的类型，pre、route、post、error return null; } @Override int filterOrder() { // 定义filter的顺序，数字越小表示顺序越高，越先执行 return 0; } @Override boolean shouldFilter() { // 是否需要执行该filter，true表示执行，false表示不执行 return false; } @Override Object run() { // filter需要执行的具体操作 return null; } } Zuul 限流 限流在前置过滤器（pre）前使用，在请求被转发前调用，且优先级最高。\n令牌桶限流示例。令牌桶算法能够在限制数据的平均传输速率的同时还允许某种程度的突发传输。\n令牌桶算法会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import org.springframework.cloud.netflix.zuul.filters.support.FilterConstants; @Component public class RateLimiterFilter extends ZuulFilter { // 直接使用 guava 中的 RateLimiter 实现 private static final RateLimiter RATE_LIMITER = RateLimiter.create(100); @Override public String filterType() { return FilterConstants.PRE_TYPE; } @Override public int filterOrder() { // 限流是最高优先级，所以比最高优先级 -3 还要小 return FilterConstants.SERVLET_DETECTION_FILTER_ORDER - 1; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { // 如果没有拿到令牌 if (!RATE_LIMITER.tryAcquire()) { throw new RuntimeException(); } return null; } } Zuul 鉴权 在请求服务前，判断是否有权限访问。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Component public class TokenFilter extends ZuulFilter { @Override public String filterType() { return FilterConstants.PRE_TYPE; } @Override public int filterOrder() { // 越小越靠前，放在 PRE_DECORATION_FILTER_ORDER 之前 return PRE_DECORATION_FILTER_ORDER - 1; } @Override public boolean shouldFilter() { return true; } // 需要定义的逻辑 @Override public Object run() throws ZuulException { RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); // 需要根据实际情况，从 header / cookie 中获取信息 String token = ...; // 根据实际情况进行校验 if (...) { // 首先设置 zuul requestContext.setSendZuulResponse(false); // 设置返回信息 requestContext.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); } return null; } } Zuul 跨域 在浏览器中的 ajax 请求是有同源策略的，如果违反了同源策略，就会有跨域问题。在 Zuul 中添加 CorsFilter 过滤器，是跨域问题的一种解决方案。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Configuration public class CorsConfig { @Bean public CorsFilter corsFilter() { final UrlBaseCorsConfigurationSource source = new UrlBaseCorsConfigrationSOurce(); final CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); config.setAllowedOrigins(Collections.singletonList(\u0026#34;*\u0026#34;)); config.setAllowedHeaders(Collections.singletonList(\u0026#34;*\u0026#34;))； config.setAllowedMethods(Collections.singletonList(\u0026#34;*\u0026#34;)); config.setMaxAge(300L); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); return new CorsFilter(source); } } ","date":"2020-07-28T15:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/spring-cloud-zuul/","title":"Spring Cloud Zuul 服务网关"},{"content":"Spring Cloud Config Spring Cloud Config 是一个解决分布式系统的配置管理方案。\nServer 提供配置文件的存储，以接口的形式提供配置文件的内容 Client 通过接口获取数据，并依据此数据初始化应用 Config Server 新建一个 git 仓库 在 git 服务器上创建一个仓库，用来存放配置文件。\n并在仓库中添加相应的配置文件。\nuser-dev.yml user-test.yml user-prod.yml 具体实现 添加依赖 1 2 3 4 5 6 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-config-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 添加注解 1 2 3 4 5 6 7 8 @EnableConfigServer @EnableDiscoveryClient @SpringBootApplication public class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class, args); } } 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 spring: application: name: config cloud: config: server: git: uri: http://github.com/xxx/confg # 配置文件仓库地址 username: ... password: ... searchpath: config-repo # git仓库地址下的相对地址，可配置多个 server: port: 8000 eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 通过接口查看配置 仓库中的配置文件会被转换成web接口，启动应用后，可在浏览器中查看配置文件（若配置文件的格式有错误，将无法访问）。\n如访问 http://localhost:8000/user/dev 即可返回 user-dev.yml 的配置信息。\n/{application}/{profile}[/{label}] /{application}-{profile}.yml /{label}/{application}-{profile}.yml profile：配置环境，label：仓库分支。\nConfig Client 在项目中创建 bootstrap.yml 在项目中，bootstrap.yml 会优先于 application.yml 加载。\napplication.yml 应用场景 主要用于 Spring Boot 项目的自动化配置。\nbootstrap.yml 应用场景 从额外的资源加载配置信息（如使用 Spring Cloud Config 时） 一些固定不能被覆盖的属性（具有高优先级，一般不会被本地配置或application中同名配置覆盖） 一些 加密/解密 的场景 具体实现 添加依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 spring: application: name: user # 该应用获取之前配置好的 user-dev.yml cloud: config: url: http://localhost:8000/ profile: dev label: master --- spring: cloud: config: discovery: enable: true # 启用服务发现 (Eureka) service-id: config # spring cloud config server 应用名称 profile: dev label: master 启动服务 启动服务时，即会先去 git 仓库获取配置信息。\n配置信息自动更新 当 git 仓库中的配置信息更新后，使用配置的客户端并不会自动更新配置。所以我们需要一些机制去触发配置的更新。\nactuator 添加依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加注解，打开更新机制 通过在需要加载更新配置的类上添加 @RefreshScope，当客户端通过触发 POST 方式的 /refresh 时，会自动将新的配置更新到相应的字段中。\n1 2 3 4 5 6 7 8 9 10 @RefreshScope // 该类中配置相关会自动刷新 @RestController public class ActuatorController { @Value(\u0026#34;${env}\u0026#34;) private String env; @RequestMapping(\u0026#34;/env\u0026#34;) public String env { return this.env; } } 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # server 端添加 management: endpoints: web: exposure: include: \u0026#34;*\u0026#34; --- # client 端添加 management: endpoints: web: exposure: include: refresh 测试自动刷新 当 git 仓库中配置文件更新后，通过发送 POST 请求到 /refresh 后，客户端会自动获取最新配置。\n1 curl -v -X POST http://localhost:8080/actuator/refresh Spring Cloud Bus （推荐） 通过 spring cloud bus，通过 POST 请求 /bus-refresh，实现自动获取最新配置。\n至此两种消息代理：\nRabbitMQ Kafka WebHook WebHook 是当某个事件发生时，通过发送 http post 请求的方式来通知信息接收方。\n通过创建 WebHook 即可自动触发 POST 请求，让客户端动态刷新配置。\n","date":"2020-07-27T12:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/spring-cloud-config/","title":"Spring Cloud Config 统一配置中心"},{"content":"Spring Cloud 服务通信 同步通信：\ndobbo 通过 RPC 远程调用。 spring cloud 通过 REST 接口调用。 异步通信：\n通过消息对列，如：RabbitMQ，Kafka，ActiveM 等。 本文主要介绍 Spring Cloud 使用 RestTemplate / OpenFeign 进行 REST 接口调用。\nRestTemplate 通过 RestTemplate 进行调用 1 2 3 4 5 6 7 8 9 public ProductInfo getProductMsg(String id) { RestTemplate restTemplate = new RestTemplate(); ProductInfo response = restTemplate.getForObject( \u0026#34;http://example.com/product/info\u0026#34;, // 远程调用地址 ProductInfo.class, // response 类型 id // 需要传递的参数 ); return response; } 利用 LoadBalancerClient 获取信息 1 2 3 4 5 6 7 8 9 10 11 12 @Autowired private LoadBalancerClient loadBalancerClient; public ProductInfo getProductMsg(String id) { RestTemplate restTemplate = new RestTemplate(); ServiceInstance serviceInstance = loadBalancerClient.choose(\u0026#34;PRODUCT\u0026#34;); // 利用 loadBalancerClient 通过应用名（spring.application.name）获取信息 String url = String.format(\u0026#34;http://%s:%s\u0026#34;, serviceInstance.getHost(), serviceInstance.getPort()) + \u0026#34;/product/info\u0026#34;; ProductInfo response = restTemplate.getForObject(url, ProductInfo.class, id); return response; } 利用 LoadBalance 在 RestTemplate 中直接使用应用名称 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RestTemplateConfig { @Bean @LoadBalance public RestTemplate restTemplate() { return new RestTemplate(); } } --- @Autowired private RestTemplate restTemplate; public ProductInfo getProductMsg(String id) { // 利用 @LoadBalance 可以在 RestTemplate 中使用应用名称 ProductInfo response = restTemplate.getForObject(\u0026#34;http://PRODUCT/product/msg\u0026#34;, ProductInfo.class, id); return response; } OpenFeign （推荐） 引入依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加启动注解 1 2 3 4 5 6 7 8 9 10 import org.springframework.cloud.openfeign.EnableFeignClients; @EnableFeignClients @SpringBootApplication @EnableDiscoveryClient public class FeignApplication { public static void main(String[] args) { SpringApplication.run(FeignApplication.class, args); } } 具体实现 现在有两个服务，分别为 Prodcut 和 Order 。 需求： Order 服务中，客户进行了下单操作后，调用 Product（Feign） 的进行减库存操作。\nProduct 服务中，定义远程调用端。 1 2 3 4 5 6 7 8 9 10 11 12 public class DecreaseStockInput { // ... } --- @FeignClient(name = \u0026#34;product\u0026#34;) // name: 远程服务名(Spring.application.name) public interface ProductClient { @RequestMapping(value = \u0026#34;/product/decrease_stock\u0026#34;) void decreaseStock(@RequestBody List\u0026lt;DecreaseStockInput\u0026gt; decreaseStockInputList); } Order 服务中，对 Product Client 进行调用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Service public class OrderServiceImpl implements OrderService { // 注入的为 Product 中的 ProductClient // 通过依赖的方式 @Autowired private ProductClient productClient; public OrderDTO create(OrderDTO orderDTO) { // ... // 调用 Product 服务中的 api 进行减库存操作 productClient.decreaseStock(decreaseStockInputList); // ... } } ","date":"2020-07-26T21:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/spring-cloud-openfeign/","title":"Spring Cloud 服务通信"},{"content":"Eureka 找到啦！ 服务注册与发现\n简介 Spring Cloud 封装了 Netflix 公司开发的 Eureka 模块来实现服务注册和发现。采用了 C-S 的设计架构。用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。 由两个组件组成。 Ereka Server。 注册中心 Ereka Client。 服务注册 Eureka 采用了客户端发现的方式，在服务运行时，通过(轮训、hash等负载均衡机制等方式)注册中心找到需要服务（即 A 通过 注册中心 找 B，需要谁找谁）。\nEureka Server 注册中心记录着所有应用的信息和状态(如：应用名，所在服务器，是否正常工作)。\n实现一个注册中心 1. 引入依赖 1 2 3 4 5 6 7 8 9 10 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-eureka-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2. 添加启动注解 1 2 3 4 5 6 7 @EnableEurekaServer @SpringBootApplication public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } } 3. 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 spring: application: name: eureka-server Server: port: 8761 eureka: client: register-with-eureka: false # 是否将自己注册到Eureka Server，作为 Server 端不需要 fetch-registry: false # 是否从Eureka Server获取注册信息，作为 Server 端不需要 service-url: # 接收的是一个 Map 结构 defaultZone: http://localhost:8761/eureka/ 4. 启动程序 启动后，访问 http://localhost:8761/，即可看到 Spring Eureka 界面。\n实现 Eureka 集群 在一个分布式系统中，服务注册中心是最重要的基础部分，理应随时处于可以提供服务的状态。为了维持其可用性，通常会采用集群的方案。Eureka通过互相注册的方式来实现高可用的部署\n双节点注册 创建两台服务器，端口分别为 8761 和 8762。\n将 8761 的服务器配置指向 8761，将 8762 的服务器指向 8761。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 spring: application: name: eureka-server Server: port: 8761 eureka: client: register-with-eureka: false fetch-registry: false service-url: # 将 service-url 指向 8762 defaultZone: http://localhost:8762/eureka/ --- spring: application: name: eureka-server Server: port: 8762 eureka: client: register-with-eureka: false fetch-registry: false service-url: # 将 service-url 指向 8761 defaultZone: http://localhost:8761/eureka/ 启动程序后，通过 http://localhost:8761/ 和 http://localhost:8762/ 都可访问 Eureka 界面。并且可以看到另一个节点信息节点的信息。\n多节点注册 在生产中我们需要三台或者大于三台的注册中心来保证服务的稳定性，配置的原理其实都一样：将注册中心分别指向其它的注册中心。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 --- spring: application: name: eureka-server server: port: 8761 eureka: client: register-with-eureka: false fetch-registry: false serviceUrl: defaultZone: http://localhost:8762/eureka/,http://localhost:8763/eureka/ --- spring: application: name: eureka-server server: port: 8762 eureka: client: register-with-eureka: false fetch-registry: false serviceUrl: defaultZone: http://localhost:8761/eureka/,http://localhost:8763/eureka/ --- spring: application: name: eureka-server server: port: 8763 eureka: client: register-with-eureka: false fetch-registry: false serviceUrl: defaultZone: http://localhost:8761/eureka/,http://localhost:8762/eureka/ Eureka Client 实现一个服务注册 1. 依赖配置 1 2 3 4 5 6 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-eureka\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2. 添加启动注解 1 2 3 4 5 6 7 8 9 import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; @EnableDiscoveryClient @SpringBootApplication public class ClientApplication { public static void main(String[] args) { SpringApplication.run(ClientApplication.class, args); } } 3. 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 spring: application: name: eureka-client server: port: 8080 eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ # instance: # 自定义链接 # hostname: example.com 4. 启动程序 启动程序后，进入 Eureka 页面 http://localhost:8761/eureka/，即可看到注册的服务 eureka-client。\n总结 分布式系统中，服务注册中心是最重要的基础部分 @EnableEurekaServer @EnableEurekaClient 具有 心跳检测，健康检查，负载均衡等功能 为保证高可用，建议集群部署 ","date":"2020-07-25T13:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/spring-cloud-eureka/","title":"Spring Cloud Eureka 服务注册与发现"},{"content":"警告：该教程仅为个人记录，该笔记本安装涉及解锁BIOS，存在一定风险，如您使用该教程对计算机进行更改，所造成的的任何后果我概不负责。\n写在最前 开学后太忙，并且电脑我换了块更大的硬盘，这台电脑我不打算再安装黑苹果了，本教程可能会不再更新，最新上传的配置文件中，添加了对 type-C 4K 30Hz 的支持，4K 60Hz 显示器会黑屏，无法输出信号。\n如果想要使用 Clover 安装 10.15 或以下系统的话，可以依旧按照此教程（请将 Clover 和 kext 选择到适应版本）。\n如果打算安装新系统使用的话，建议使用 Opencore 安装。推荐参考 RazerBlade15-Base-Model-Hackintosh_macOS_Monterey，该教程写的非常详细，感谢他的付出。\n建议不要使用 东芝（铠侠）的固态硬盘，我的硬盘为东芝 tr200，在 macOS 中莫名卡顿，我的东芝U盘在 macOS 中也莫名卡顿，其他系统没有什么问题。（玄学问题？）\n祝你玩得愉快！\nGithub ➡️\n因为疫情原因春节一直宅在家，学校假期也延长了，找到了同款笔记本的教程，所以入坑安装黑苹果，最近把步骤整理了一下。\n安装过程我主要参考了 这篇 和 这篇 教程，感谢他们的辛苦付出。部分内容为他们所写教程的汉化，详细或精简，我的水平有限，刚接触黑苹果，建议同时参考他们的教程。\n硬件介绍 结果介绍 解锁BIOS 安装前准备 系统安装 DSDT，SSDT制作 网卡 一些优化 参考 更新 [1] 硬件介绍 型号 最终情况 CPU i7-8750H 可用 GPU Nvdia 1060 Max-Q 除 10.13 High Sierra 安装 WebDriver 外不可用 硬盘 更换了 金士顿 A2000 可用 网卡 9560NGW WIFI 目前无解，蓝牙可用 显示器 1080P 可用 摄像头 可用 扬声器 可用 耳机 无法检测到麦克风 麦克风 不可用，已识别，但在设置中未看见输入电平 触控板 手势可用（反应稍慢） HDMI 接口 直通显卡，除安装 High Sierra 外不可用 Mini DP 接口 直通显卡，除安装 High Sierra 外不可用 雷电3 被识别成 USB3.1，可外接拓展坞外接显示器，我的电脑中需要删除SSDT-12-OptTabl.aml [2] 安装结果 一些小问题 我也是刚刚接触黑苹果，很多问题我也无法解决，有谁了解的话希望能帮助一下，感谢。\n麦克风无法使用，系统能找到但无法使用，耳机麦克风无法找到。想要使用的话只能通过蓝牙耳机了。\n耳机麦克无法识别。\n输出设备默认识别到了扬声器和耳机（即使未插入耳机），无法自动切换，需手动切换。\n更新 今天本来想根据 这篇文章 尝试自己定制一下 AppleALC ，当我把有效节点和路径弄完之后，准备下载 AppleALC-DEBUG 编译的时候，没想到最新版本已经添加了这个笔记本的 layout-id:23。\n请按照如图修改，保存后重启。我的电脑耳机麦克风无法识别（我在 Ubuntu 下也无法找到耳机麦克风的有效节点信息）\n添加 type-c 输出 4k，只能支持到最高 30Hz，输出 60Hz 会直接黑屏。可以安装一个 RDM 进行管理。\n[3] 解锁BIOS 解锁BIOS，存在一定风险，如您使用该教程对计算机进行更改，所造成的的任何后果我概不负责！！！\n雷蛇国内官网没有提供驱动和BIOS的下载，如有需要，需要访问美国官网。点我。\n该笔记本 DVMT 预分配默认为 32MB，不足以启动 MacOS，在 BIOS 中该设置项默认隐藏，所以要提取本机 BIOS 并且进行解锁，将 DVMT 预分配默认设置为 64MB（1080P），分辨率更高请分配更大空间。\n建议在 windows 下操作。\n[3-1] 提取本机 BIOS 注意备份好。\n打开 AFUWINGUI.exe，点击 Save 按钮，导出本机当前 BIOS 。\n[3-2] 修改 BIOS 打开 AMIBCP.exe ，点击 File -\u0026gt; open 打开导出的 BIOS。 如图，在左侧选择 / -\u0026gt; Setup -\u0026gt; Chipset，将左侧的 System Agent Configuration 的 Access 由 Default 修改为 USER 修改完后点击 File -\u0026gt; Save as。重命名为新的 BIOS。 [3-3] 刷入新 BIOS ！！！ 注意，该过程虽然简单，但有一定风险，造成的任何结果与本人无关。\n重新打开 AFUWINGUI.exe，点击 Open 打开刚刚修改后的 BIOS。\n尽可能的退出其他程序，尽量保持后台干净，再点击 Flash 刷入新的 BIOS。\n重启 [4] 安装前准备 [4-1] 准备macOS Catalina 安装盘 推荐使用黑果小兵制作的镜像，使用 TransMac 制作（软件在文件夹中已提供）。这里是10.15.3的镜像。\n如果您要安装更新的系统，请升级 CLOVER，和 kexts/ 到对应兼容或更新的版本，可将制作好的安装盘中 EFI/CLOVER 的文件进行同名替换。（未来的新版本可能不可预知的问题，请酌情升级）。\n[4-2] 启动盘制作 请参考，或自行搜索，网上教程很多。点我。\n[5] 系统安装 [5-1] BIOS 设置 Advanced\nThunderbolt(TM) Configuration Security Level 设置成 No Security Chipset\nSystem Agent (SA) Configuration Graphics Configuration DVMT Pre-Allocated 设置成 64 DVMT Total Gfx Mem 设置成 MAX Security\nSecure Boot 设置成 Disabled Boot\nFast Boot 设置成 Disabled\nCSM Configuration\nCSM Support 设置成 Disabled [5-2] 安装过程 系统安装过程大致相同，选择U盘启动后进入安装。安装过程会重启几次。\n可自行搜索，参考其他人的步骤。\n[5-3] 安装时可能出现的问题 显示程序副本已损坏\n断网 打开终端 修改时间为系统发布对应的时间。 如修改为 2019年。输入 date 000000002019。\n[6] DSDT，SSDT制作 通过修补DSDT，SSDT驱动触控板，音频，电池状态，亮度控制等。\n[6-1] 准备修补 [6-1-1]\n开机在 Clover 引导界面中按 F4，所需文件会加载到 EFI/Clover/ACPI/origin 中。通过 Clover Configurator 挂载启动的 EFI（通过U盘启动就挂载U盘）。\n[6-1-2]\n将 origin 文件夹复制到桌面，同时将 iasl 软件复制到文件夹中。\n[6-1-3]\n打开终端\n1 2 3 cd ~/Desktop mkdir patched ./origin/iasl -da -dl DSDT.aml [6-1-4]\n打开 origin，使用 MaciASL 打开生成的 DSDT.dsl 文件。点击 Compile，确保没有错误。（默认应该没有 error，但有很多 warning，warning 不必关系，若有 error 请将 error 处代码注释或删除）\n[6-1-5]\n确保没有 errors 后，点击 Patch。\n[6-2] 修复电池 [1] 在弹窗的左侧点击 _RehabMan Laptop/[bat]Razer Blade (2014) ，等待右侧进行匹配后点击 Apply。\n如果网络不好的话可能无法加载（github），请切换到合适的网络，或访问 这里，或复制以下代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 #Maintained by: RehabMan for: Laptop Patches #battery_Razer-Blade-2014.txt # created by sidelia 2016-01-17 # changes for Razer Blade Stealth (Kaby Lake) by BlenderSleuth (minor fixes by RehabMan) # works for: # Razer Blade (2014) # Razer Blade Stealth (Kaby Lake), per BlenderSleuth # Razer Blade (14\u0026#34;, late 2016) # Razer Blade Pro (2017) # Razer Blade 15 (2018), per JomanJi/blodtanner into method label B1B2 remove_entry; into definitionblock code_regex . insert begin Method (B1B2, 2, NotSerialized) { Return(Or(Arg0, ShiftLeft(Arg1, 8))) }\\n end; into device label EC0 code_regex BIF1,\\s+16, replace_matched begin IF10,8,IF11,8, end; into device label EC0 code_regex BIF2,\\s+16, replace_matched begin IF20,8,IF21,8, end; into device label EC0 code_regex BIF3,\\s+16, replace_matched begin IF30,8,IF31,8, end; into device label EC0 code_regex BIF4,\\s+16, replace_matched begin IF40,8,IF41,8, end; into device label EC0 code_regex BST0,\\s+16, replace_matched begin ST00,8,ST01,8, end; into device label EC0 code_regex BST1,\\s+16, replace_matched begin ST10,8,ST11,8, end; into device label EC0 code_regex BST2,\\s+16, replace_matched begin ST20,8,ST21,8, end; into device label EC0 code_regex BST3,\\s+16, replace_matched begin ST30,8,ST31,8, end; into method label _BIF code_regex \\^\\^EC0\\.BIF1, replaceall_matched begin B1B2(^^EC0.IF10,^^EC0.IF11), end; into method label _BIF code_regex \\^\\^EC0\\.BIF2, replaceall_matched begin B1B2(^^EC0.IF20,^^EC0.IF21), end; into method label _BIF code_regex \\^\\^EC0\\.BIF3, replaceall_matched begin B1B2(^^EC0.IF30,^^EC0.IF31), end; into method label _BIF code_regex \\^\\^EC0\\.BIF4, replaceall_matched begin B1B2(^^EC0.IF40,^^EC0.IF41), end; into method label _BST code_regex \\^\\^EC0\\.BST0, replaceall_matched begin B1B2(^^EC0.ST00,^^EC0.ST01), end; into method label _BST code_regex \\^\\^EC0\\.BST1, replaceall_matched begin B1B2(^^EC0.ST10,^^EC0.ST11), end; into method label _BST code_regex \\^\\^EC0\\.BST2, replaceall_matched begin B1B2(^^EC0.ST20,^^EC0.ST21), end; into method label _BST code_regex \\^\\^EC0\\.BST3, replaceall_matched begin B1B2(^^EC0.ST30,^^EC0.ST31), end; # added for Razer Blade 15 (2018), per JomanJi into device label EC0 code_regex BIF0,\\s+16, replace_matched begin IF00,8,IF01,8, end; into method label _BIF code_regex \\(\\^\\^EC0.BIF0, replaceall_matched begin (B1B2(\\^\\^EC0.IF00,\\^\\^EC0.IF01), end; # utility methods to read/write buffers from/to EC into method label RE1B parent_label EC0 remove_entry; into method label RECB parent_label EC0 remove_entry; into device label EC0 insert begin Method (RE1B, 1, NotSerialized)\\n {\\n OperationRegion(ERAM, EmbeddedControl, Arg0, 1)\\n Field(ERAM, ByteAcc, NoLock, Preserve) { BYTE, 8 }\\n Return(BYTE)\\n }\\n Method (RECB, 2, Serialized)\\n // Arg0 - offset in bytes from zero-based EC\\n // Arg1 - size of buffer in bits\\n {\\n ShiftRight(Add(Arg1,7), 3, Arg1)\\n Name(TEMP, Buffer(Arg1) { })\\n Add(Arg0, Arg1, Arg1)\\n Store(0, Local0)\\n While (LLess(Arg0, Arg1))\\n {\\n Store(RE1B(Arg0), Index(TEMP, Local0))\\n Increment(Arg0)\\n Increment(Local0)\\n }\\n Return(TEMP)\\n }\\n end; # buffer fields into device label EC0 code_regex (ECCM,)\\s+(256) replace_matched begin ECCX,%2,//%1%2 end; into method label _BIF code_regex \\(\\^\\^EC0.ECCM, replaceall_matched begin (^^EC0.RECB(0x60,256), end; [2] 点击 Compile，确保没有错误。（默认情况下没有，不同版本BIOS可能情况不同）。\n[6-4] 修复重启保存背光亮度 [6-4-1]\n在左侧菜单栏向下滑动，找到 [gfx0] Disable/Enable on _WAK/_PTS (DSDT)，点击都单击 Apply。\n网络不好可点击 这里 或复制以下代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #Maintained by: RehabMan for: Laptop Patches #graphics_PTS_WAK-disable.txt # # The purpose of this patch is to add code to to _WAK # that disables Radeon/nvidia on wake and add code # to _PTS that enables it on _PTS. # # The path of _OFF may have to be customized to match your SSDTs # The patch attempts to identify the correct _REG by using # the ACPI PNP identifier for the EC. # # Use this patch if you experience trouble shutting down # or restarting your laptop when disabling nvida/radeon. # into method label _PTS code_regex ([\\s\\S]*) replace_matched begin External(\\\\_SB.PCI0.PEG0.PEGP._ON, MethodObj)\\n If (CondRefOf(\\\\_SB.PCI0.PEG0.PEGP._ON)) { \\\\_SB.PCI0.PEG0.PEGP._ON() }\\n %1 end; into method label _WAK code_regex (Return\\s+\\(.*) replace_matched begin External(\\\\_SB.PCI0.PEG0.PEGP._OFF, MethodObj)\\n If (CondRefOf(\\\\_SB.PCI0.PEG0.PEGP._OFF)) { \\\\_SB.PCI0.PEG0.PEGP._OFF() }\\n %1 end; [6-4-2] 按 command + F 搜索 Device (ALSD)，找到如图代码，将其替换为以下代码。\n1 2 3 4 5 6 7 8 9 10 Device (_SB.ALS0) { Name (_HID, \u0026#34;ACPI0008\u0026#34;) // _HID: Hardware ID Name (_CID, \u0026#34;smc-als\u0026#34;) // _STA: Status Name (_ALI, 300) // _ALI: Ambient Light Illuminance Name (_ALR, Package () // _ALR: Ambient Light Response { Package () { 100, 300 }, }) } [6-3] 修复触控板 灵刃 15 的标准版和精英版使用的触控板不同，请根据自己的电脑进行选择修复方案。\n[6-3-1] 标准版 [6-3-1-1]\n继续搜索 SSCN。找到 Scope 为 _SB.PCI0.I2C0 下的 SSCN 方法。复制 SSCN 与 FMCN（在 SSCN 下方）这 两个方法。并将这两个方法如图重命名（也可选择删除）。\n重命名为：\n[6-3-1-3]\n搜索 TPD0。将之前剪切的两个方法放到 _INI 方法后。\n[6-3-1-4]\n向下找到如下代码。\n将其更改为如图。\n[6-3-2] 精英版 [6-3-2-1]\n在 Patch 页面中粘贴以下代码代码，点击 Apply。\n[6-3-2-2]\n点击 Compile 进行编译确定无 error（默认没有）。\n1 2 3 4 5 6 7 into method label _STA parent_label GPI0 replace_content begin Return (0x0F) end; into_all method label _CRS parent_label TPD0 replace_content begin ConcatenateResTemplate (SBFB, SBFI) end; [6-4] 保存修改好的 DSDT.aml 点击 File -\u0026gt; save as 。\nFile Format 选择 ACPI Machine Language Binary。命名为 DSDT.aml。存入桌面中的 parched 文件夹中。\n[6-5] 屏蔽 Nvdia 显卡 如果你选择安装 High Sierra 安装 WebDriver 使用 Nvidia 显卡的话，不用该补丁。 [点击这里查看支持驱动的 High Sierra ](https : //www.tonymacx86.com/nvidia-drivers/)\n在的笔记本上使用该补丁会导致 type-c 转视频接口无信号，无法拓展显示器，若出现相同情况请删除该补丁。 [6-5-1]\n再次进入 origin 文件夹中，在终端输入\n1 ./origin/iasl -da -dl SSDT-12-OptTabl.aml [6-5-2]\n根据上方修补电池状态，触控板的方式类似，使用 MaciASL 打开 SSDT-12-OptTabl.dsl\n[6-5-3]\n按 command + F 搜索以下代码\n1 Method (_OFF, 0, Serialized) // _OFF: Power Off [6-5-4]\n在该代码上方，粘贴以下代码\n1 Method (_INI) {_OFF() } // added to call _OFF [6-5-5]\n点击 patch，将以下代码粘贴到弹窗中，点击 apply。\n1 2 3 4 5 6 into method label _INI parent_label \\_SB.PCI0.GFX0 insert begin //added to turn nvidia/radeon off\\n External(\\_SB.PCI0.PEG0.PEGP._OFF, MethodObj)\\n \\n end; [6-5-6]\n点击编译，出现一个错误。\n[6-5-7]\n搜索一下代码，并将其删除，再次编译。\n1 External (_SB_.PCI0.PEG0.TGPC, IntObj) // (from opcode) [6-5-8]\n点击 File -\u0026gt; Save As。将最终的 /aml 文件保存。\n[6-6] 制作 SSDT-USBX.aml 如果想制作自己的 SSDT-USBX.aml。请参考 点我。\n使用 USBMap。点我\n[6-7] 复制提供的的 .aml 文件 将文件夹中的 SSDT-PNLF.aml，SSDT-UIAC-ALL.aml，SSDT-USBX.aml，SSDT-XOSI.aml 同上面修补的两个文件一同放入 patched 文件夹中，最后 patched 文件夹中应该有如下6个文件。\n如果 type-c 转视频接口无信号，请删除SSDT-12-OptTabl.aml\n[7] 网卡 [7-1] 更换博通网卡 在网上找过拆机图，网卡附近的位置还是挺多的，我的选择是拆机的 BCM94360cs2 + 转接卡，可直接免驱使用。\n相比使用原装的网卡位置稍有点高，压在一根的排线上，但是不影响，如选择同款网卡，请注意绝缘，建议上螺丝的时候不要拧太紧，不松动即可。装上之后的效果如图。\n**小提示: **拧螺丝前最好把易碎贴给清理干净。这个贴纸分量太足，卡在螺丝孔中导致一直滑丝。\n**使用效果: **2.4G WIFI 和 蓝牙有干扰，尤其是 2.4G WIFI 使用带宽高的时候，蓝牙几乎不能用。其他使用场景基本良好。\n想折腾的话可选择 DW1820A，可参考 这里。\n博通 BCM94352Z ，现在价钱被炒的很高，目前将近 300，有钱随意。\n[7-2] 使用自带网卡 Intel 蓝牙默认免驱，WiFi 目前无解。\n蓝牙从 windows 重启进入 macOS 可使用（网卡未断电所以上传了驱动）。\n将 该驱动 放入 EFI/CLOVER/kexts，可以实现冷启动驱动自带网卡蓝牙。\n**使用效果: **蓝牙键盘，蓝牙音箱没有问题，蓝牙鼠标貌似不能用。\n[7-3] 使用USB网卡 usb 网卡驱动安装。点我。\nCOMFAST CF-WU815N 150M 单频 COMFAST CF-811AC 650M 双频 COMFAST CF-812AC 1300M 双频 更多其他型号自行搜索 [8] 一些优化 [8-1] HIDPI 开启 HIDPI 后可能会导致开机第二阶段 Logo 变大，因为分辨率是仿冒的，不影响使用。\n使用终端执行：\n1 sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/xzhih/one-key-hidpi/master/hidpi.sh)\u0026#34; 选择 \u0026ldquo;开启 HIDPI\u0026rdquo;\n显示的 ICON 选择 Macbook Pro（在设置界面显示的样式）\n选择分辨率配置 1080P 显示器（根据自身情况选择）\n更多详细情况可参考这篇文章。点我。\n[8-2] 打开 TRIM 如果使用 SSD，一定要打开 TRIM，防止系统多次擦写，确保硬盘寿命。\n1 sudo trimforce enable 完成后系统会进行一次重启。\n[8-3] 禁用睡眠 在终端运行以下命令，并在 设置 -\u0026gt; 节能 中关闭相应设置。\n1 2 3 4 5 sudo pmset -a hibernatemode 0 sudo rm /var/vm/sleepimage sudo mkdir /var/vm/sleepimage [8-4] “洗白”序列号 网络上已经有很多教程，自行搜一下。\n参考 https://github.com/stonevil/Razer_Blade_Advanced_early_2019_Hackintosh https://www.tonymacx86.com/threads/guide-razer-blade-15-2018-detailed-install-guide-high-sierra-10-13-6-17g2208-17g5019.264017/ https://blog.daliansky.net/ ","date":"2020-02-27T21:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/razer-blade-base-hackintosh/","title":"雷蛇 灵刃 15 标准版 2018 黑苹果"}]