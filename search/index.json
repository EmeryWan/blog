[{"content":"使用 ZooKeeper 实现 原理 持久节点（红色）\n瞬时节点（黄色）：不可再有子节点，会话结束后瞬时节点会自动消失\n利用 Zookeeper 的瞬时有序节点的特性，多线程并发创建瞬时节点时，得到有序的序列\n序号最小的线程获得锁，其他的线程则监听自己序号的前一个序号；当前一个线程执行完成，删除自己序号的节点；下一个序号的线程得到通知，将继续执行\n创建节点时，已经确定了线程的执行顺序\n实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 public class ZkLock implements AutoCloseable, Watcher { private ZooKeeper zooKeeper; private String znode; // 当前线程创建的路径 public ZkLock(String connectString, int sessionTimeout) throws IOException { this.zooKeeper = new ZooKeeper(connectString, sessionTimeout, this); } /** * try-catch-with-resource */ public void clode() throws Exception { zooKeeper.delete(znode, -1); zooKeeper.close(); log.info(\u0026#34;释放锁\u0026#34;); } /** * 观察器 */ @Override public void process(WatchedEvent watchedEvent) { // 当前一个节点被删除时，可唤醒获取锁的等待，表示当前线程获取了锁 if (watchedEvent.getType() == Event.EventType.NodeDeleted) { synchronized (this) { notify(); } } } /** * 获取锁 */ public boolean getLock(String businessCode) { try { String path = \u0026#34;/\u0026#34; + businessCode; Stat stat = zooKeeper.exists(path, false); if (null == stat) { // 当前业务若没有持久节点 // 先创建一个持久节点，在持久节点里创建瞬时节点 zooKeeper.create( path, businessCode.getBytes(StandardCharsets.UTF_8), ZooDefs.Ids.OPEN_ACL_UNSAFE, // 公开权限，不使用用户名密码就能访问这个节点 CreateMode.PERSISTENT ); } // 创建瞬时有序节点 String subPath = \u0026#34;/\u0026#34; + businessCode + \u0026#34;/\u0026#34; + businessCode + \u0026#34;_\u0026#34;; znode = zooKeeper.create( subPath, businessCode.getBytes(StandardCharsets.UTF_8), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL ); // 获取该业务下的所有瞬时节点，进行比较排序 List\u0026lt;String\u0026gt; childrenNodes = zooKeeper.getChildren(path, false); Collections.sort(childrenNodes); // 如果列表中的第一个是当前创建的节点，直接获取锁 String firstNode = childrenNodes.get(0); if (znode.endsWith(firstNode)) { return true; } // 监听前一个节点，等待获取锁 String lastNode = firstNode; for (String node : childrenNode) { // 找到当前节点，监听前一个节点 if (znode.endWith(node)) { zooKeeper.exists(\u0026#34;/\u0026#34; + businessCode + \u0026#34;/\u0026#34; + lastNode, this); break; } else { lastNode = node; } } synchronized (this) { // 让当前线程阻塞，并且会释放锁 // 上面的同步代码块才会获得锁并执行 notify() wait(); } return true; } catch (KeeperException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } return false; } } 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Slf4j @RestController public class ZkLockController { @GetMapping(\u0026#34;/zkLock\u0026#34;) public String zkLock() { log.info(\u0026#34;进入方法\u0026#34;); try (ZkLock zklock = new ZkLock(\u0026#34;127.0.0.1:2181\u0026#34;, 10000)) { if (zkLock.getLock(\u0026#34;order\u0026#34;)) { log.info(\u0026#34;获取了锁\u0026#34;); try { TimeUtil.SECONDS.sleep(10); // 模拟业务 } catch (InterruptedException e) { e.printStackTrace(); } } log.info(\u0026#34;完成业务\u0026#34;); } catch (Exception e) { e.printStackTrace(); } return \u0026#34;success\u0026#34;; } } Curator 依赖配置 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-recipes\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 @Slf4j public class DemoTest { @Test public void test() { String zookeeperConnectionString = \u0026#34;127.0.0.1:2181\u0026#34;; RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3); CuratorFramework client = CuratorFrameworkFactory.newClient(zookeeperConnectionString, retryPolicy); client.start(); String lockPath = \u0026#34;/order\u0026#34;; InterProcessMutex lock = new InterProcessMutex(client, lockPath); try { // 获取互斥锁，阻塞直到可用，或给定时间到期 // 同一个线程调用 acquire() 可重入 if (lock.acquire(30, TimeUnit.SECONDS)) { try { log.info(\u0026#34;获取锁\u0026#34;); } finally { // 必须通过 release() 释放锁 lock.release(); } } } catch (Exception e) { e.printStackTrace(); } } } ","date":"2022-05-11T21:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/distributed-lock/zookeeper/","title":"使用 ZooKeeper 实现分布式锁"},{"content":"Redis NX 实现 利用 NX 的原子性，多个线程并发时，只有一个线程可以设置成功，设置成功即获取了锁。\n如果没有获取锁，不会阻塞当前方法，直接跳过任务。\n获取锁 1 2 # set key unique_value NX PX 30000 set product:stock:clothes UUID NX PX 30000 key 根据不同的业务，区分不同的锁 unique_value 保证每个线程的随机值都不同，用于释放锁时的校验 NX key 不存在时设置成功，key 存在则不成功 PX 自动失效时间。若出现异常，没有主动释放锁，可以保证超时后，锁可以过期失效（毫秒） 释放锁 释放锁将该 key 删除，在释放锁之前需要校验设置的随机数，相同才表示是该线程加的锁，能释放。\n需要采用 LUA 脚本，del 命令没有提供校验值的功能。\nredis 执行命令是按照一条指令完成之后，再执行下一条，用 lua 脚本，能保证 redis 执行完这个脚本才执行下一条，所以能保证判断 和 删除是原子性的\n1 2 3 4 5 if redis.call(\u0026#34;get\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;, KEYS[1]) else return 0 end 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Slf4j @RestController public class RedisLockController { @Autowired private RedisTemplate redisTemplate; @GetMapping(\u0026#34;/redisLock\u0026#34;) public String redisLock() { // 获取分布式锁 Boolean lock = redisTemplate.execute((RedisCallback\u0026lt;Boolean\u0026gt;) redisConnection -\u0026gt; { Expiration expiration = Expiration.seconds(30); // NX RedisStringCommands.SetOption setOption = RedisStringCommands.SetOption.ifAbsent(); // 需要使用 redisTemplate 中的序列化器 byte[] redisKey = redisTemplate.getKeySerializer().serialize(key); byte[] redisValue = redisTemplate.getValueSerializer().serialize(value); return redisConnection.set(redisKey, redisValue, expiration); }); if (lock) { // 获取到了锁 log.info(\u0026#34;获取到了锁\u0026#34;); try { TimeUnit.SECONDS.sleep(15); // 模拟业务处理 } catch (InterruptedException e) { e.printStackTrace(); } finally { String script = \u0026#34;if redis.call(\\\u0026#34;get\\\u0026#34;,KEYS[1])==ARGV[1] then\\n\u0026#34; + \u0026#34;\\treturn redis.call(\\\u0026#34;del\\\u0026#34;,KEYS[1])\\n\u0026#34; + \u0026#34;else\\n\u0026#34; + \u0026#34;\\treturn 0\\n\u0026#34; + \u0026#34;end\u0026#34;; RedisScript\u0026lt;Boolean\u0026gt; redisScript = RedisScript.of(script, Boolean.class); boolean result = redisTemplate.execute(redisScript, Arrays.asList(key), value); log.info(\u0026#34;释放锁 {}\u0026#34;, result); } } log.info(\u0026#34;业务完成\u0026#34;); return \u0026#34;success\u0026#34;; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 @Slf4j @RestController public class RedisLock { private RedisTemplate redisTemplate; // 锁名称，不同业务可能锁不同 private String key; private String value; // 锁过期时间，单位秒 private int expireTime; public RedisLock(RedisTemplate redisTemplate, String key, int expireTime) { this.redisTemplate = redisTemplate; this.key = key; this.expireTime = expireTime; // value 可以不暴露出去，每个线程都是不一样的 this.value = UUID.randomUUID().toString(); } /** * 获取锁 */ public boolean getLock() { // 获取分布式锁 Boolean lock = (Boolean) redisTemplate.execute((RedisCallback\u0026lt;Boolean\u0026gt;) redisConnection -\u0026gt; { Expiration expiration = Expiration.seconds(expireTime); // NX RedisStringCommands.SetOption setOption = RedisStringCommands.SetOption.ifAbsent(); // 由于这里需要接受 byte, 不能暴力的使用 string.getBytes() // 要使用模板里面的 key\\value 序列化器来实现 byte[] redisKey = redisTemplate.getKeySerializer().serialize(key); byte[] redisValue = redisTemplate.getValueSerializer().serialize(value); Boolean result = redisConnection.set(redisKey, redisValue, expiration, setOption); return result; }); return lock; } /** * 释放锁 */ public boolean unLock() { // lua 脚本 String script = \u0026#34;if redis.call(\\\u0026#34;get\\\u0026#34;,KEYS[1])==ARGV[1] then\\n\u0026#34; + \u0026#34;\\treturn redis.call(\\\u0026#34;del\\\u0026#34;,KEYS[1])\\n\u0026#34; + \u0026#34;else\\n\u0026#34; + \u0026#34;\\treturn 0\\n\u0026#34; + \u0026#34;end\u0026#34;; RedisScript\u0026lt;Boolean\u0026gt; redisScript = RedisScript.of(script, Boolean.class); Boolean result = (Boolean) redisTemplate.execute(redisScript, Arrays.asList(key), value); return result; } } Redisson 依赖配置 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16.7\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Slf4j @RestController public class RedissonLockController { @Autowired private RedissonClient redissonClient; @GetMapping(\u0026#34;/redissonLock\u0026#34;) public String redissonLock() { log.info(\u0026#34;执行方法\u0026#34;); final String key = \u0026#34;redisson\u0026#34;; RLock lock = redissonClient.getLock(key); // 锁超时时间，如果未获得锁，会阻塞等待获取到锁（-1 表示没有超时时间） lock.lock(30, TimeUnit.SECONDS); log.info(\u0026#34;获取锁\u0026#34;); try { TimeUnit.SECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } finally { log.info(\u0026#34;释放锁\u0026#34;); lock.unlock(); } log.info(\u0026#34;完成业务\u0026#34;); return \u0026#34;success\u0026#34;; } } ","date":"2022-05-11T12:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/distributed-lock/redis/","title":"使用 Redis 实现分布式锁"},{"content":"🌱 介绍 许多平台都提供了免费的静态页面托管的服务，如 Github Pages，Vercel，Netlify等。但在国内由于一些“原因”，这些国外的服务在国内的访问并不稳定。\n国内的免费托管平台如 Gitee 限制很多，不可以自定义域名而且之前出现了防盗链问题，访问也不是很快，不太推荐作为托管平台。\n腾讯云推出的云开发 CloudBase 也有静态页面托管服务。其实它相比这些静态托管平台，有更多强大的功能，甚至能够搭一整套系统。虽然是付费服务，但是在按量付费的情况下资费不是很高，在博客访问量不是很高的情况下十分合适。\n目前在腾讯云中暂时还没有 Hugo 的模板。目前有两种方式可以达到自动部署的功能：\n🌰 使用 Github Actions 编译，通过 Tencent CloudBase Github Action 自动部署到 CloudBase。\n🌰 使用 Github Actions 编译，推送到 Web 应用托管（webify） 的简易静态页面模板。\n🏖 使用 CloudBase 使用 CloudBse 时，使用按量计费环境会有一些免费用量。\n☁️ 腾讯云 创建环境 在 云开发 CloudBase 新建一个应用，选择 空模板，根据自身需求填写信息。\n创建成功后，获得 环境ID。\n获取 API 密钥 为部署新建一个密钥对。在 访问管理 -\u0026gt; 用户列表 -\u0026gt; 新建用户 -\u0026gt; 自定义创建 -\u0026gt; 可访问资源并接收消息。🔗 传送门\n根据自己的需要，新建用户名后选择 编程访问，点击下一步。\n在自定义策略中勾选：\nQcloudAccessForTCBRole：授予云开发（TCB）对云资源的访问权限； QcloudAccessForTCBRoleInAccessCloudBaseRun：供云开发（TCB）服务角色（TCB_QcsRole）进行关联，用于 TCB 访问其他云服务资源。包含私有网络 VPC、云服务器 CVM 相关操作权限。 点一下一步后，新建用户成功。可以获得 SecretId 和 SecretKey。\n⚙️ Github Actions 设置 Github Secrets 在项目的 Settings -\u0026gt; Secrets -\u0026gt; Actions 中添加上述得到的 ENV_ID，SECRET_ID，SECRET_KEY（名称可以自定义）。\n添加 workflows 可以在仓库的 Actions 中 new workflow，或者在项目中 .github/workflows 添加。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name: Tencent CloudBase on: push: branches: - main jobs: hugo-publish: name: publish content to static website runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: latest extended: true - name: Build run: hugo --minify --gc # 使用云开发 Github Action 部署 - name: Deploy to Tencent CloudBase uses: TencentCloudBase/cloudbase-action@v2 with: secretId: ${{ secrets.QCLOUD_SECRET_ID }} secretKey: ${{ secrets.QCLOUD_SECRET_KEY }} envId: ${{ secrets.QCLOUD_ENV_ID }} 🚧 提示：\n这里使用了 TencentCloudBase/cloudbase-action@v2，需要在项目根目录添加 cloudbaserc.json。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \u0026#34;envId\u0026#34;: \u0026#34;{{env.ENV_ID}}\u0026#34;, // 这里需要更改为你的 环境ID，或者在 .env 文件中配置 \u0026#34;$schema\u0026#34;: \u0026#34;https://framework-1258016615.tcloudbaseapp.com/schema/latest.json\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;framework\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hugo-blog\u0026#34;, \u0026#34;plugins\u0026#34;: { \u0026#34;client\u0026#34;: { \u0026#34;use\u0026#34;: \u0026#34;@cloudbase/framework-plugin-website\u0026#34;, \u0026#34;inputs\u0026#34;: { \u0026#34;outputPath\u0026#34;: \u0026#34;public\u0026#34;, \u0026#34;ignore\u0026#34;: [ \u0026#34;.git\u0026#34;, \u0026#34;.github\u0026#34;, \u0026#34;cloudbaserc.js\u0026#34; ] } } } } } 🚧 提示：\n这里也可以选择 Tencent CloudBase Github Action V1。🙋‍♂️ （推荐）\nV2 比 V1 有更多功能，比如拉取代码在腾讯云端编译，但目前没有 Hugo 模板。我们已经在 Github Actions 产出了静态文件，直接推送即可。所以目前对于 hugo 来说，没什么区别，使用甚至 V1 更快更简洁。\n1 2 3 4 5 6 7 8 # 将上述 jobs 内替换为 - name: Deploy to Tencent CloudBase uses: TencentCloudBase/cloudbase-action@v1.1.1 with: secretId: ${{ secrets.QCLOUD_SECRET_ID }} secretKey: ${{ secrets.QCLOUD_SECRET_KEY }} envId: ${{ secrets.QCLOUD_ENV_ID }} staticSrcPath: public 🏝 使用 webify 使用 Web 应用托管（webify）主要是利用 Github Actions 生成 静态页面到另一个分支，再托管这个分支的内容。\n☁️ 创建服务 在 Web 应用托管 -\u0026gt; 新建应用 新建一个简易静态页面模板。根据需求填写信息。选择纯静态页面。\n在 应用列表 -\u0026gt; 应用设置 中配置仓库信息，并根据自身情况选择静态文件的部署分支。（如果当前没有生成静态页面的分支，可完成后面操作后再进行此步骤）。\n⚙️ Github Actions 设置 Github Token 在用户的 Settings -\u0026gt; Developer settings -\u0026gt; Personal access tokens -\u0026gt; Generate new token 获取一个 Repo Token。🔗 传送门\n在项目的 Settings -\u0026gt; Secrets -\u0026gt; Actions 中添加上述得到的 Token。\n添加 workflows 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 name: Tencent CloudBase on: push: branches: - main jobs: hugo-publish: name: publish content to static website runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: latest extended: true - name: Build run: hugo --minify --gc - name: Deploy to Branch uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.ACCESS_TOKEN }} keep_files: false publish_branch: gh-pages # 更改为你想要生成的分支 publich_dir: ./public commit_message: ${{ github.event.head_commit.message }} ⛓ 参考 🔗 https://blog.wangjunfeng.com/post/hugo-cloudbase/ 🔗 https://cloud.tencent.com/document/product/1210/43389 🔗 https://github.com/TencentCloudBase/cloudbase-action 🔗 https://github.com/TencentCloudBase/cloudbase-action/blob/3354b442713265aa9d7c5bf03b0b8cb0173f546f/README.md ","date":"2022-05-01T21:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/hugo-in-cloudbase/","title":"使用 Github Actions 在腾讯云 CloudBase 部署 Hugo"},{"content":"在并发情况下，多个线程会对同一个资源进行争抢，可能会导致数据不一致的问题。\n为了解决这个问题，通过引入锁机制，使用一种抽象的锁，对资源进行锁定，达到同步访问。\n实现 Java 采用了两种实现方式：\n基于 Object 的悲观锁\n基于 CAS 的乐观锁\n悲观锁 在 Java 中，每个对象（Object），都拥有一把锁，存放在对象头中，记录了当前对象被哪个线程所占用。\nsynchronized synchronized 关键字可以用来同步线程，其被编译后，会生成 monitorenter 和 moniterexit 两个字节码指令，用来进行线程的同步。\nsynchronized 是非公平锁。一把锁只能被一个线程获取，没有获得锁的线程只能等待。\n加锁方式：\n对象锁（锁住 this）\n修饰实例方法 pubilc sychronized void method() { ... }\n代码块锁住当前对象 synchronized(this)\n类锁\n修饰静态方法 public static sychronized void method() { ... }\n代码块锁定 class 对象 synchronized(MyClass.class) { ... }\nsynchronized 修饰的方法，无论方法正常执行完还是抛出异常，都会释放锁。\nJDK 1.6 对 synchronized 的优化 synchronized 依赖于 JVM，使用的是操作系统底层的 Mutex Lock 实现。\nJava 线程的实现是对操作系统线程的映射，每当唤醒或挂起一个线程的时候，都要切换到操作系统的内核态，代价是非常昂贵的。\nJDK 1.6 对锁的实现引入了大量的优化，如 锁粗化，锁消除，轻量级锁，偏向锁，适应性自旋等。\n对象锁一共有四种状态：\n无锁 -\u0026gt; 偏向锁 -\u0026gt; 轻量级锁 -\u0026gt; 重量级锁\n会随着竞争情况逐渐升级（不可以降级），提高获取锁和释放锁的效率。\n无锁状态 不对资源进行操作系统级别的锁定。\n某些资源不会出现多线程竞争的情况，随意多个线程调用\n利用其他一些方式控制同步。如：CAS\n偏向锁\n适合只有一个线程访问同步代码块的场景 在一些情况下，没有多线程的竞争，每次都是同一个线程多次获取锁，那么对象锁会“记住”这个线程，只要是这个线程过来，就直接把锁交出去。\n如果对象发现目前不是只有一个线程，而是有多个线程在竞争锁，偏向锁就会升级为轻量级锁。\n轻量级锁\n适合同步代码块的执行速度非常快的场景 当锁升级为轻量级锁的时候，其他线程会通过 CAS 进行自旋等待来获取锁，不会阻塞，从而提高性能。\n重量级锁\n适合同步代码块执行速度较长的场景 对象锁状态被标记为重量级锁，需要通过 Monitor 来对线程进行控制。\n乐观锁 ","date":"2022-03-30T14:02:02+08:00","permalink":"https://emerywan.github.io/blog/p/thread/lock/","title":"Java 并发 - 锁机制"},{"content":"☘️ 通用程序设计 Effective Java 阅读笔记。本章主要讨论了 Java 语言的具体细节。包括：\n局部变量 控制结构 类库 数据结构 两种不是由语言本身提供的机制： 反射 本地方法 优化和命名惯例。 57. 将局部变量的作用域最小化 🌸 建议 🌱 最小化局部变量的范围，可提高代码的可读性和可维护性，降低出错的可能性。在第一次使用它的地方声明变量。\n🍀 每个局部变量声明都应该包含一个初始化表达式。try-catch 语句除外。\n如果一个变量初始化，会抛出一个 checked 异常，必须在 try 中初始化（除非所包含的方法可以抛异常）。\n如果该值必须在 try 块之外使用，那么它必须在 try 块之前声明，此时它还不能“合理地初始化“。\n1 2 3 4 5 Set\u0026lt;String\u0026gt; set = null; try { set = cons.newInstance(); } catch () { } 🍀 循环结束后不再需要循环变量，for 循环就优于 while 循环（for 循环允许声明循环变量）。\n🌱 保持方法小而集中，每个操作都用一个方法来完成。避免一个操作相关的局部变量可能在另一个操作中。\n🌻 案例 🌾 遍历集合的首选习惯用法\n1 2 3 for (Element e : c) { // do something with e } 💐 需要访问 Iterator / 调用 Iterator 的 remove()，首选 for\n1 2 3 4 for (Iterator\u0026lt;Element\u0026gt; i = c.iterator(); i.hasNext(); ) { // i is loop variable Element e = i.next(); // do something with i and e } 💐 循环习惯用法：最小化局部变量的范围\n1 2 3 4 // 每次循环都会调用 expensiveComputation()，且返回结果相同 for (int i = 0, n = expensiveComputation(); i \u0026lt; n; i++) { // do something with i } 它有两个循环变量：i 和 n，都具有完全正确的作用域。第二个变量 n 用于存储第一个变量的极限，避免了每次迭代中冗余计算的成本。 如果循环涉及一个方法调用，并且保证在每次迭代中返回相同的结果，应该使用这个习惯用法。\n58. for-each 循环优于传统的 for 循环 🌸 建议 🌱 for-each 隐藏迭代器或索引变量，可消除混乱和出错。\n🌱 : 表示 “在\u0026hellip;里面”。使用 for-each 循环不会降低性能。\n🥀 以下情况不应该使用 for-each：\n🌰 破坏性过滤。如果需要遍历一个集合并删除选定元素，需要使用显式的迭代器，以便调用其 remove()。\n🌰 转换。遍历时需要替换其中元素的值，需要 List 迭代器或数组索引来替换元素的值。\n🌰 并行迭代。如果需要并行遍历多个集合，那么需要显式地控制迭代器或索引变量，以便所有迭代器或索引变量都可以同步执行。\n🌻 案例 💐 使用 Collection.removeIf() 可避免显式的遍历（Java8）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public interface Collection\u0026lt;E\u0026gt; extends Iterable\u0026lt;E\u0026gt; { default boolean removeIf(Predicate\u0026lt;? super E\u0026gt; filter) { Objects.requireNonNull(filter); boolean removed = false; final Iterator\u0026lt;E\u0026gt; each = interator(); while (each.hasNext()) { if (filter.test(each.next)) { each.remove(); removed = true; } } return removed; } } 59. 了解并使用库 🌸 建议 能用库方法就用库方法。\n具有算法背景的高级工程师花了大量时间设计、实现和测试库方法，然后将库方法展示给该领域的几位专家，以确保库方法是正确的。 这些库方法经过 beta 测试、发布，并被数百万程序员广泛使用了近 20 年。\n🌱 使用标准类库的好处：\n🌰 利用编写它的专家的知识和以前使用它的人的经验。 🌰 不必浪费时间为那些与你的工作无关的问题编写专门的解决方案。 🌰 随着时间的推移，它们的性能会不断提高，无需付出任何努力。（版本更新） 🌰 可以将代码放在主干中。这样的代码更容易被开发人员阅读、维护和复用。 🌱 在每个主要版本中，都会向库中添加许多特性，了解这些新增特性是值得的。\n🍀 每个程序员都应该熟悉 java.lang、java.util 和 java.io 的基础知识及其子包。 其他库的知识可以根据需要获得。尤其是：\n🌰 java.util.Collections 🌰 java.util.Streams 🌰 java.util.concurrent 🍀 如果你在 Java 平台库中找不到你需要的东西，你的下一个选择应该是寻找高质量的第三方库，比如谷歌的优秀的开源 Guava 库。如果你无法在任何适当的库中找到所需的功能，只能自己实现它。\n🌻 案例 💐 从 Java 7 开始，就不应该再使用 Random。\n🌰 在大多数情况下，选择的随机数生成器现在是 ThreadLocalRandom。 它能产生更高质量的随机数，而且速度非常快。 🌰 对于 Fork Join Pool 和并行 Stream，使用 SplittableRandom。 假设你想要生成 0 到某个上界之间的随机整数，许多程序员会编写一个类似这样的小方法：\n1 2 3 4 5 // 有严重缺陷 static Random rnd = new Random(); static int random(int n) { return Math.abs(rad.nextInt()) % n; } 它有三个缺点:\n🌩 n 是小的平方数，随机数序列会在相当短的时间内重复 🌩 如果 n 不是 2 的幂，那么平均而言，一些数字将比其他数字更频繁地返回 🌩 在极少数情况下会返回超出指定范围的数字 Integer.MAX_VALUE 直接使用 Ramdom.nextInt(n) 即可。\n1 public int nextInt(int n); 🌾 Linux curl in Java 9\n假设你想编写一个程序来打印命令行中指定的 URL 的内容（这大致是 Linux curl 命令所做的）。在 Java 9 之前，这段代码有点乏味，但是在 Java 9 中，transferTo() 被添加到 InputStream 中。这是一个使用这个新方法执行这项任务的完整程序：\n1 2 3 4 5 public static void main(String[] args) throws IOException { try (InputStream in = new URL(args[0]).openStream()) { in.transferTo(System.out); } } 60. 若需要精确答案就应避免使用 float double 🌸 建议 🌱 float 和 double 类型特别不适合进行货币计算，因为不能将 0.1（或 10 的任意负次幂）精确地表示。 1 2 // 0.6100000000000001 System.out.println(1.03 - 0.42); 🍀 数值不是太大，可以使用 int 或 long 🌰 如果数值不超过 9 位小数，可以使用 int 🌰 如果不超过 18 位，可以使用 long 🌰 如果数量可能超过 18 位，则使用 BigDecimal 例如：在微信支付的 Java SDK 中，货币的类型为 int，结算单位为 分； 在支付宝支付的 Java SDK 中，货币的类型为 String，结算单位为 元\n🌱 使用 BigDecimal 类型代替 double / float。注意，使用 BigDecimal 的 String 构造函数而不是它的 double / float 构造函数。 61. 基本数据类型优于包装类 🌸 建议 🌱 Java 类型系统由两部分组成：\n🌰 基本类型（primitive type）：int double boolean 🌰 引用类型（reference type）：String List 每个基本类型都有一个对应的引用类型，称为包装类型。 🌱 基本类型和包装类型之间有三个主要区别：\n🌰 基本类型只有它们的值，而包装类型具有与其值不同的标识 🌰 基本类型只有全功能值，而每个包装类型除了对应的基本类型的所有功能值外，还有一个非功能值，即 null 🌰 基本类型比包装类型更节省时间和空间 🍀 要有选择，就应该优先使用基本类型，而不是包装类型。基本类型更简单、更快。\n🥀 以下情况必须使用包装类型：\n🌰 作为集合中的元素、键和值 🌰 必须使用包装类型作为类型参数，Java 不允许使用基本类型。如 ThreadLocal\u0026lt;Integer\u0026gt; 🌰 进行反射方法调用时，必须使用包装类型 🌻 案例 🌾 以下三个例子为常见的包装类型问题：\n🌩 将 == 操作符应用于包装类型几乎都是错误的\n1 2 🙅‍♂️ Comparator\u0026lt;Integer\u0026gt; naturalOrder =(i, j) -\u0026gt; (i \u0026lt; j) ? -1 : (i == j ? 0 : 1); 表达式 i \u0026lt; j 会使 i 和 j 引用的 Integer 实例自动拆箱。 表达式 i == j 对两个对象引用执行比较，返回 false。\n1 2 3 4 5 🙆 Comparator\u0026lt;Integer\u0026gt; naturalOrder = (iBoxed, jBoxed) -\u0026gt; { int i = iBoxed, j = jBoxed; // 自动拆箱 return i \u0026lt; j ? -1 : (i == j ? 0 : 1); }; 🌩 NullPointerException\n1 2 3 4 5 6 7 public class Unbelievable { static Integer i; public static void main(String[] args) { if (i == 42) System.out.println(\u0026#34;Unbelievable\u0026#34;); } } 计算表达式 i == 42 时抛出 NullPointerException。空对象引用自动拆箱，将得到一个 NullPointerException。\n🌩 严重的性能问题\n1 2 3 4 5 6 7 public static void main(String[] args) { Long sum = 0L; for (long i = 0; i \u0026lt; Integer.MAX_VALUE; i++) { sum += i; } System.out.println(sum); } 局部变量 sum，它是包装类型 Long，而不是基本类型 long。变量被反复装箱和拆箱（超出缓存部分时），导致产生明显的性能下降。\n62. 其他类型更合适时，应避免使用字符串 🌸 建议 🌱 当存在或可以编写更好的数据类型时，应避免将字符串用来表示对象。\n🌱 如果使用不当，字符串比其他类型更麻烦、灵活性更差、速度更慢、更容易出错。\n🍀 字符串不适合代替其他的值类型。\n🌰 如果是数值类型，则应将其转换为适当的数值类型，如 int、float 或 BigInteger。 🌰 如果是问题的答案，如“是”或“否”这类形式，则应将其转换为适当的 Enum 或 boolean。 🌰 更一般地，如果有合适的值类型，无论是基本类型还是对象引用，都应该使用它；如果没有，应该写一个。 🌱 字符串不适合代替枚举类型。\n🌱 字符串不适合代替聚合类型。\n如果一个实体有多个组件，将其表示为单个字符串通常是很不合适的。 例如，下面这行代码来自一个真实的系统标识符：\n1 String compoundKey = className + \u0026#34;#\u0026#34; + i.next(); 这种方法有很多缺点：如果用于分隔字段 # 的字符出现在其中一个字段中，可能会导致混乱。要访问各个字段，你必须解析字符串。不能提供 equals、toString 或 compareTo 方法，但必须接受 String 提供的行为。 更好的方法是编写一个类来表示聚合，通常是一个私有静态成员类。（Item-24）。\n🍀 字符串不适合代替 capabilities\n有时，字符串用于授予对某些功能的访问权。\n例如，考虑线程本地变量机制的设计。这样的机制提供了每个线程都有自己的变量值。 这种方法的问题在于：字符串键表示线程本地变量的共享全局名称空间。 为了使这种方法有效，客户端提供的字符串键必须是唯一的：如果两个客户端各自决定为它们的线程本地变量使用相同的名称，它们无意中就会共享一个变量，这通常会导致两个客户端都失败。 而且安全性很差。恶意客户端可以故意使用与另一个客户端相同的字符串密钥来非法访问另一个客户端的数据。\n63. 当心字符串连接引起的性能问题 🌸 建议 🌱 不要使用字符串连接操作符合并多个字符串，除非性能无关紧要。使用字符串串联运算符 +，重复串联 n 个字符串，需要 n 的平方级时间。\n🍀 使用 StringBuilder 代替 String\n64. 通过接口引用对象 🌸 建议 🍀 优先使用接口而不是类来引用对象。如果存在合适的接口类型，那么应该使用接口类型声明参数、返回值、变量和字段。\n🌱 使用接口作为类型的习惯，程序将更加灵活。\n🥀 以下情况使用 类 来引用对象：\n🌰 没有合适的接口存在 String 和 BigInteger 🌰 框架的基本类型是类，不是接口 java.io 🌰 实现接口的类提供了接口中不存在的额外方法 PriorityQueue 中实现了 Queue 不存在的 comparator 🌻 案例 🌾 优先使用接口作为类型 1 2 3 4 5 🙆 Set\u0026lt;Son\u0026gt; sonSet = new LinkedHashSet\u0026lt;\u0026gt;(); 🙅‍♂️ LinkedHashSet\u0026lt;Son\u0026gt; sonSet = new LinkedHashSet\u0026lt;\u0026gt;(); 65. 接口优先反射机制 🌸 建议 🌱 核心反射机制 java.lang.reflect 提供对任意类的编程访问。给定一个 Class 对象，可以获得 Constructor、Method、Filed 实例。\n🌱 通过过调用 Constructor、Method、Filed 实例上的方法，可以构造底层的实例、调用底层类的方法、访问底层类中的字段。\n🌰 Method.invoke() 🥀 反射允许一个类使用另一个类，即使在编译前者时后者并不存在。然而，这种能力是有代价的：\n🌰 失去了编译时类型检查的所有好处，包括异常检查。 🌰 执行反射访问所需的代码既笨拙又冗长。写起来很乏味，读起来也很困难。 🌰 性能降低。 🍀 如果你对应用程序是否需要反射有任何疑问，那么它可能不需要。\n🌱 如果必须用到在编译时无法获取的类，在编译时存在一个适当的接口或超类来，可以用反射方式创建实例，并通过它们的接口或超类正常地访问它们。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public static void main(String[] args) { // Translate the class name into a Class object Class\u0026lt;? extends Set\u0026lt;String\u0026gt;\u0026gt; cl = null; try { cl = (Class\u0026lt;? extends Set\u0026lt;String\u0026gt;\u0026gt; cl = null) Class.forNmae(args[0]) // Unchecked cast } catch (ClassNotFoundException e) { fatalError(\u0026#34;Class not found.\u0026#34;); } // Get the constructor Constructor\u0026lt;? extends Set\u0026lt;String\u0026gt;\u0026gt; cons = null; try { cons = cl.getDeclaredConstructor(); } catch (NoSuchMethodException e) { fatalError(\u0026#34;No parameterless constructor\u0026#34;); } // Instantiate the set Set\u0026lt;String\u0026gt; s = null; // 🙋‍♂️ use interface try { s = cons.newInstance(); } catch (IllegalAccessException e) { fatalError(\u0026#34;Constructor not accessible\u0026#34;); } catch (InstantiationException e) { fatalError(\u0026#34;Class not instantiable.\u0026#34;); } catch (InvocationTargetException e) { fatalError(\u0026#34;Constructor threw \u0026#34; + e.getCause()); } catch (ClassCastException e) { fatalError(\u0026#34;Class doesn\u0026#39;t implement Set\u0026#34;); } // Exercise the set s.addAll(Arrays.asList(args).subList(1, args.length)); System.out.println(s); } 🥀 上例中反射机制的缺点\n🌰 产生 6 个运行时异常 🌰 根据类名生产实例需要 25 行冗长代码，而调用构造器只需要一行。 🌱 反射的合法用途（很少）是管理类对运行时可能不存在的其他类、方法或字段的依赖关系。\n🌱 如果编写的程序必须在编译时处理未知的类，则应该尽可能只使用反射实例化对象，并使用在编译时已知的接口或超类访问对象。\n66. 谨慎地使用本地方法 🌸 建议 🌱 非常不建议使用本地方法。JVM 变得更快了，并且 Java 平台的成熟，它提供了对许多以前只能在宿主平台中上找到的特性。 例如，Java 9 中添加的流 API 提供了对 OS 流程的访问。\n🥀 使用本地方法有严重的缺点： 🌰 本地语言不安全（Item-50），使用本地方法的应用程序不再能免受内存毁坏错误的影响。 🌰 Java 更依赖于平台，因此使用本地方法的程序的可移植性较差。 🌰 它们更难调试。 🌰 如果不小心，本地方法可能会降低性能，因为垃圾收集器无法自动跟踪本地内存使用情况，而且进出本地代码会产生相关的成本。 🌰 本地方法需要“粘合代码”，这很难阅读，而且编写起来很乏味。 67. 谨慎地进行优化 🌸 建议 🍀 优化弊大于利，尤其是如果过早地进行优化。在此过程中，你可能会生成既不快速也不正确且无法轻松修复的软件。\n🍀 不要为了性能而牺牲合理的架构。努力编写好的程序，而不是快速的程序。\n🍀 好的程序体现了信息隐藏的原则：在可能的情况下，它们在单个组件中本地化设计决策，因此可以在不影响系统其余部分的情况下更改单个决策\n🍀 不优化不意味着在程序完成之前可以忽略性能问题。实现上的问题可以通过以后的优化来解决，但是对于架构缺陷，如果不重写系统，就不可能解决限制性能的问题，特别是在设计API、线路层协议和持久数据格式时。\n🍀 再多的底层优化也不能弥补算法选择的不足。\n68. 遵守被广泛认可的命名约定 🌸 建议 🌱 Java 平台有一组完善的命名约定，其中许多约定包含在《The Java Language Specification》\n🌰 typographical 字面约定 🌰 grammatical 语法约定 🌱 字面惯例示例：\nIdentifier Type Example Package or module org.junit.jupiter.api, com.google.common.collect Class or Interface Stream, FutureTask, LinkedHashMap, HttpClient Method or Field remove(), groupingBy(), getCrc() Constant Field MIN_VALUE, NEGATIVE_INFINITY Local Variable i, denom, houseNum Type Parameter T, E, K, V, X, R, U, V, T1, T2 🌱 语法命名约定比排版约定更灵活，也更有争议。\n","date":"2022-03-30T14:02:02+08:00","image":"https://emerywan.github.io/blog/p/effective-java/general-programming/effective-java_hu8285674e0bb74a2ea271ae0a19ba75ab_128063_120x120_fill_box_smart1_3.png","permalink":"https://emerywan.github.io/blog/p/effective-java/general-programming/","title":"通用程序设计"},{"content":"这一节，将介绍 LSTM (Long Shorter Term Memory)，以及用 pytorch 实现 LSTM 。\nLSTM 是一种 RNN 模型，是对 simple RNN 的改进，LSTM 可以避免梯度消失的问题，可以有更长的记忆。LSTM 的论文在 1997 年发表。\nHochreiter and Schmidhuber.\tLong short-term\tmemory. Neural computation, 1997.\n🔖 LSTM LSTM 也是一种循环神经网络，原理跟 simple RNN 差不多，每当读取一个新的输入 $x$，就会更新状态 $h$。\nLSTM 的结构比 simple RNN 要复杂很多，simple RNN 只有一个参数矩阵， LSTM 有四个参数矩阵。接下来我们具体来看看 LSTM 的内部结构。\n🚠 传送带 LSTM 最重要的设计是这个传送带 Conveyor belt，即为向量 $C$。过去的信息通过传送带，直接送到下一个时刻，不会发生太大的变化。LSTM 就是靠传送带来避免梯度消失的问题。\nLSTM 中有很多个门 gate，可以有选择的让信息通过。\n🚪 Forgate Gate 首先介绍 forget gate 遗忘门。遗忘门由 ☘️ sigmoid 函数，和 🍀 元素积 element wise multiplication 两部分组成。\n🌼 输入 sigmoid 的是一个向量 $a$，sigmoid 作用到向量 $a$ 的每一个元素上，把每一个元素都压到 0 和 1 之间。\n举个例子，假如向量 $a$ 是：[1, 3, 0, -2]，那么，sigmoid 函数将分别作用在这四个元素上。然后分别输出：[0.73, 0.95, 0.5, 0.12] 。\n输入的向量 $a$，与输出的向量 $f$ 应该有相同的维度，这个例子里，向量 $a$ 是四维的，向量 $f$ 也会是四维的。\n🌸 算出 $f$ 向量之后，计算传送带向量 $c$ 与遗忘门向量 $f$ 的元素积。元素积 element wise multiplication 是这样算的：\n$c$ 和 $f$ 都是四维的向量，将它们的每一个元素分别相乘。所以元素积的结果也是个四维的向量。\n这个遗忘门 $f$，有选择的让传送带 $c$ 的值通过：\n🌰 假如 $f$ 的一个元素是 $0$，那么 $c$ 对应的元素不能通过，对应的输出是 $0$；\n🌰 假如 $f$ 的一个元素是 $1$，那么 $c$ 对应的元素就全部通过，对应的输出是 $c$ 本身。\n遗忘门 $f$ 具体是这么算出来的：首先看这张结构图，$f_t$ 是上一个状态 $h_{t-1}$，与当前输入 $x$ 的函数。\n把状态 $h_{t-1}$ 与输入 $x_t$ 做拼接 concatnation，得到更高维度的向量。然后计算矩阵 $w_f$ 与这个向量的乘积，得到一个向量，再用 sigmoid 函数，得到向量 $f_t$，$f_t$ 的每一个元素都介于 0 和 1 之间，遗忘门有一个参数矩阵 $w_f$，需要通过 反向传播 从训练数据里学习。\n🚪 Input Gate 刚才讲了遗忘门，现在来看一看 input gate 输入门。在这张结构图里，输入门 $i_t$，依赖于旧的状态向量 $h_{t-1}$，和新的输入 $x_t$。\n输入门 $i_t$ 的计算类似于遗忘门，把旧的状态 $h_{t-1}$，与新的输入 $x_t$ 做拼接 concatnation，得到更高维的向量。\n然后计算矩阵 $w_i$ 与这个向量的乘积得到一个向量，最后使用激活函数 sigmod，得到向量 $i_t$（$i_t$ 的每一个元素都介于 $0$ 和 $1$ 之间）。\n输入门也有自己的参数矩阵，计作 $W_i$，$W_i$ 也需要从训练数据中学习。\n🆕 New Value 还需要计算新的输入值 new value $\\widetilde{c}_t$，$\\widetilde{c}_t$ 是个向量，计算方法跟遗忘门和输入门都很像。也是把旧状态 $h_{t-1}$，与新输入 $x_t$ 做拼接，再乘到参数矩阵上。\n区别在于激活函数不是 sigmoid，而是双曲正切函数 tanh，所以算出的向量 $\\widetilde{c}_t$ 的元素都介于 (-1, +1)。\n计算 new value $\\widetilde{c}_t$，也需要一个单独的参数矩阵矩阵 $w_c$。\n🚂 更新 传输带 我们已经算出了遗忘门 $f_t$，输入门 $i_t$，以及新的输入值 $\\widetilde{c}_t$，我们还知道传送带旧的值 $c_{t-1}$，现在可以更新传送带 $c$ 了。\n1️⃣ 计算遗忘门 $f_t$ 和传送带旧的值 $c_{t-1}$ 的元素积。\n遗忘门 $f_t$，和传送带 $c_{t-1}$ 是维度相同的向量，算出的乘积也是个向量。遗忘门 $f_t$，可以选择性的遗忘 $c_{t-1}$ 中的一些元素，如果 $f_t$ 中的一个元素是 $0$，那么 $c_{t-1}$ 相应的元素就会被遗忘。\n上一步通过 🚪 遗忘门 选择性删除掉了传送带 $c_{t-1}$ 的一些元素，现在要往传送带上添加新的信息。\n2️⃣ 计算输入门 $i_t$，和新的输入值 $\\widetilde{c}_t$ 的元素积。\n输入门 $i_t$ 和新的值 $\\widetilde{c}_t$ 都是维度相同的向量，他们的乘积也是维度相同的向量，把乘积加到传送带上，这样就完成了对传送带的一轮更新。\n用遗忘门删除了传送带上的一些信息，然后用遗忘门输入加入新的信息，得到了传送带新的值 $c_t$，到现在，已经更新完传送带 $c$ 。\n🚪 Output Gate 最后一步是计算 LSTM 的输出，也就是状态向量 $h_t$。\n$h_t$ 是这么计算的：首先计算输出门 $o_t$，输出门 $o_t$ 跟前面的遗忘门，输入门的计算基本一样。\n把旧的状态 $h_{t-1}$，与新的输入 $x_t$ 做拼接，得到更高维的向量，然后算矩阵 $W_o$ 与这个向量的乘积，得到一个向量，最后使用激活函数 sigmod 得到向量 $o_t$。$o_t$ 的每一个元素都介于 (0, 1)，输出门也有自己的参数向量 $W_o$，$W_o$ 也需要从训练数据中学习。\n现在计算状态向量 $h_t$，对传送带 $c_t$ 的每一个元素求双曲正切tanh，把元素全都压到 (-1, +1) 区间。\n然后，求这两个向量的元素积，这个红色向量是刚刚求出的输出门 $o_t$，这样就得到了状态向量 $h_t$。\n看一下结构图，$h_t$ 他有两份 copys，$h_t$ 的一份 copy 传输到了下一步，另一份 copy 成了 LSTM 的输出。\n到第 t 步为止，一共有 t 个向量 $x$ 被输入了 LSTM，我们可以认为所有这些 $x$ 向量的信息，都积累在了状态 $h_t$ 里面。\n🧮 LSTM 的参数数量 我们来算一下 LSTM 的参数数量，LSTM 有 ❶ 遗忘门；❷ 输入门；❸ 新的输入；❹ 输出门。\n这四个模块都有各自的参数矩阵 $w$，所以一共有 4 个参数矩阵，矩阵的行数是：$shape(h)$，列数是： $shape(h)+shape(x)$\n所以，LSTM 参数的数量是：\n$4 * shape(h) * [ shape(h) + shape(x)]$\n🛠 实现 LSTM Doing\n🎐 总结 总结一下这一节的内容，这节介绍了 LSTM 模型和用 PyTorch 的实现。\nLSTM 和 simple RNN 主要的区别，是用了一条传送带，让过去的信息可以很容易传输到下一时刻，这样就有了更长的记忆。\nLSTM 的表现总是比 simple RNN 要好，所以当我们想使用 RNN 的时候就用 🙋‍♂️ LSTM 模型，而不要用 🙅‍♂️ simple RNN 模型。\nLSTM 有四个组件，分别是：\n🚪 Forget Gate 遗忘门 🚪 Input Gate 输入门 🆕 New Value 新的输入 🚪 Output Gate 输出门 这四个组件各自有一个参数矩阵，所以一共有四个参数矩阵，LSTM 参数的数量是：\n$4 * shape(h) * [ shape(h) + shape(x)]$\n下一节将介绍：\nstacked RNN bi-directional RNN 预训练 ⛓ 参考 🔗 https://github.com/wangshusen/DeepLearning/blob/master/Slides/9_RNN_3.pdf 🔗 https://colah.github.io/posts/2015-08-Understanding-LSTMs/ 🔗 https://www.youtube.com/watch?v=vTouAvxlphc 🔗 https://www.bilibili.com/video/BV1UK4y1d7xa ","date":"2022-03-19T20:36:14+08:00","image":"https://nlp.letout.cn/img/nlp/banner.png","permalink":"https://emerywan.github.io/blog/p/nlp-in-action/long-short-term-memory/","title":"Long Shorter Term Memory"},{"content":"本节主要内容为 文本处理 Text Processing 和 词嵌入 Word Embedding。本节和下面两节内容都会使用 IMDb 电影评论的数据，用来搭建机器学习模型分析电影评论。\n🌱 IMDb IMDb 是最有名的电影评论网站，用户可以在 IMDb 上给电影打分，1 分是非常讨厌，10 分是非常喜欢，如果乐意，还可以写一段电影评论。\n如果不给你看分数，只给你看评论，你大概能猜到用户打的分数，但你的猜测可能不太准确。如果换种方式，让你判断电影评论是 正面 positive 的还是 负面 negative 的，你应该会有很高的准确率。有人从 IMDb 上爬了 5 万条电影评论，这些评论都是很极端的，都是强烈的喜欢，或者强烈反感。这个二分类问题对于人来说很简单，人读一下电影评论就能轻易知道这是正面评价还是负面评价，人应该能有 100% 的准确率，这个数据集被分成两半，2 万 5 千条作为训练数据 Train，另外 2 万 5 千条作为测试数据 Test。\n你可以在下面的链接中获取到数据集：https://ai.stanford.edu/~amaas/data/sentiment/\n🔖 文本处理文本处理 在词嵌入 Word Embedding 和搭建机器学习模型之前，首先要进行文本处理，将文本变成序列 Sequence，文本处理很无聊，但我们应该重视它，文本处理的好坏，会直接影响机器学习模型的准确率。\n🚀 Tokenization 文本处理的第一步是 Tokenization，把文本分割成很多 tokens，这里我们把文本分割成很多单词，一个 token 就是一个单词（假如你把文本分割成字符，那么一个 token 就是一个字符），做完 Tokenization，一个很长的字符串就被分割成一个很多单词的列表。\nTokenization 看起来很简单，但是讲究很多。比如：\n🌰 是否应该把大写变成小写？ 通常情况下应该把大写变成小写，大小写单词通常是一个意思；但有时候会混淆单词（Apple -\u0026gt; apple），比如 Apple 是苹果公司，apple 是水果，大小写的 apple 并不是相同的单词。\n🌰 去除停用词。stop word 有些应用会去除 stop word，它是 the、a、of 等最高频的单词，这些词几乎出现在所有的句子里，对这个二分类问题几乎是没有帮助。\n🌰 拼写纠错。 用户发电影评论的时候，大部分情况下并不会仔细检查，所以写的东西难免会有拼写错误，所以做拼写纠错通常是有用的。\n这里只是举了几个例子，实际上做 Tokenization 的时候需要做大量的工作，Tokenization 看似简单，但实际上并不容易。\n🧰 Build Dictionary 第二步是建立一个字典。可以先统计词频，去掉一些低频词，让后让每个单词对应一个正整数，比如让 the -\u0026gt; 1; cat -\u0026gt; 2; sat -\u0026gt; 3。有了这个字典，就可以把每个单词对应到一个整数，这样一来，一句话就可以用正整数的列表表示，这个列表被称为序列 Sequences。\n如果有必要的话，还得进一步做 one-hot encoding，把单词表示成 one-hot 向量。\n在电影评论的例子里，数据是 5 万条电影评论，每条电影评论可以表示成一个字符串。做完 Tokenization 和 Encoding 后，每条电影评论都会转换成一个 Sequences，也就是一个正整数的列表。\n电影评论有长有短，有人只能写几个字的评论，有人能洋洋洒洒写几千字，所以得到的这些 Sequences 的长度也各不相同。比如这两条 Sequences 的长度分别是 52 和 90。\n这就造成了一个问题，训练数据没有对齐，每条 Sequences 都有不同的长度。做机器学习的时候，我们需要把数据存储到矩阵或者张量里，每条序列都得有相同的长度，需要把序列对齐。\n解决方案是这样的：我们可以固定长度为 $w$。假如一个序列长度太长，超过了 $w$ 个词，就砍掉前面的词，只保留最后面 $w$个词（当然保留最前面 $w$ 个词也同样可以）；假如一个序列太短，不到 $w$ 个词，那么就做 zero padding 用 0 来补齐，把长度增加到 $w$。\n这样一来，所有序列的长度都是 $w$，可以存储到一个矩阵里。\n🍀️ 词嵌入 文本处理已经完成了，现在每个词都用一个正整数来表示，下一步是 Word Embedding，把每个词都表示为一个一维向量。\n现在每个单词都用一个数字来表示，该怎么把这些 Categorical 特征表示为数值向量呢？\n显然可以做 one-hot encoding，用一个 one-hot 向量来表示一个单词。 比如 good: index = 2，于是使用标准正交积 $e_2$ 来表示，它的第二个元素是 1，其余元素都是 0，$e_2=[0, 1, 0, 0, \u0026hellip;, 0]$\n假如 vocabulary = v，也就是说字典里一共有 $v$ 个单词，那么就需要维度 dimension = v 的 one-hot 向量，要是字典里有 1 万个单词，那么这些 one-hot 向量都是 1 万维的，这样的向量维度是在太高了。下一节介绍 RNN 的时候你会看到，RNN 的参数数量正比于输入向量的维度，我们肯定不想让输入的向量是 1 万维的，否则一层 RNN 将会有好几十万个参数。所以我们要做 Word Embedding，把这些高维 one-hot 向量映射到低维向量。\n具体做法是吧 one-hot 向量 $e_i$ 乘到参数矩阵 $P^T$ 上，矩阵 $P^T$ 的大小是 $d*v$。其中 $d$ 是词向量的维度，由用户自己决定；$v$ 是 vocabulary，表示字典里单词的数量。\n矩阵的乘法的结果记做向量 $x_i$，$x_i$ 就是一个词向量，维度是 $d*1$，如果 one-hot 向量 $e$ 的第三个元素是 1，那么 $x_i$ 就是 $P^T$ 矩阵的第三列，可以看出，$P^T$ 矩阵每一列都是一个词向量。\n同理，下面这个参数矩阵 $P$ 的每一行都是一个词向量。这个矩阵的行数是 $v$，也就是 vocabulary；每一行对应一个单词，矩阵的列数是 $d$，$d$ 是用户决定的，$d$ 的大小会影响机器学习模型的表现，应该用 交叉验证 Cross Validation 用来选择一个比较好的 $d$。\n字典里的第一个词的是 movie，那么第一行就是 movie 的词向量；字典里的第二个词是 good，那么第二行就是 good 的词向量。\n我们的任务是判断电影评论是正面的还是负面的，这个参数矩阵是从训练数据中学习出来的，所以这些词向量都带有感情色彩，假如这些词向量都是二维的，我们就可以在平面坐标系中标出这些词向量。\nfantastic; good; fun 这些词向量都带有正面情感，所以这三个词的词向量学出来都比较接近；同理，poor; boring; mediocre 这些词带有负面情感，所以学出来的词同样也应该比较接近，但是这些词的词向量应该远离正面色彩的词向量。像 movie; is 这样的中性词，没有感情色彩，它们应该在中间。\n🎐 总结 最后总结一下这一章的内容。\n这一节上半部分，说明了文本处理是什么样的。给我们一条电影评论，首先做 Tokenization，把电影评论分割成很多单词，然后把很多单词编码成数字，这样一整条电影评论就可以很多正整数来表示，我们把这个正整数序列叫做 Sequences，就是神经网络中 Embedding 层的输入。由于电影评论的长短不一，得到的 Sequence 的长短也不一样，没办法存储在一个矩阵里，解决方案是 Alignment 对齐。假设最大长度为 20，如果长度大于20，就只保留最后 20 个单词；如果长度不到 20，就用 0 补齐，把长度增加到 20。这样一来，每个 Sequences 长度都相同。\n","date":"2022-03-11T21:14:45+08:00","image":"https://nlp.letout.cn/img/nlp/banner.png","permalink":"https://emerywan.github.io/blog/p/nlp-in-action/text-processing-and-word-embedding/","title":"文本处理与词嵌入"},{"content":"这一节我们来学习循环神经网络Recurrent Neural Networks。本节的内容是 Simple RNN，以及用 Pytorch 编程实现 Simple RNN。\n🌱 简介 现在 RNN 没有以前流行，尤其是在自然语言处理上，RNN 已经有一些过时了，如果训练的数据足够多，RNN 的效果不如 Transformer 模型，但是在小规模的问题上，RNN 还是很有用的。\n🔖 如何建模时序数据？ 机器学习中经常用到文本、语音等 时序数据sequential data（按时间顺序记录的数据列，有长度不固定的特点）。\n首先思考一个问题，怎么对这样的时序数据进行建模？ 在上一小节中，我们将一段文字整体输入到一个逻辑回归 Logistic Regression 模型中，让模型来做二分类，这属于一个 one-to-one 模型，一个输入对应一个输出。\n全连接神经网络和卷积神经网络都属于 one-to-one 模型。\n人脑并不会使用 one-to-one 模型处理时序数据，不会把一整段文字全部输入到大脑，我们在阅读的时候，会从左到右阅读一段文字，不断地在大脑里积累信息，阅读一段话之后，你脑子里就积累了一段文字的大意。\none-to-one 模型要求一个输入对应一个输出，比如：输入一张图片，输出每一类的概率值，one-to-one 的模型比较适合这类图片问题，但是不太适合文本问题。\n对于文本问题，输入和输出的长度并不固定，一段话可长可短，所以输入的长度并不固定；输出的长度也不固定，比如将英语翻译成汉语，一句英语有十个单词，翻译成汉语可能有十个字，可能有八个字，也可能是四个字的成语，输出汉语的字数并不固定，由于输入和输出的长度不固定，one-to-one 模型就不太适合了。\n对于时序数据，更好的是 many-to-one 或者是 many-to-many 模型，RNN 就是这样的模型，输入和输出的长度都不固定。所以 RNN 很适合语音，文本等时序序列数据。\n🍀️ RNN RNN 和跟人的阅读习惯很类似：人每次看一个词，会逐渐在大脑里积累信息；RNN 每看一个词，会用状态向量 $h$ 来积累阅读过的信息。\n首先，我们将输入的每个词用 词嵌入word embedding 变成一个词向量 $x$。\n每次把一个词向量输入 RNN，就会更新状态 $h$ ，把新的输入积累到状态 $h$ 里面。\n在 $h_0$中，包含了第一个词 the 的信息，在 $h_1$ 里面，包含了前两个 the cat 的信息；以此类推，状态 $h_2$ 包含 了前三个词 the cat sat 的信息，最后一个状态 $h_t$ 包含了整句话的信息，可以把 $h_t$ 看做 RNN 从整句话 the cat sat on the mat 抽取的特征向量，在更新状态 $h$ 的时候，需要用到参数矩阵 $A$。\n注意：整个 RNN 只有一个参数矩阵 $A$。无论这条链有多长，参数 $A$ 只有一个，$A$ 随机初始化，然后利用训练数据来学习 $A$。下面首先讲解 Simple RNN Model。\n🚀 Simple RNN 我们具体看看，Simple RNN 简单循环神经网络是怎么把输入的词向量 $x$，结合到状态 $h$ 中的。\n我们将上一个状态记做 $h_t-1$，新输入词向量记做 $x_t$，将这两个向量做拼接 concatenation，得到一个更高维的向量。\n图中这个矩阵 $A$ 是 RNN 的模型参数，这里计算矩阵 $A$ 和这个向量的乘积（拼接后的向量），矩阵和向量的乘积是一个向量，然后使用激活函数 tanh 作用在向量的每一个元素上，最后把激活函数的输出记做新的状态 $h_t$。\n这个激活函数式 双曲正切函数 hyperbolic tangent function，输入是任意实数，输出在 $(-1, +1)$ 之间。由于用了双曲正切激活函数，向量 $h_t$ 的每一个元素都在 $(-1, +1)$ 之间。\n这个神经网络的结构图可以这样理解：新的状态 $h_t$，是旧状态 $h_{t-1}$ 和新的输入 $x_t$ 的函数，神经网络模型的参数是 $A$：新的状态 $h_t$，依赖于向量 $h_{t-1}$, 向量 $x_t$ 以及矩阵 $A$。\n🎨 为什么需要使用 tanh 作为激活函数？ 我们思考这样一个问题：为什么需要使用 tanh 作为激活函数？能否将这个激活函数去掉，去掉之后会发生什么呢？\n首先我们做个简化，假设输入的词向量的元素都是 $0$。如图，这等同于输入的词向量 $x_t$ 都去掉，把矩阵 $A$ 右边一半也去掉。\n$x_0 = x_1 = \u0026hellip; = x_{100} = 0$\n这么一来，第 100 维的特征向量 $h_{100} = Ah_{99} = A^2h_{98} = \u0026hellip; = A^{100}h_0$。\n🌰 假设矩阵 $A$ 最大的特征值略小于 1 比如，最大的特征值等于 0.9。那么会发生什么呢？\n$0.9^{100}$ 非常接近于 0 了，所以矩阵 $A^{100}$ 非常接近于 0，那么新的特征向量 $h_{100}$ 也几乎也是一个全零的向量。\n🌰 假设矩阵 $A$ 最大的特征值略大于 1 比如，最大的特征值等于 1.2。\n$1.2^{100}=82817974.522$，所以矩阵 $A^{100}$ 的元素都超级大，$A^{100}$的每个元素都很大，假如循环的次数更多一些，或者 $A$ 的特征值再大一些，状态向量的值就会爆炸。\n假如没有这个激活函数 tanh，数值计算的时候很有可能会出问题，要么计算出的结果全部等于 0，要么爆炸了全部是 NaN: Not a Number。通过使用这个激活函数，每次更新状态 $h$ 后，都会做一个标准化操作 normalization，让 $h$ 恢复到 $(-1, +1)$ 这个合适的区间里。\n🏝️ Simple RNN 模型参数数量 我们来数一下 Simple RNN 有多少个模型参数。\n如图，先看一下这个拼接后向量，这个向量的维度是 $h_{t-1}$ 的维度加上 $x_t$ 的维度：\n所以 $A$ 一定要有 $shape(h)+shape(x)$ 维度这么多列：\n$A$ 的行数等于 $h$ 的维度：\n所以，最终矩阵 $A$ 的大小等于：\n$parameter(A) = shape(h) * [shape(h) + shape(x)]$\n这个乘积 $parameter(A)$ 就是 simple RNN 的最终的参数数量。\n📖 (TODO) Simple RNN 的电影评论分析 Doing\n🧰 simple RNN 的缺陷 下面看一下 simple RNN 这种简单的模型有什么缺陷。\n举个栗子 🌰 ，现在有这样一个问题，给定半句话，要求预测下一个单词。\n输入是 clouds are in the，正确的输出应该是 sky，如果在大量文本中预测 RNN，应该是有能力做出这样的预测的。在这个例子里，RNN 只需要看最近的几个词，尤其是 clouds are，并不需要更多的上下文看的更远。\n这个例子是对 simple RNN 十分有利，simple RNN 特别擅长这种 short-term dependence，simple RNN 不擅长的是 long-term dependence。\nRNN 的状态 $h$，和之前所有的输入 $x$ 都有函数依赖关系，照理来说，如果改变输入的单词 $x_1$，所有的状态 $h$ 都会发生变化，但实际上，simple RNN 并没有这种性质，所以很不合理。如果把第 100 个状态向量 $h_{100}$，关于输入 $x_1$ 求导，你会发现导数几乎等于 0。\n$\\frac{\\partial h_{100}}{\\partial x_1} \\approx 0$\n导数几乎等于 0 说明什么呢？说明当我们改变 $x_1$时，$h_{100}$ 几乎不会发生任何变化，也就是说状态 $h_{100}$ 和 100 步之前的输入 $x_1$ 几乎没有关系，这显然不合理，说明状态 $h_{100}$ 几乎把很多步之前的输入都给忘记了，simple RNN 的这种遗忘会给后续操作造成很多问题。\n再举个栗子 🌰 ，这是很长的一段话，一开始是 I grow up in China when I was a child, ... ... 到了很多句话之后，有这样一句，I speak fluent ...。\n下一个词应该是 Chinese，我小时候在中国，所有会说流利的中文，然而 simple RNN 不太可能会做出 Chinese 这个正确的预测，因为 RNN 已经把前文给忘记了。simple RNN 擅长的是 short-term dependence，RNN 看到最近的单词是 speak fluent，所以 RNN 知道下一个单词可能是某种语言，可能是 Chinese、English、French、Japanese 等等，但正确答案是 Chinese，因为上文有 I grow up in china when i was child，simple RNN 就像金鱼一样记忆力只有 7 秒，RNN 根本就不记得上文有这句话，所以 I speak fluent ... 预测单词可能是 English , French 等任何一种语言，未必是 Chinese。\n🎐 总结 最后总结一下这一节的内容：\nRNN 是一种神经网络，但是他的结构不同于全连接网络和卷积网络，RNN 适用于文本，语音等时序序列数据，RNN 按照顺序读取每一个词向量，并且在状态向量 $h$ 中积累看到过得信息，$h_0$ 中包含了 $x_0$ 的信息，$h_1$ 中包含了 $x_0$ 和 $x_1$ 的信息，$h_t$ 中积累了之前所有 $x={x_0, x_1, \u0026hellip;, x_t}$ 的信息。\n有一种错误的看法是 $h_t$ 中只包含了 $x_t$ 的信息，这是不对的，$h_t$ 中包含了之前所有输入的信息，可以认为 $h_t$ 代表了 RNN 从整个序列中抽取的特征向量，所有我们只需要 $h_t$ 就可以判断电影评价是正面的还是负面的。\nsimple RNN 有一个参数矩阵 $A$，它可能还会一个 intercept 参数向量 $b$，上面的介绍中忽略了这个参数向量 $b$，这个参数矩阵 $A$ 的维度是：\n$shape(h) * [shape(h) + shape(x)]$\n参数矩阵 $A$ 一开始随机初始化，然后从训练数据上学习。注意：simple RNN 只有一个参数矩阵，不管这个序列有多长，参数矩阵只有一个，所有模块里的参数都是一样的。\nRNN 有一个缺点，RNN 的记忆比较短，会遗忘很久之前的输入 $x$，如果这个时间序列很长，有好几十步，最终 RNN 就会忘记了之前的输入。下一节将介绍 LSTM，LSTM 的记忆会比 simple RNN 长很多，但是 RNN 也还是会有遗忘的问题。\n","date":"2022-03-08T20:36:14+08:00","image":"https://nlp.letout.cn/img/nlp/banner.png","permalink":"https://emerywan.github.io/blog/p/nlp-in-action/simple-rnn/","title":"RNN"},{"content":"🌱 类别特征 机器学习的数据通常有 类别特征 Categorical Features ，我们需要把类别特征 Categorical Features 转化成机器学习模型能理解的数值特征，下面使用一个例子来具体讲解类别特征数据的处理。\n这张表的每一行是一个人的数据，包括：年龄、性别、国籍，我们需要把这些数据变成机器学习模型可以理解的数值特征。\n表格的第一列是年龄，年龄本身就是数值特征，所以可以不用做处理，数值特征的特点是可以比较大小，比如 35 岁的人比 31 岁的年龄大。\n第二列是性别，性别是二元特征，我们可以用一个数来表示性别。用 0 表示女性，用 1 表示男性。这样一来，性别就表示为一个标量：0 / 1。\n第三列是国籍，比如中国，美国，印度。国籍是类别特征，机器学习并不理解国籍，所以我们要把国籍编码成数值向量。世界上约有 197 个国家，我们先用一个 [1 - 197] 的整数表示一个国家。可以建立一个字典，把国籍映射成一个 [1 - 197] 的整数。比如：China:1; US:2; India:3; Japan:4; Germany:5。\n我们要从 1 开始计算，而不能从 0 开始计算。\n做这种映射，国籍就表示成 [1 - 197] 之间的整数。仅仅把国籍表示成 [1 - 197] 的整数还是不行，一个整数只是一种类别，它们之间不能比较大小。US:2; India:3 这个数字并不表示印度大于美国，这些整数只是类别而已，并不是真正的数值特征。\n所以要进一步对国籍做 one-hot encoding ，用 one-hot 向量来表示国籍：\n1 2 China -\u0026gt; 1 -\u0026gt; [1,0,0,0,...,0] US -\u0026gt; 2 -\u0026gt; [0,1,0,0,...,0] 比如，中国对应 1，所以用 197 维的 one-hot 向量 [1,0,0,0...,0] 来表示，其中第一个元素为 1，其余元素都是 0；美国对应 2，这个 197 维的向量 [0,1,0,0...,0] 第二个元素是 1，其余元素都是 0。这样一来，每个国籍就由一个 one-hot 向量表示，一共有 197 个国家，所以每个向量都是 197 维的。\n我们要从 1 开始计算，而不能从 0 开始计算。 因为我们要把 0 保留，用来表示未知或者缺失的国籍。数据库里面经常会有缺失的数据（比如用户没有填写国籍），这样缺失的国籍就用 0 来表示，它的 one-hot 向量就是一个全 0 的向量[0,0,0,0...,0]。\n下面这个例子中，我们用一个 199 维表示一个人的特征。比如这个人 28 岁，女性，国籍是中国。\n其中，一个维度表示年龄，一个维度表示性别，一个 197 维的 one-hot 向量表示国籍。\n这个例子里，这个 36 岁，男性，国籍未知的人的特征是这个 199 维的向量，我们用一个 197 维的全 0 向量表示未知国籍。\n🔖 为什么要用 one-hot 向量表示特征 在处理类别特征的时候，我们使用 one-hot 向量表示国籍，每个国籍都用 197 维的向量表示。为什么要用 one-hot 向量而不用一个数字表示呢？比如用 1 表示中国，2 表示美国，3 表示印度。这样一来，名字就变成了数字，可以做数值计算，而且用一个数字表示的话，可以节省 197 倍的存储空间。当然这是不行的。否则我们就不需要 one-hot encoding 了。\n假设我们使用 1 -\u0026gt; China; 2 -\u0026gt; US; 3 -\u0026gt; India。那么将中国 1 和美国 2 的特征加起来：1+2=3 ，相当于 “中国 + 美国 = 印度”。这样的特征完全不合理。\n使用 one-hot 特征向量更合理。将 China 和 US 的 one-hot 向量加起来，得到 [1,1,0,0,...,0]，第一个和第二个元素都是 1，其余元素都是 0，这个特征向量的解释是：既有中国国籍，又有美国国籍。\n所以做机器学习的时候，不能用一个标量来表示一个类别特征，这种特征做法求和等数值计算是没有意义的。正确的做法是使用 one-hot 向量来表示类别特征。\n🚀 处理文本数据的流程 在自然语言处理的应用中，数据就是文本 document，文本可以分割成很多单词，我们需要把单词表示成数值向量。其中每个单词都是一个类别，如果字典里有一万个单词，那么就有一万的类别，显然单词就是类别特征。我们需要使用处理类别特征的方法，把单词变成数值向量。\n文本处理主要分为三个步骤：\n🔔 把文本分割成单词 🔔 计算每个单词出现的次数 🔔 进行 one-hot 编码 文本处理的第一步是把文本分割成单词。一段话，一篇文章或者一本书可以表示为一个字符串，可以把文本分割成很多单词，这个步骤称为 Tokenization。\n比如说这句话 ... to be or not to be ...， 可以分割成这些单词 [to, be, or, not, to, be]。Tokenization 就是把文本变成单词的列表。\n文本处理的第二步是计算词频，也就是每个单词出现的次数。我们可以用一个哈希表 hash Map 来计算，计算开始之前，哈希表是空的，我们根据以下方式更新哈希表：如果单词 w 不在表里面，说明到目前为止，w 还没有出现在文本里，所以我们要把 w 加入哈希表，并让它的词频等于 1；如果 w 在哈希表里面，说明 w 之前在文本里出现过，只需要把 w 的词频加 1 即可。\n接下来举个例子，我们将挨个处理这个列表里的单词。当处理到单词 to 的时候，首先查一下哈希表，发现哈希表里面有 to，它的词频是 398，说明 to 在文章里已经出现过 398 次了，现在这个单词又出现了一次，于是把表里的词频加 1，变成了 399；当处理到单词 or的时候，在表里找不到，这说明文章里还没有出现过 or 这个单词，第一次出现在文章里，于是我们把 or 插入表里，将词频设置为 1。\n完成统计词频之后，需要把哈希表做一个排序，按照词频递减的顺序进行排列，表的最前面是词频最高的，表最后是词频最低的。然后就把词频换成下标 index，从 1 开始数计数，词频最高的词的 index 是 1。这个例子里，一共有 8 个单词，每个词对应一个 [1, 8] 之间的正整数。这个表称为字典 ，可以把单词映射为一个数字。\n字典里单词的个数称为词汇量 vocabulary。这例子里词汇量等于 8。\n英语里大概有 1 万个常用词，但是统计词频之后，你会发现字典会有几十万甚至上百万个单词。统计词频的目的就是保留常用词，去掉低频词。比如，我们可以保留词频最高的 1 万个单词，删掉其余单词。\n为什么要删掉低频词呢？\n🌰 低频词通常没有意义 很多低频词都是名字实体 name entities，比如我们的名字就是个名字实体，假如我们的名字出现在一个数据集里面，他的频率肯定会很低，在大多数的应用里名字实体没有意义。\n低频词很多都是拼写错误造成的，如果把 prince 的 c 误写成 s，prinse，那么就创造了一个新的单词，这种词的频率也很低，在很多应用里，去掉这种词没有危害。\n🌰 去掉低频词的另一个原因是我们不希望 vocabulary 太大。 下一个步骤做 one-hot encoding 的时候，向量的维度就是字典的大小。字典越大，向量的维度就越高，这会让计算变慢。下一节详细说明词嵌入 Word Embedding 的时候就会看到，字典越大，模型的参数就越会越多，就会容易造成过拟合 overfitting，删掉低频词就会大幅减小 vocabulary。\n文本处理的第三步就是对单词做 one-hot encoding，通过查字典，把单词映射成一个正整数，一个单词的列表就映射成了一个正整数的列表；如果有必要就继续把这些正整数变成 one-hot 向量。这些 one-hot 向量的维度正好等于 vocabulary，在这个例子里面，字典的长度是 8，所以 one-hot 维度就等于 8。\n上面说过，字典里的低频词可能会被删掉，所以有些词在字典里找不到，例如把 be 错误拼写成单词 bi，这个词在字典里找不到，one-hot encoding 时，可以忽略这个词，也可以把它编码成全 0 向量。\n🎐 总结 最后总结一下这一节的内容。\n部分机器学习的数据会具备类别特征 Categorical Features，机器学习模型无法理解，我们需要将其转换成数值特征。类别特征的类别会被映射成一个从 1 开始计算的整数，0 被用来表示缺失或者未知的类别，并且使用 one-hot 向量，能很好的表示类别特征的意义。\n文本处理主要有三个步骤，第一步 tokenization 把文本分割成单词的列表；第二步建立了一个字典vocabulary，把单词映射成一个正整数；第三步进行 one-hot encoding，将分割后的单词列表映射成正整数的列表或变成 one-hot 向量。\n","date":"2022-03-01T02:02:02+08:00","image":"https://nlp.letout.cn/img/nlp/banner.png","permalink":"https://emerywan.github.io/blog/p/nlp-in-action/data-processing/","title":"数据处理基础"},{"content":"做自然语言处理写了挺久的 Python ，经常要处理数据。用 Python 中的处理数据真的挺爽的 🫣，我平常都喜欢把各种数据都往 dict（也就是 Java 中的 map） 和 json 上转，用 Python 处理这个各种方便。 最近再写 Java 就经常“手残”，所以总结一下 Java 中处理 Map。\n⭐️ 遍历方式 Java 遍历 Map，要么就是遍历它的 Map.Entry\u0026lt;K,V\u0026gt; \u0026lt;- entrySet()，要么就是遍历它的 key KeySet \u0026lt;- keySet()。主要可以用下面四种方式遍历：\nIterator\nForEach\nLambda\nStream\n除非特殊需要，尽量使用后 3 种遍历方式，使用 Iterator 可能更容易造成一些错误（Effective Java - 58：for-each 优先于 for 循环）。\n在一些 for-each 不能胜任的地方，其实也有很对内置方法能够完成操作，不仅更加直观，而且非常易用。比如删除操作：Collection#removeIf() Java 1.8+。\nInterator EntrySet 1 2 3 4 5 6 7 Iterator\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; iterator = map.entrySet().iterator(); while(iterator.hasNext()) { Map.Entry\u0026lt;String, String\u0026gt; entry = iterator.next(); String key = entry.getKey(); String value = entry.getValue(); } 根据 Effective Java - 57，更推荐以下这种写法：\n1 2 3 4 5 for (Iterator\u0026lt;Map.Entry\u0026lt;String, String\u0026gt;\u0026gt; iterator = map.entrySet().iterator(); iterator.hasNext(); ) { Map.Entry\u0026lt;String, String\u0026gt; entry = iterator.next(); String key = entry.getKey(); String value = entry.getValue(); } KeySet 1 2 3 4 for (Iteator\u0026lt;String\u0026gt; iterator = map.keySet().iterator(); iterator.hasNext(); ) { String key = iterator.next(); String value = map.get(key); } ForEach EntrySet 1 2 3 4 for (Map.Entry\u0026lt;String, String\u0026gt; entry : map.entrySet()) { String key = entry.getKey(); String value = entry.getValue(); } KeySet 1 2 3 for (String key : map.keySet()) { String value = map.get(key); } Lambda 1 2 3 4 map.forEach((key, value) -\u0026gt; { // key // value }) 1 2 3 4 5 public class HashMap\u0026lt;K,V\u0026gt; extends AbstractMap\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt;, Cloneable, Serializable { @Override public void forEach(Biconsumer\u0026lt;? super K, ? super V\u0026gt; action) { } } Stream Steram 1 2 3 4 map.entrySet().stream().forEach((entry) -\u0026gt; { String key = entry.getKey(); String value = entry.getValue(); }) parallelStream 1 2 3 4 map.entrySet().parallelStream().forEach((entry) -\u0026gt; { String key = entry.getKey(); String value = entry.getValue(); }) 🌟 一些操作 判空 1 2 3 4 5 🙋‍♂️ map.isEmpty(); 🙅‍♂️ boolean b = map.size() == 0; 计数 / merge() 1 2 public V merge(K key, V value, BiFunction\u0026lt;? super V, ? super V, ? extends V\u0026gt; remappingFunction) { } 1 map.merge(key, 1, Integer::sum); removeIf() 🚧 注意：\nMap 本身是没有 removeIf()。\n1 2 3 map.entrySet().removeIf(entry -\u0026gt; {}); map.keySet().removeIf(key -\u0026gt; {}); map.values().removeIf(value -\u0026gt; {}); absent 1 public V putIfAbsent(K key, V value); 1 2 3 4 5 6 7 // 不存在 key 时，按 mappingFunction 添加 value // 存在 key 不改变 public V computeIfAbsent(K key, Function\u0026lt;? super K, ? extends V\u0026gt; mappingFunction) { } public V computeIfPresent(K key, BiFunction\u0026lt;? super K, ? super V, ? extends V\u0026gt; remappingFunction) { } default 1 map.getOrDefault(key, 0); 🔗 参考 https://mp.weixin.qq.com/s/zQBN3UvJDhRTKP6SzcZFKw ","date":"2022-01-28T21:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/java-map-traversal/","title":"Java Map 操作"},{"content":"PyTorch 是什么？ 基于 Python 的科学计算包，服务于以下两种场景：\nNumpy 的替代品，可以使用 GPU 的强大计算力 提供最大的灵活性和高速的深度学习研究平台 Tensors Tensors 与 Numpy 中的 ndarrays 类似，但是在 PyTorch 中 Tensors 可以使用 GPU 进行计算。\n1 2 from __future__ import print_function import torch [ 1 ] 创建一个 5x3 的矩阵，但不初始化：\n1 2 3 4 5 6 7 x = torch.empty(5, 3) print(x) # tensor([[0.0000, 0.0000, 0.0000], # [0.0000, 0.0000, 0.0000], # [0.0000, 0.0000, 0.0000], # [0.0000, 0.0000, 0.0000], # [0.0000, 0.0000, 0.0000]]) [ 2 ] 创建一个随机初始化的矩：\n1 2 3 4 5 6 7 x = torch.rand(5, 3) print(x) # tensor([[0.6972, 0.0231, 0.3087], # [0.2083, 0.6141, 0.6896], # [0.7228, 0.9715, 0.5304], # [0.7727, 0.1621, 0.9777], # [0.6526, 0.6170, 0.2605]]) [ 3 ] 创建一个 0 填充的矩阵，数据类型为 long：\n1 2 3 4 5 6 7 x = torch.zero(5, 3, dtype=torch.long) print(x) # tensor([[0, 0, 0], # [0, 0, 0], # [0, 0, 0], # [0, 0, 0], # [0, 0, 0]]) [ 4 ] 创建一个 tensor 使用现有数据初始化：\n1 2 3 4 5 x = torch.tensor( [5.5, 3] ) print(x) # tensor([5.5000, 3.0000]) [ 5 ] 根据现有的 tensor 创建 tensor。这些方法将重用输入 tensor 的属性（如：dtype，除非设置新的值进行覆盖）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 利用 new_* 方法创建对象 x = x.new_ones(5, 3, dtype=torch.double) print(x) # tensor([[1., 1., 1.], # [1., 1., 1.], # [1., 1., 1.], # [1., 1., 1.], # [1., 1., 1.]], dtype=torch.float64) # 覆盖 dtype # 对象 size 相同，只是 值和类型 发生变化 print(x) # tensor([[ 0.5691, -2.0126, -0.4064], # [-0.0863, 0.4692, -1.1209], # [-1.1177, -0.5764, -0.5363], # [-0.4390, 0.6688, 0.0889], # [ 1.3334, -1.1600, 1.8457]]) [ 6 ] 获取 size：\n1 2 print(x.size()) # torch.Size([5, 3]) Tip:\ntorch.Size 返回 tuple 类型，支持 tuple 类型所有的操作。\n[ 7 ] 操作\n[ 7.1 ] 加法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 y = torch.rand(5, 3) print(x+y) # tensor([[ 0.7808, -1.4388, 0.3151], # [-0.0076, 1.0716, -0.8465], # [-0.8175, 0.3625, -0.2005], # [ 0.2435, 0.8512, 0.7142], # [ 1.4737, -0.8545, 2.4833]]) print(torch.add(x, y)) # tensor([[ 0.7808, -1.4388, 0.3151], # [-0.0076, 1.0716, -0.8465], # [-0.8175, 0.3625, -0.2005], # [ 0.2435, 0.8512, 0.7142], # [ 1.4737, -0.8545, 2.4833]]) 提供输出 tensor 作为参数：\n1 2 3 4 5 6 7 8 result = torch.empty(5, 3) torch.add(x, y, out=result) print(result) # tensor([[ 0.7808, -1.4388, 0.3151], # [-0.0076, 1.0716, -0.8465], # [-0.8175, 0.3625, -0.2005], # [ 0.2435, 0.8512, 0.7142], # [ 1.4737, -0.8545, 2.4833]]) [ 7.2 ] 替换：\n1 2 3 4 5 6 7 8 # add x to y y.add_(x) print(y) # tensor([[ 0.7808, -1.4388, 0.3151], # [-0.0076, 1.0716, -0.8465], # [-0.8175, 0.3625, -0.2005], # [ 0.2435, 0.8512, 0.7142], # [ 1.4737, -0.8545, 2.4833]]) {% note info %} _ 结尾的操作会替换原变量。 如：x_copy_(y)，x.t_() 会改变 x {% endnote %}\n[ 7.3 ] 使用 Numpy 中索引方式，对 tensor 进行操作：\n1 2 print(x[:, 1]) # tensor([-2.0126, 0.4692, -0.5764, 0.6688, -1.1600]) [ 8 ] torch.view 改变 tensor 的维度和大小 （与 Numpy 中 reshape 类似）：\n1 2 3 4 5 6 x = torch.randn(4, 4) y = x.view(16) z = x.view(-1, 8) # -1 从其他维度推断 print(x.size(), y.size(), z.size()) # torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) [ 9 ] 如果只有一个元素的 tensor，使用 item() 获取 Python 数据类型的数值：\n1 2 3 4 5 x = torch.randn(1) print(x) print(x.item()) # tensor([-0.2368]) # -0.23680149018764496 Numpy 转换 Torch Tensor 与 Numpy 数组之间进行转换非常轻松。\n1 2 3 4 5 a = torch.ones(5) b = a.numpy() print(a) # tensor([1., 1., 1., 1., 1.]) print(b) # [1. 1. 1. 1. 1.] Torch Tensor 与 Numpy 数组共享底层内存地址，修改一个会导致另一个的变化。\n1 2 3 4 a.add_(1) print(a) # tensor([2., 2., 2., 2., 2.]) print(b) # [2. 2. 2. 2. 2.] 1 2 3 4 5 6 7 import numpy as np a = np.ones(5) b = torch.from_numpy(a) np.add(a, 1, out=a) print(a) # [2. 2. 2. 2. 2.] print(b) # tensor([2., 2., 2., 2., 2.], dtype=torch.float64) Tip:\n所有的 Tensor 类型默认都是基于 CPU， CharTensor 类型不支持到 Numpy 的装换。\nCUDA 张量 使用 .to() 可以将 Tensor 移动到任何设备中。\n1 2 3 4 5 6 7 if torch.cuda.is_available(): device = torch.device(\u0026#39;cuda\u0026#39;) # CUDA 设备对象 y = torch.ones_like(x, device=device) # 直接从 GPU 创建张量 x = x.to(device) z = x + y print(z) # tensor([0.7632], device=\u0026#39;cuda:0\u0026#39;) print(z.to(\u0026#39;cpu\u0026#39;, torch.double)) # tensor([0.7632], dtype=torch.float64) Autograd 自动求导 autograd 包为 Tensor 上所有的操作提供了自动求导。它是一个运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。\n正向传播 反向传播 神经网络（NN）是在某些输入数据上执行嵌套函数的集合。 这些函数由参数（权重和偏差组成）定义，参数在 PyTorch 中存储在张量中。\n训练 NN 分为两个步骤：\n正向传播：在正向传播中，NN 对正确的输出进行最佳猜测。它通过每个函数运行输入数据以进行猜测。 反向传播：在反向传播中，NN 根据其猜测中的误差调整其参数。它通过从输出向后遍历，收集有关参数（梯度）的误差导数并使用梯度下降来优化参数来实现。 [ 1 ] 我们从 torchvision 加载了经过预训练的 resnet18 模型。创建一个随机数据张量来表示具有 3 个通道的单个图像，高度和宽度为 64，其对应的label初始化为一些随机值。\n1 2 3 4 5 import torch, torchvision model = torchvision.models.resnet18(pretrained=True) data = torch.rand(1, 3, 64, 64) labels = torch.rand(1, 1000) [ 2 ] 接下来，通过模型的每一层运行输入数据进行预测。正向传播。\n1 prediction = model(data) [ 3 ] 使用模型的预测（predication）和相应的标签（labels）来计算误差（loss）。 下一步通过反向传播此误差。我们在 loss tensor 上调用 .backward() 时，开始反向传播。Autograd 会为每个模型参数计算梯度并将其存储在参数 .grad 属性中。\n1 2 loss = (prediction - labels).sum() loss.backword() # backword pass [ 4 ] 接下来，我们加载一个优化器（SDG），学习率为 0.01，动量为 0.9。在 optim 中注册模型的所有参数。\n1 optim = torch.optim.SDG(model.parameters(), lr=1e-2, momentum=0.9) [ 5 ] 最后，调用 .step() 启动梯度下降。优化器通过 .grad 中存储的梯度来调整每个参数。\n1 optim.step() # gradient descent 神经网络的微分 这一小节，我们将看看 autograd 如何收集梯度。 我们在创建 Tensor 时，使用 requires_grad=True 参数，表示将跟踪 Tensor 的所有操作。\n1 2 3 4 5 6 7 import torch a = torch.tensor([2., 3.], require_grad=True) b = torch.tensor([6., 4.], require_grad=True) # 从 tensor a, b 创建另一个 tensor Q Q = 3*a**3 - b**2 假设 tensor a，b 是神经网络的参数，tensor Q 是误差。在 NN 训练中，我们想要获得相对于参数的误差，即各自对应的偏导：\n$$\\frac{\\partial Q}{\\partial a}=9a^2$$\n当我们在 tensor Q 上调用 .backward() 时，Autograd 将计算这些梯度并将其存储在各个张量的 .grad 属性中。\n我们需要在 Q.backword() 中显式传递 gradient 参数（与 Q 形状相同的张量，表示 Q 相对本身的梯度）。\n$$\\frac{\\partial Q}{\\partial b}=-2b$$\n1 2 3 4 5 6 7 8 external_grad = torch.tensor([1., 1.]) Q.backward(gradient=external_grad) # 最后，梯度记录在 a.grad b.grad 中，查看收集的梯度是否正确 print(9*a**2 == a.grad) # tensor([True, True]) print(-2*b == b.grad) # tensor([True, True]) 我们也可以将 Q 聚合为一个标量，然后隐式地向后调用，如：Q.sum().backward()。\n神经网络 上一节，我们了解到 nn 包依赖 autograd 包来定义模型并求导。下面，我们将了解如何定义一个网络。一个 nn.Module 包含个 layer 和一个 forward(input) 方法，该方法返回 output。\n如下，这是一个对手写数字图像进行分类的卷积神经网络：\n神经网络的典型训练过程如下：\n定义包含一些可学习的参数（权重）神经网络模型 在数据集上迭代 通过神经网络处理输入 计算损失（输出结果和正确值的差值大小） 将梯度反向传播回网络的参数 更新网络的参数（梯度下降）：weight = weight - learning_rate * gradient 定义网络 在模型中必须定义 forward()， backword（用来计算梯度）会被 autograd 自动创建。可在 forward() 中使用任何针对 Tensor 的操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Model): def __init__(self): super(Net, self).__init__() # 1 input image channel, 6 output channels, 3x3 square convolution # kernel self.conv_1 = nn.Conv2d(1, 6, 3) self.conv_2 = nn.Conv2d(6, 16, 3) # an affine operation: y = Wx + b self.fc1 = nn.Linear(16 * 6 *6, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # Max Pooling over a (2, 2) window x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # If the size is a square you can only specify a single number x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(sefl, x): size = x.size()[1: ] # all dimensions except the batch dimension num_features = 1 for s in size: num_features *= s return num_features net = Net() print(net) # Net( # (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) # (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) # (fc1): Linear(in_features=576, out_features=120, bias=True) # (fc2): Linear(in_features=120, out_features=84, bias=True) # (fc3): Linear(in_features=84, out_features=10, bias=True) # ) parameters() 返回可被学习的参数（权重）列表和值\n1 2 3 4 params = list(net.parameters()) print(len(params)) # 10 print(params[0].size()) # conv1 的 weight torch.Size([6, 1, 3, 3]) 测试随机输入 32x32。注：这个网络（LeNet）的期望的输入大小是 32x32，如果使用 MINIST 数据集来训练这个网络，请把图片大小重新调整到 32x32。\n1 2 3 4 5 input = torch.randn(1, 1, 32, 32) out = net(input) print(out) # tensor([[ 0.1120, 0.0713, 0.1014, -0.0696, -0.1210, 0.0084, -0.0206, 0.1366, # -0.0455, -0.0036]], grad_fn=\u0026lt;AddmmBackward\u0026gt;) 将所有的参数的梯度缓存清零，进行随机梯度的反向传播。\n1 2 net.zero_grad() out.backward(torch.randn(1, 10)) Tip:\ntorch.nn 仅支持小批量输入。整个 torch.nn 包都只支持小批量样本，而不支持单个样本。 如：nn.Conv2d接受一个4维 Tensor，分别维 sSamples * nChannels * Height * Width （样本数* 通道数 * 高 * 宽）。如果你有单个样本，只需要使用 input.unsqueeze(0) 来添加其他的维数。\n至此，我们大致了解了如何构建一个网络，回顾一下到目前为止使用到的类。\ntorch.Tensor： 一个多维数组。 支持使用 backward() 进行自动梯度计算，并保存关于这个向量的梯度 w.r.t.\nnn.Model： 神经网络模块。实现封装参数、移动到 GPU 上运行、导出、加载等。\nnn.Parameter： 一种张量。将其分配为 Model 的属性时，自动注册为参数。\nautograd.Function： 实现一个自动求导操作的前向和反向定义。每个 Tensor 操作都会创建至少一个 Function 节点，该节点连接到创建 Tensor 的函数，并编码其历史记录。\n损失函数 1 2 3 4 5 6 7 8 9 output = net(input) target = torch.randn(10) # 例子：一个假设的结果 target = target.view(1, -1) # 让 target 与 output 的形状相同 criterion = nn.MSELoss() loss = criterion(output, target) print(loss) 反向传播 要实现反向传播误差，只需要 loss.backward()。 但是，需要清除现有的梯度，否则梯度将累积到现有的梯度中。\n1 2 3 4 5 6 7 net.zero_grad() # 将所有的梯度缓冲归零 print(net.conv1.bias.grad) # conv1.bias.grad 反向传播前 tensor([0., 0., 0., 0., 0., 0.]) loss.backward() print(net.conv1.bias.grad) # 反向传播后 tensor([0.0111, -0.0064, 0.0053, -0.0047, 0.0026, -0.0153]) 更新权重 在使用 PyTorch 时，可以使用 torch.optim 中提供的方法进行梯度下降。如：SDG，Nesterov-SDG，Adam，RMSprop 等。\n1 2 3 4 5 6 7 8 9 10 11 import torch.optim as optim # 创建一个 optimizer optimizer = optim.SDG(net.parameters(), lr=0.01) # 在训练中循环 optimizer.zero_grad() # 将梯度缓冲区清零 output = net(input) loss = criterion(output, target) loass.backword() optimizer.step() # 更新 训练分类器 数据从哪里来？ 通常，需要处理图像、文本、音频或视频数据时，可以使用将数据加载到 NumPy 数组中的标准 Python 包，再将该数值转换为 torch.*Tensor。\n处理图像，可以使用 Pillow，OpenCV 处理音频，可以使用 SciPy，librosa 处理文本，可基于 Python 或 Cython 的原始加载，或 NLTK 和 SpaCy 对于图像任务，其中包含了一个 torchvision 的包，含有常见的数据集（Imagenet，CIFAR10，MNIST等）的数据加载器，以及用于图像的数据转换器（torchvision.datasets 和 torch.utils.data.DataLoader）。\n在本示例中，将使用 CIFAR10 数据集。其中包含 10 分类的图像：“飞机”，“汽车”，“鸟”，“猫”，“鹿”，“狗”，“青蛙”，“马”，“船”，“卡车”。图像的尺寸为 3 * 32 * 32，即尺寸为 32 * 32 像素的 3 通道彩色图像。\n接下来，作为演示，将按顺序执行以下步骤训练图像分类器：\n使用 torchvision 加载并标准化 CIFAR10 训练和测试数据集 定义 CNN 定义损失函数 根据训练数据训练网络 在测试数据上测试网络 加载并标准化 CIFAR10 1 2 3 import torch import torchvision import torchvision.transforms as transforms torchvision 的输出是 [0, 1] 的 PILImage 图像，我们要把它转换为归一化范围为 [-1, 1] 的张量。\n1 2 3 4 5 6 7 8 9 10 11 transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))] ) trainset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = trochvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, barch_size=4, shuffle=False, num_workers=2) classes = (\u0026#39;plane\u0026#39;, \u0026#39;car\u0026#39;, \u0026#39;bird\u0026#39;, \u0026#39;cat\u0026#39;, \u0026#39;deer\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;frog\u0026#39;, \u0026#39;horse\u0026#39;, \u0026#39;ship\u0026#39;, \u0026#39;truck\u0026#39;) 定义 CNN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # in_channels, out_channels, kernel_size # 输入的为 3 通道图像，提取 6 个特征，得到 6 个 feature map，卷积核为一个 5*5 的矩阵 self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) # 卷积层输出了 16 个 feature map，每个 feature map 是 6*6 的二维数据 self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net(s) 定义损失函数和优化器 这里我们使用交叉熵作为损失函数，使用带动量的随机梯度下降。\n1 2 3 4 import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SDG(net.parameters(), lr=0.001, momentum=0.9) 训练网络 接下来，只需要在迭代数据，将数据输入网络中并优化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 for epoch in range(2): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data # 获取输入 optimizer.zero_grad() # 将梯度缓冲区清零 outputs = net(inputs) # 正向传播 loss = criterion(outputs, lables) loss.backward() # 反向传播 optimizer.step() # 优化 running_loss += loss.item() if i % 2000 == 1999: # 每 2000 批次打印一次 print(\u0026#39;[]\u0026#39; % (epoch+1, i+1, running_loss / 2000)) running_loss = 0.0 在测试集上测试数据 在上面的训练中，我们训练了 2 次，接下来，我们要检测网络是否从数据集中学习到了有用的东西。通过预测神经网络输出的类别标签与实际情况标签对比进行检测。\n1 2 3 4 5 6 7 8 9 10 11 12 corrent = 0 total = 0 with torch.no_grad(): for data in testloader: images, lobels = data outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) corrent += (predicted == labels).sum().item() print(\u0026#39;Accuracy of the network on the 10000 test images: %d %%\u0026#39; % (100 *corrent / total)) # Accuracy of the network on the 10000 test images: 9% 在训练两次的网络中，随机选择的正确率为 10%。网络似乎学到了一些东西。\n那这个网络，识别哪一类好，哪一类不好呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class_corrent = list(0. for i in range(10)) class_total = list(0. for i in range(10)) with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1 for i in range(10): print(\u0026#39;Accuracy of %5s : %2d %%\u0026#39; % (classes[i], 100 * class_correct[i] / class_total[i])) # Accuracy of plane : 99 % # Accuracy of car : 0 % # Accuracy of bird : 0 % # Accuracy of cat : 0 % # Accuracy of deer : 0 % # Accuracy of dog : 0 % # Accuracy of frog : 0 % # Accuracy of horse : 0 % # Accuracy of ship : 0 % # Accuracy of truck : 0 % 使用 GPU 与将 tensor 移到 GPU 上一样，神经网络也可以移动到 GPU 上。 如果可以使用 CUDA，将设备定义为第一个 cuda 设备：\n1 2 3 4 device = torch.device(\u0026#39;cuda:0\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39;) print(device) # cuda:0 复制 nn 和 tensor 到 GPU 上。\n1 2 3 model = net.to(device) inputs, labels = data[0].to(device), data[1].to(device) Tip:\n使用 .to(device) 并没有复制 nn / tensor 到 GPU 上，而是返回了一个 copy。需要赋值到一个新的变量后在 GPU 上使用这个 nn / tensor。\n参考 https://pytorch.apachecn.org/#/docs/1.7/02 ","date":"2021-05-01T21:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/pytorch-handbook/","title":"PyTorch 火速上手"},{"content":"机器学习 基本术语 如图所示表格，是鸢尾花（lris）相关信息的数据，其中：\n数据整体称为数据集（data set） 每一行数据称为一个样本（sample） 每一列（除表格最后一列）表达样本的一个特征（feature） 最后一列，成为标记（label） 如图所示信息，其中 萼片长度、宽度，花瓣的长度、宽度称为 特征；每一行特征的值称为特征向量（数学上通常会将其表示为列向量）。\n若将该图中的数据表示为矩阵的方式，结果如图：\n选择两种鸢尾花的特征为例，将其表示为如图的二维空间（多维特征将其表示为多维空间）。\n我们将这样的空间称为 特征空间（feature space）。\n分类任务本质就是在特征空间切分，如图所示，在特征空间中，将鸢尾花根据两种特征分为了两类。\n机器学习的基本任务 机器学习的基本任务基本有两类，分别为：\n分类 回归 分类任务 一些算法只支持完成二分类的任务 多分类的任务可以转换成二分类的任务 一些算法天然的支持多分类问题 二分类 二分类问题的常见实例：\n判断邮件是垃圾邮件；不是垃圾邮件 判断发放给客户信用卡有风险；无风险 判断病患良性肿瘤；恶性肿瘤 判断某支股票涨；跌 多分类 多分类问题的常见实例：\n数字识别 图像识别 判断发放给客户信用卡的风险评级 围棋游戏等 自动驾驶识别 多标签分类 如图所示，为多标签分类问题的常见实例：\n回归任务 回归问题的结果与分类问题的结果不同，回归问题的结果是一个连续数字的值，而非一个类别。\n常见的回归问题有：\n房屋价格 市场分析 学术成绩 股票价格 在一些情况下，回归任务可以简化成分类任务。\n机器学习算法分类 监督学习 监督学习 supervised learning 主要处理的是分类问题和回归问题。\n监督学习的含义是给机器的训练数据中拥有“标记”或者“答案”。根据这些数据进行模型的训练。\n如根据图片判断猫狗（图像已经拥有了标定信息） 如更具手写字体识别数字（给出结果标记） 银行已经积累了一定的客户信息和他们信用卡的信用情况\n医院已经积累了一定的病人信息和他们最终确诊是否患病的情况。\n常见的监督学习算法有：\nk近邻 线性回归和多项式回归 逻辑回归 SVM 决策树和随机森林 非监督学习 非监督学习 unsupervised learning 给机器的训练数据没有任何“标记”或者“答案”。\n对没有“标记”的数据进行分类 \u0026ndash; 聚类分析。\n意义 对数据进行降维处理 特征提取：行用卡的信用评级和人的胖瘦无关？ 特征压缩：PCA 降维处理的意义：方便可视化\n我们无法理解四维以上空间，所以可以将其降维到三维或者二维空间，方便理解。\n异常检测 半监督学习 semi-supervised learning\n一部分数据有“标记”或者答案，另一部分数据没有\n常见的场景：各种原因产生的标记缺失。\n我们通常都先使用无监督学习手段对数据做处理，之后使用监督学习手段做模型的训练和预测。\n增强学习 根据周围环境的情况，采取行动，根据采取行动的结果，学习行动方式。\n无人驾驶 机器人 在增强学习中，监督学习和半监督学习是基础。\n机器学习的其他分类 在线学习和批量学习 在线学习 Online Learning\n优点：及时反映新的环境变化\n问题：新的数据可能带来不好的变化，错误的数据可能带来错误的结果\n解决方案：需要加强对数据的监控 也适用于数据量巨大，完全无法批量学习的环境\n批量学习（离线学习） Batch Learning / Offline Learning\n优点：简单\n问题：要考虑如如何适应环境变化\n解决方案：定时重新批量学习 缺点：每次重新批量学习，运行量巨大。在某些环境变化非常快的情况下，甚至是不可能的。\n参数学习和非参数学习 参数学习 Parametric Learning\n如图所示，为房屋面积与价格的关系曲线。\n特点：一旦学习到了参数，就不需要原有的数据集。\n非参数学习 Nonparametric Learning\n不对模型进行过多假设\n非参数不等于没有参数，而是对整个不进行建模，不学习一些参数\n","date":"2020-09-28T14:02:02+08:00","permalink":"https://emerywan.github.io/blog/p/mechine-learning-basics/","title":"机器学习基础"},{"content":"Spring Cloud Hystrix 在微服务架构中，我们将系统拆分成了一个个的服务单元，各单元应用间通过服务注册与订阅的方式互相依赖。由于每个单元都在不同的进程中运行，如果某个服务不可用，可能导致级联故障，造成整个系统不可用的情况（雪崩效应）。为了解决这样的问题，产生了断路器等一系列的服务保护机制。\n简介 Spring Cloud Hystrix，它是一个基于 Netflix 的开源框架，具有如下功能：\n服务降级 依赖隔离 服务熔断 监控（Hystrix Dashboard） 实现一个 Hystrix Server 添加依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-hystrix\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加注解 1 2 3 4 5 6 7 8 @EnableCircuitBreaker @EnableDiscoveryClient @SpringBootApplication public class HystrixApplication { public static void main(String[] args) { SpringApplication.run(HystrixApplication.class, args); } } 配置文件 1 2 3 4 5 6 7 8 9 10 11 spring: application: name: hystrix-server server: port: 8080 eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ Hystrix 应用 服务降级 假设现在有一个接口 /user/{id} 获取用户信息。\n1 2 3 public ResultVo\u0026lt;UserInfo\u0026gt; getUserInfo(@PathVariable String id) { return userService.getUserInfo(id); } 在 UserService 中添加调用方法的服务降级。\n1 2 3 4 5 6 7 8 9 10 11 12 @HystrixCommand(fallbackMethod = \u0026#34;userFallback\u0026#34;) public ResultVo\u0026lt;UserInfo\u0026gt; getUserInfo(String id) { // 正常的服务调用和业务 此处以 restTemplate 为例 // ... return restTemplate.getForObject(url + \u0026#34;/user/{1}\u0026#34;, ResultVo.class, id); } public ResultVo\u0026lt;UserInfo\u0026gt; userFallback() { // ... // 处理服务降级需要返回的内容 } 服务降级 OpenFiegn 配置文件 1 2 3 feign: hystrix: enabled: true OpenFeign Client 端实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @FeignClient( name = \u0026#34;user\u0026#34;, // 远程服务名 fallback = UserClientFallback.class // 指定 当服务降级时，采用的方法 ) public interface UserClient { @GetMapping(\u0026#34;/user/{id}\u0026#34;) ResultVo\u0026lt;UserInfo\u0026gt; getUserInfo(@PathVariable String id); } --- // 实现 UserClient 接口 @Component public class UserClientFallback implements UserClient { @Override ResultVo\u0026lt;UserInfo\u0026gt; getUserInfo(@PathVariable String id) { // ... // 实现降级内容 } } 依赖隔离 SpringCloud Hystrix 的 依赖隔离 类似于docker的“舱壁模式”。 docker通过”舱壁模式”实现进程隔离，使得容器之间互不影响。 而Hystrix使用该模式实现：“线程池隔离”，会为每一个HystrixCommand创建一个独立线程池，这样就算某个在Hystrix包装下的依赖服务出现延迟过高情况，也只是对该依赖服务的调用产生影响，并不会拖慢其他服务。\n使用 @HystrixCommand 来将某个函数包装成了 Hystrix 命令时，Hystrix框架自动地为这个函数实现了依赖隔离。所以依赖隔离，服务降级在使用时候都是一体化实现的，这样就可以实现服务容错保护。在编程模型上就会非常方便。\n服务熔断 ","date":"2020-07-29T21:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/spring-cloud-hystrix/","title":"Spring Cloud Hystrix 服务容错"},{"content":"Spring Cloud Zuul 在微服务架构中，后端服务往往不直接开放给调用端，而是通过一个API网关根据请求的url，路由到相应的服务。 当添加API网关后，在第三方调用端和服务提供方之间就创建了一面墙，这面墙直接与调用方通信进行权限控制，后将请求均衡分发给后台服务端。 Spring Cloud Zuul 是一个基于JVM路由和服务端的负载均衡器，提供动态路由，监控，弹性，安全等的边缘服务。\n简介 Zuul 的主要功能是路由转发和过滤器（Filter）。不同类型的 Filter 用于处理请求，可以实现以下功能：\n权限控制和安全性：可以识别认证需要的信息和拒绝不满足条件的请求 监控：监控请求信息 动态路由：根据需要动态地路由请求到后台的不同服务集群 压力测试：逐渐增大到集群的流量，以便进行性能评估 负载均衡：为每种类型的请求分配容量并丢弃超过限额的请求 限流 黑白名单过滤 静态资源处理：直接在zuul处理静态资源的响应而不需要转发这些请求到内部集群中 基础使用 创建一个 api-gateway 添加依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-zuul\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加注解 1 2 3 4 5 6 7 8 @EnableZuulProxy @EnableDiscoveryClient @SpringBootApplication public class ApiGatewayApplication { public static void main(String[] args) { SpringApplication.run(ApiGatewayApplication.class, args); } } 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 spring: application: name: api-gateway server: port: 9000 # 自定义路由规则 zuul: routes: user: path: /user/** serviceId: user 测试 通过以上配置文件配置，即可通过 api-gateway 服务去请求 user 服务。\n假设 user 服务的端口为 8080，其中包含一个 api 为 /info。 通过访问 http://localhost:9000/user/info，即可访问该 api。（若原接口包含路由前缀 /user，需要使用 /user/user/info 访问）\n常用功能 统一前缀 1 2 zuul: prefix: /proxy Header 过滤及重定向添加 Host 1 2 3 4 5 6 7 8 9 zuul: # 默认为该配置，会过滤 Cookie Set-Cookie Authorization 信息 # 设置为空即不会过滤 sensitive-headers: Cookie,Set-Cookie,Authorization --- zuul: add-host-header: true # 重定向会添加 host 请求头 查看路由信息 添加依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件 1 2 3 4 5 6 7 8 server: port: 9000 management: endpoints: web: exposure: include: \u0026#39;routes\u0026#39; 访问接口 访问 http://localhost:9000/actuator/routes 获取信息 访问 http://localhost:9000/actuator/routes/details 获取详细信息 Zuul 应用 Zuul Filter Filter是Zuul的核心，用来实现对外服务的控制。Filter有4个生命周期。\npre 在请求被路由到目标服务前执行。 比如权限校验、打印日志等功能。 routing 在请求被路由到目标服务时执行。 用于构建发送给微服务的请求，并使用 Apache HttpClient 或 Netfilx Ribbon 请求微服务。 post 这种过滤器在路由到微服务以后执行。 为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 error 其他阶段发生错误时执行该过滤器。 自定义 Filter 实现自定义 Filter，需继承 com.netflix.zuul.ZuulFilter，并覆盖继承的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Component public class MyFilter extends ZuulFilter { @Override String filterType() { // 定义filter的类型，pre、route、post、error return null; } @Override int filterOrder() { // 定义filter的顺序，数字越小表示顺序越高，越先执行 return 0; } @Override boolean shouldFilter() { // 是否需要执行该filter，true表示执行，false表示不执行 return false; } @Override Object run() { // filter需要执行的具体操作 return null; } } Zuul 限流 限流在前置过滤器（pre）前使用，在请求被转发前调用，且优先级最高。\n令牌桶限流示例。令牌桶算法能够在限制数据的平均传输速率的同时还允许某种程度的突发传输。\n令牌桶算法会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import org.springframework.cloud.netflix.zuul.filters.support.FilterConstants; @Component public class RateLimiterFilter extends ZuulFilter { // 直接使用 guava 中的 RateLimiter 实现 private static final RateLimiter RATE_LIMITER = RateLimiter.create(100); @Override public String filterType() { return FilterConstants.PRE_TYPE; } @Override public int filterOrder() { // 限流是最高优先级，所以比最高优先级 -3 还要小 return FilterConstants.SERVLET_DETECTION_FILTER_ORDER - 1; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { // 如果没有拿到令牌 if (!RATE_LIMITER.tryAcquire()) { throw new RuntimeException(); } return null; } } Zuul 鉴权 在请求服务前，判断是否有权限访问。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @Component public class TokenFilter extends ZuulFilter { @Override public String filterType() { return FilterConstants.PRE_TYPE; } @Override public int filterOrder() { // 越小越靠前，放在 PRE_DECORATION_FILTER_ORDER 之前 return PRE_DECORATION_FILTER_ORDER - 1; } @Override public boolean shouldFilter() { return true; } // 需要定义的逻辑 @Override public Object run() throws ZuulException { RequestContext requestContext = RequestContext.getCurrentContext(); HttpServletRequest request = requestContext.getRequest(); // 需要根据实际情况，从 header / cookie 中获取信息 String token = ...; // 根据实际情况进行校验 if (...) { // 首先设置 zuul requestContext.setSendZuulResponse(false); // 设置返回信息 requestContext.setResponseStatusCode(HttpStatus.UNAUTHORIZED.value()); } return null; } } Zuul 跨域 在浏览器中的 ajax 请求是有同源策略的，如果违反了同源策略，就会有跨域问题。在 Zuul 中添加 CorsFilter 过滤器，是跨域问题的一种解决方案。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Configuration public class CorsConfig { @Bean public CorsFilter corsFilter() { final UrlBaseCorsConfigurationSource source = new UrlBaseCorsConfigrationSOurce(); final CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); config.setAllowedOrigins(Collections.singletonList(\u0026#34;*\u0026#34;)); config.setAllowedHeaders(Collections.singletonList(\u0026#34;*\u0026#34;))； config.setAllowedMethods(Collections.singletonList(\u0026#34;*\u0026#34;)); config.setMaxAge(300L); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); return new CorsFilter(source); } } ","date":"2020-07-28T15:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/spring-cloud-zuul/","title":"Spring Cloud Zuul 服务网关"},{"content":"Spring Cloud Config Spring Cloud Config 是一个解决分布式系统的配置管理方案。\nServer 提供配置文件的存储，以接口的形式提供配置文件的内容 Client 通过接口获取数据，并依据此数据初始化应用 Config Server 新建一个 git 仓库 在 git 服务器上创建一个仓库，用来存放配置文件。\n并在仓库中添加相应的配置文件。\nuser-dev.yml user-test.yml user-prod.yml 具体实现 添加依赖 1 2 3 4 5 6 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-config-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 添加注解 1 2 3 4 5 6 7 8 @EnableConfigServer @EnableDiscoveryClient @SpringBootApplication public class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class, args); } } 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 spring: application: name: config cloud: config: server: git: uri: http://github.com/xxx/confg # 配置文件仓库地址 username: ... password: ... searchpath: config-repo # git仓库地址下的相对地址，可配置多个 server: port: 8000 eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 通过接口查看配置 仓库中的配置文件会被转换成web接口，启动应用后，可在浏览器中查看配置文件（若配置文件的格式有错误，将无法访问）。\n如访问 http://localhost:8000/user/dev 即可返回 user-dev.yml 的配置信息。\n/{application}/{profile}[/{label}] /{application}-{profile}.yml /{label}/{application}-{profile}.yml profile：配置环境，label：仓库分支。\nConfig Client 在项目中创建 bootstrap.yml 在项目中，bootstrap.yml 会优先于 application.yml 加载。\napplication.yml 应用场景 主要用于 Spring Boot 项目的自动化配置。\nbootstrap.yml 应用场景 从额外的资源加载配置信息（如使用 Spring Cloud Config 时） 一些固定不能被覆盖的属性（具有高优先级，一般不会被本地配置或application中同名配置覆盖） 一些 加密/解密 的场景 具体实现 添加依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 spring: application: name: user # 该应用获取之前配置好的 user-dev.yml cloud: config: url: http://localhost:8000/ profile: dev label: master --- spring: cloud: config: discovery: enable: true # 启用服务发现 (Eureka) service-id: config # spring cloud config server 应用名称 profile: dev label: master 启动服务 启动服务时，即会先去 git 仓库获取配置信息。\n配置信息自动更新 当 git 仓库中的配置信息更新后，使用配置的客户端并不会自动更新配置。所以我们需要一些机制去触发配置的更新。\nactuator 添加依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加注解，打开更新机制 通过在需要加载更新配置的类上添加 @RefreshScope，当客户端通过触发 POST 方式的 /refresh 时，会自动将新的配置更新到相应的字段中。\n1 2 3 4 5 6 7 8 9 10 @RefreshScope // 该类中配置相关会自动刷新 @RestController public class ActuatorController { @Value(\u0026#34;${env}\u0026#34;) private String env; @RequestMapping(\u0026#34;/env\u0026#34;) public String env { return this.env; } } 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # server 端添加 management: endpoints: web: exposure: include: \u0026#34;*\u0026#34; --- # client 端添加 management: endpoints: web: exposure: include: refresh 测试自动刷新 当 git 仓库中配置文件更新后，通过发送 POST 请求到 /refresh 后，客户端会自动获取最新配置。\n1 curl -v -X POST http://localhost:8080/actuator/refresh Spring Cloud Bus （推荐） 通过 spring cloud bus，通过 POST 请求 /bus-refresh，实现自动获取最新配置。\n至此两种消息代理：\nRabbitMQ Kafka WebHook WebHook 是当某个事件发生时，通过发送 http post 请求的方式来通知信息接收方。\n通过创建 WebHook 即可自动触发 POST 请求，让客户端动态刷新配置。\n","date":"2020-07-27T12:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/spring-cloud-config/","title":"Spring Cloud Config 统一配置中心"},{"content":"Spring Cloud 服务通信 同步通信：\ndobbo 通过 RPC 远程调用。 spring cloud 通过 REST 接口调用。 异步通信：\n通过消息对列，如：RabbitMQ，Kafka，ActiveM 等。 本文主要介绍 Spring Cloud 使用 RestTemplate / OpenFeign 进行 REST 接口调用。\nRestTemplate 通过 RestTemplate 进行调用 1 2 3 4 5 6 7 8 9 public ProductInfo getProductMsg(String id) { RestTemplate restTemplate = new RestTemplate(); ProductInfo response = restTemplate.getForObject( \u0026#34;http://example.com/product/info\u0026#34;, // 远程调用地址 ProductInfo.class, // response 类型 id // 需要传递的参数 ); return response; } 利用 LoadBalancerClient 获取信息 1 2 3 4 5 6 7 8 9 10 11 12 @Autowired private LoadBalancerClient loadBalancerClient; public ProductInfo getProductMsg(String id) { RestTemplate restTemplate = new RestTemplate(); ServiceInstance serviceInstance = loadBalancerClient.choose(\u0026#34;PRODUCT\u0026#34;); // 利用 loadBalancerClient 通过应用名（spring.application.name）获取信息 String url = String.format(\u0026#34;http://%s:%s\u0026#34;, serviceInstance.getHost(), serviceInstance.getPort()) + \u0026#34;/product/info\u0026#34;; ProductInfo response = restTemplate.getForObject(url, ProductInfo.class, id); return response; } 利用 LoadBalance 在 RestTemplate 中直接使用应用名称 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class RestTemplateConfig { @Bean @LoadBalance public RestTemplate restTemplate() { return new RestTemplate(); } } --- @Autowired private RestTemplate restTemplate; public ProductInfo getProductMsg(String id) { // 利用 @LoadBalance 可以在 RestTemplate 中使用应用名称 ProductInfo response = restTemplate.getForObject(\u0026#34;http://PRODUCT/product/msg\u0026#34;, ProductInfo.class, id); return response; } OpenFeign （推荐） 引入依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加启动注解 1 2 3 4 5 6 7 8 9 10 import org.springframework.cloud.openfeign.EnableFeignClients; @EnableFeignClients @SpringBootApplication @EnableDiscoveryClient public class FeignApplication { public static void main(String[] args) { SpringApplication.run(FeignApplication.class, args); } } 具体实现 现在有两个服务，分别为 Prodcut 和 Order 。 需求： Order 服务中，客户进行了下单操作后，调用 Product（Feign） 的进行减库存操作。\nProduct 服务中，定义远程调用端。 1 2 3 4 5 6 7 8 9 10 11 12 public class DecreaseStockInput { // ... } --- @FeignClient(name = \u0026#34;product\u0026#34;) // name: 远程服务名(Spring.application.name) public interface ProductClient { @RequestMapping(value = \u0026#34;/product/decrease_stock\u0026#34;) void decreaseStock(@RequestBody List\u0026lt;DecreaseStockInput\u0026gt; decreaseStockInputList); } Order 服务中，对 Product Client 进行调用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Service public class OrderServiceImpl implements OrderService { // 注入的为 Product 中的 ProductClient // 通过依赖的方式 @Autowired private ProductClient productClient; public OrderDTO create(OrderDTO orderDTO) { // ... // 调用 Product 服务中的 api 进行减库存操作 productClient.decreaseStock(decreaseStockInputList); // ... } } ","date":"2020-07-26T21:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/spring-cloud-openfeign/","title":"Spring Cloud 服务通信"},{"content":"Eureka 找到啦！ 服务注册与发现\n简介 Spring Cloud 封装了 Netflix 公司开发的 Eureka 模块来实现服务注册和发现。采用了 C-S 的设计架构。用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。 由两个组件组成。 Ereka Server。 注册中心 Ereka Client。 服务注册 Eureka 采用了客户端发现的方式，在服务运行时，通过(轮训、hash等负载均衡机制等方式)注册中心找到需要服务（即 A 通过 注册中心 找 B，需要谁找谁）。\nEureka Server 注册中心记录着所有应用的信息和状态(如：应用名，所在服务器，是否正常工作)。\n实现一个注册中心 1. 引入依赖 1 2 3 4 5 6 7 8 9 10 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-eureka-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2. 添加启动注解 1 2 3 4 5 6 7 @EnableEurekaServer @SpringBootApplication public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } } 3. 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 spring: application: name: eureka-server Server: port: 8761 eureka: client: register-with-eureka: false # 是否将自己注册到Eureka Server，作为 Server 端不需要 fetch-registry: false # 是否从Eureka Server获取注册信息，作为 Server 端不需要 service-url: # 接收的是一个 Map 结构 defaultZone: http://localhost:8761/eureka/ 4. 启动程序 启动后，访问 http://localhost:8761/，即可看到 Spring Eureka 界面。\n实现 Eureka 集群 在一个分布式系统中，服务注册中心是最重要的基础部分，理应随时处于可以提供服务的状态。为了维持其可用性，通常会采用集群的方案。Eureka通过互相注册的方式来实现高可用的部署\n双节点注册 创建两台服务器，端口分别为 8761 和 8762。\n将 8761 的服务器配置指向 8761，将 8762 的服务器指向 8761。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 spring: application: name: eureka-server Server: port: 8761 eureka: client: register-with-eureka: false fetch-registry: false service-url: # 将 service-url 指向 8762 defaultZone: http://localhost:8762/eureka/ --- spring: application: name: eureka-server Server: port: 8762 eureka: client: register-with-eureka: false fetch-registry: false service-url: # 将 service-url 指向 8761 defaultZone: http://localhost:8761/eureka/ 启动程序后，通过 http://localhost:8761/ 和 http://localhost:8762/ 都可访问 Eureka 界面。并且可以看到另一个节点信息节点的信息。\n多节点注册 在生产中我们需要三台或者大于三台的注册中心来保证服务的稳定性，配置的原理其实都一样：将注册中心分别指向其它的注册中心。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 --- spring: application: name: eureka-server server: port: 8761 eureka: client: register-with-eureka: false fetch-registry: false serviceUrl: defaultZone: http://localhost:8762/eureka/,http://localhost:8763/eureka/ --- spring: application: name: eureka-server server: port: 8762 eureka: client: register-with-eureka: false fetch-registry: false serviceUrl: defaultZone: http://localhost:8761/eureka/,http://localhost:8763/eureka/ --- spring: application: name: eureka-server server: port: 8763 eureka: client: register-with-eureka: false fetch-registry: false serviceUrl: defaultZone: http://localhost:8761/eureka/,http://localhost:8762/eureka/ Eureka Client 实现一个服务注册 1. 依赖配置 1 2 3 4 5 6 \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-eureka\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 2. 添加启动注解 1 2 3 4 5 6 7 8 9 import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; @EnableDiscoveryClient @SpringBootApplication public class ClientApplication { public static void main(String[] args) { SpringApplication.run(ClientApplication.class, args); } } 3. 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 spring: application: name: eureka-client server: port: 8080 eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ # instance: # 自定义链接 # hostname: example.com 4. 启动程序 启动程序后，进入 Eureka 页面 http://localhost:8761/eureka/，即可看到注册的服务 eureka-client。\n总结 分布式系统中，服务注册中心是最重要的基础部分 @EnableEurekaServer @EnableEurekaClient 具有 心跳检测，健康检查，负载均衡等功能 为保证高可用，建议集群部署 ","date":"2020-07-25T13:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/spring-cloud-eureka/","title":"Spring Cloud Eureka 服务注册与发现"},{"content":"警告：该教程仅为个人记录，该笔记本安装涉及解锁BIOS，存在一定风险，如您使用该教程对计算机进行更改，所造成的的任何后果我概不负责。\n写在最前 开学后太忙，并且电脑我换了块更大的硬盘，这台电脑我不打算再安装黑苹果了，本教程可能会不再更新，最新上传的配置文件中，添加了对 type-C 4K 30Hz 的支持，4K 60Hz 显示器会黑屏，无法输出信号。\n如果想要使用 Clover 安装 10.15 或以下系统的话，可以依旧按照此教程（请将 Clover 和 kext 选择到适应版本）。\n如果打算安装新系统使用的话，建议使用 Opencore 安装。推荐参考 RazerBlade15-Base-Model-Hackintosh_macOS_Monterey，该教程写的非常详细，感谢他的付出。\n建议不要使用 东芝（铠侠）的固态硬盘，我的硬盘为东芝 tr200，在 macOS 中莫名卡顿，我的东芝U盘在 macOS 中也莫名卡顿，其他系统没有什么问题。（玄学问题？）\n祝你玩得愉快！\nGithub ➡️\n因为疫情原因春节一直宅在家，学校假期也延长了，找到了同款笔记本的教程，所以入坑安装黑苹果，最近把步骤整理了一下。\n安装过程我主要参考了 这篇 和 这篇 教程，感谢他们的辛苦付出。部分内容为他们所写教程的汉化，详细或精简，我的水平有限，刚接触黑苹果，建议同时参考他们的教程。\n硬件介绍 结果介绍 解锁BIOS 安装前准备 系统安装 DSDT，SSDT制作 网卡 一些优化 参考 更新 [1] 硬件介绍 型号 最终情况 CPU i7-8750H 可用 GPU Nvdia 1060 Max-Q 除 10.13 High Sierra 安装 WebDriver 外不可用 硬盘 更换了 金士顿 A2000 可用 网卡 9560NGW WIFI 目前无解，蓝牙可用 显示器 1080P 可用 摄像头 可用 扬声器 可用 耳机 无法检测到麦克风 麦克风 不可用，已识别，但在设置中未看见输入电平 触控板 手势可用（反应稍慢） HDMI 接口 直通显卡，除安装 High Sierra 外不可用 Mini DP 接口 直通显卡，除安装 High Sierra 外不可用 雷电3 被识别成 USB3.1，可外接拓展坞外接显示器，我的电脑中需要删除SSDT-12-OptTabl.aml [2] 安装结果 一些小问题 我也是刚刚接触黑苹果，很多问题我也无法解决，有谁了解的话希望能帮助一下，感谢。\n麦克风无法使用，系统能找到但无法使用，耳机麦克风无法找到。想要使用的话只能通过蓝牙耳机了。\n耳机麦克无法识别。\n输出设备默认识别到了扬声器和耳机（即使未插入耳机），无法自动切换，需手动切换。\n更新 今天本来想根据 这篇文章 尝试自己定制一下 AppleALC ，当我把有效节点和路径弄完之后，准备下载 AppleALC-DEBUG 编译的时候，没想到最新版本已经添加了这个笔记本的 layout-id:23。\n请按照如图修改，保存后重启。我的电脑耳机麦克风无法识别（我在 Ubuntu 下也无法找到耳机麦克风的有效节点信息）\n添加 type-c 输出 4k，只能支持到最高 30Hz，输出 60Hz 会直接黑屏。可以安装一个 RDM 进行管理。\n[3] 解锁BIOS 解锁BIOS，存在一定风险，如您使用该教程对计算机进行更改，所造成的的任何后果我概不负责！！！\n雷蛇国内官网没有提供驱动和BIOS的下载，如有需要，需要访问美国官网。点我。\n该笔记本 DVMT 预分配默认为 32MB，不足以启动 MacOS，在 BIOS 中该设置项默认隐藏，所以要提取本机 BIOS 并且进行解锁，将 DVMT 预分配默认设置为 64MB（1080P），分辨率更高请分配更大空间。\n建议在 windows 下操作。\n[3-1] 提取本机 BIOS 注意备份好。\n打开 AFUWINGUI.exe，点击 Save 按钮，导出本机当前 BIOS 。\n[3-2] 修改 BIOS 打开 AMIBCP.exe ，点击 File -\u0026gt; open 打开导出的 BIOS。 如图，在左侧选择 / -\u0026gt; Setup -\u0026gt; Chipset，将左侧的 System Agent Configuration 的 Access 由 Default 修改为 USER 修改完后点击 File -\u0026gt; Save as。重命名为新的 BIOS。 [3-3] 刷入新 BIOS ！！！ 注意，该过程虽然简单，但有一定风险，造成的任何结果与本人无关。\n重新打开 AFUWINGUI.exe，点击 Open 打开刚刚修改后的 BIOS。\n尽可能的退出其他程序，尽量保持后台干净，再点击 Flash 刷入新的 BIOS。\n重启 [4] 安装前准备 [4-1] 准备macOS Catalina 安装盘 推荐使用黑果小兵制作的镜像，使用 TransMac 制作（软件在文件夹中已提供）。这里是10.15.3的镜像。\n如果您要安装更新的系统，请升级 CLOVER，和 kexts/ 到对应兼容或更新的版本，可将制作好的安装盘中 EFI/CLOVER 的文件进行同名替换。（未来的新版本可能不可预知的问题，请酌情升级）。\n[4-2] 启动盘制作 请参考，或自行搜索，网上教程很多。点我。\n[5] 系统安装 [5-1] BIOS 设置 Advanced\nThunderbolt(TM) Configuration Security Level 设置成 No Security Chipset\nSystem Agent (SA) Configuration Graphics Configuration DVMT Pre-Allocated 设置成 64 DVMT Total Gfx Mem 设置成 MAX Security\nSecure Boot 设置成 Disabled Boot\nFast Boot 设置成 Disabled\nCSM Configuration\nCSM Support 设置成 Disabled [5-2] 安装过程 系统安装过程大致相同，选择U盘启动后进入安装。安装过程会重启几次。\n可自行搜索，参考其他人的步骤。\n[5-3] 安装时可能出现的问题 显示程序副本已损坏\n断网 打开终端 修改时间为系统发布对应的时间。 如修改为 2019年。输入 date 000000002019。\n[6] DSDT，SSDT制作 通过修补DSDT，SSDT驱动触控板，音频，电池状态，亮度控制等。\n[6-1] 准备修补 [6-1-1]\n开机在 Clover 引导界面中按 F4，所需文件会加载到 EFI/Clover/ACPI/origin 中。通过 Clover Configurator 挂载启动的 EFI（通过U盘启动就挂载U盘）。\n[6-1-2]\n将 origin 文件夹复制到桌面，同时将 iasl 软件复制到文件夹中。\n[6-1-3]\n打开终端\n1 2 3 cd ~/Desktop mkdir patched ./origin/iasl -da -dl DSDT.aml [6-1-4]\n打开 origin，使用 MaciASL 打开生成的 DSDT.dsl 文件。点击 Compile，确保没有错误。（默认应该没有 error，但有很多 warning，warning 不必关系，若有 error 请将 error 处代码注释或删除）\n[6-1-5]\n确保没有 errors 后，点击 Patch。\n[6-2] 修复电池 [1] 在弹窗的左侧点击 _RehabMan Laptop/[bat]Razer Blade (2014) ，等待右侧进行匹配后点击 Apply。\n如果网络不好的话可能无法加载（github），请切换到合适的网络，或访问 这里，或复制以下代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 #Maintained by: RehabMan for: Laptop Patches #battery_Razer-Blade-2014.txt # created by sidelia 2016-01-17 # changes for Razer Blade Stealth (Kaby Lake) by BlenderSleuth (minor fixes by RehabMan) # works for: # Razer Blade (2014) # Razer Blade Stealth (Kaby Lake), per BlenderSleuth # Razer Blade (14\u0026#34;, late 2016) # Razer Blade Pro (2017) # Razer Blade 15 (2018), per JomanJi/blodtanner into method label B1B2 remove_entry; into definitionblock code_regex . insert begin Method (B1B2, 2, NotSerialized) { Return(Or(Arg0, ShiftLeft(Arg1, 8))) }\\n end; into device label EC0 code_regex BIF1,\\s+16, replace_matched begin IF10,8,IF11,8, end; into device label EC0 code_regex BIF2,\\s+16, replace_matched begin IF20,8,IF21,8, end; into device label EC0 code_regex BIF3,\\s+16, replace_matched begin IF30,8,IF31,8, end; into device label EC0 code_regex BIF4,\\s+16, replace_matched begin IF40,8,IF41,8, end; into device label EC0 code_regex BST0,\\s+16, replace_matched begin ST00,8,ST01,8, end; into device label EC0 code_regex BST1,\\s+16, replace_matched begin ST10,8,ST11,8, end; into device label EC0 code_regex BST2,\\s+16, replace_matched begin ST20,8,ST21,8, end; into device label EC0 code_regex BST3,\\s+16, replace_matched begin ST30,8,ST31,8, end; into method label _BIF code_regex \\^\\^EC0\\.BIF1, replaceall_matched begin B1B2(^^EC0.IF10,^^EC0.IF11), end; into method label _BIF code_regex \\^\\^EC0\\.BIF2, replaceall_matched begin B1B2(^^EC0.IF20,^^EC0.IF21), end; into method label _BIF code_regex \\^\\^EC0\\.BIF3, replaceall_matched begin B1B2(^^EC0.IF30,^^EC0.IF31), end; into method label _BIF code_regex \\^\\^EC0\\.BIF4, replaceall_matched begin B1B2(^^EC0.IF40,^^EC0.IF41), end; into method label _BST code_regex \\^\\^EC0\\.BST0, replaceall_matched begin B1B2(^^EC0.ST00,^^EC0.ST01), end; into method label _BST code_regex \\^\\^EC0\\.BST1, replaceall_matched begin B1B2(^^EC0.ST10,^^EC0.ST11), end; into method label _BST code_regex \\^\\^EC0\\.BST2, replaceall_matched begin B1B2(^^EC0.ST20,^^EC0.ST21), end; into method label _BST code_regex \\^\\^EC0\\.BST3, replaceall_matched begin B1B2(^^EC0.ST30,^^EC0.ST31), end; # added for Razer Blade 15 (2018), per JomanJi into device label EC0 code_regex BIF0,\\s+16, replace_matched begin IF00,8,IF01,8, end; into method label _BIF code_regex \\(\\^\\^EC0.BIF0, replaceall_matched begin (B1B2(\\^\\^EC0.IF00,\\^\\^EC0.IF01), end; # utility methods to read/write buffers from/to EC into method label RE1B parent_label EC0 remove_entry; into method label RECB parent_label EC0 remove_entry; into device label EC0 insert begin Method (RE1B, 1, NotSerialized)\\n {\\n OperationRegion(ERAM, EmbeddedControl, Arg0, 1)\\n Field(ERAM, ByteAcc, NoLock, Preserve) { BYTE, 8 }\\n Return(BYTE)\\n }\\n Method (RECB, 2, Serialized)\\n // Arg0 - offset in bytes from zero-based EC\\n // Arg1 - size of buffer in bits\\n {\\n ShiftRight(Add(Arg1,7), 3, Arg1)\\n Name(TEMP, Buffer(Arg1) { })\\n Add(Arg0, Arg1, Arg1)\\n Store(0, Local0)\\n While (LLess(Arg0, Arg1))\\n {\\n Store(RE1B(Arg0), Index(TEMP, Local0))\\n Increment(Arg0)\\n Increment(Local0)\\n }\\n Return(TEMP)\\n }\\n end; # buffer fields into device label EC0 code_regex (ECCM,)\\s+(256) replace_matched begin ECCX,%2,//%1%2 end; into method label _BIF code_regex \\(\\^\\^EC0.ECCM, replaceall_matched begin (^^EC0.RECB(0x60,256), end; [2] 点击 Compile，确保没有错误。（默认情况下没有，不同版本BIOS可能情况不同）。\n[6-4] 修复重启保存背光亮度 [6-4-1]\n在左侧菜单栏向下滑动，找到 [gfx0] Disable/Enable on _WAK/_PTS (DSDT)，点击都单击 Apply。\n网络不好可点击 这里 或复制以下代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #Maintained by: RehabMan for: Laptop Patches #graphics_PTS_WAK-disable.txt # # The purpose of this patch is to add code to to _WAK # that disables Radeon/nvidia on wake and add code # to _PTS that enables it on _PTS. # # The path of _OFF may have to be customized to match your SSDTs # The patch attempts to identify the correct _REG by using # the ACPI PNP identifier for the EC. # # Use this patch if you experience trouble shutting down # or restarting your laptop when disabling nvida/radeon. # into method label _PTS code_regex ([\\s\\S]*) replace_matched begin External(\\\\_SB.PCI0.PEG0.PEGP._ON, MethodObj)\\n If (CondRefOf(\\\\_SB.PCI0.PEG0.PEGP._ON)) { \\\\_SB.PCI0.PEG0.PEGP._ON() }\\n %1 end; into method label _WAK code_regex (Return\\s+\\(.*) replace_matched begin External(\\\\_SB.PCI0.PEG0.PEGP._OFF, MethodObj)\\n If (CondRefOf(\\\\_SB.PCI0.PEG0.PEGP._OFF)) { \\\\_SB.PCI0.PEG0.PEGP._OFF() }\\n %1 end; [6-4-2] 按 command + F 搜索 Device (ALSD)，找到如图代码，将其替换为以下代码。\n1 2 3 4 5 6 7 8 9 10 Device (_SB.ALS0) { Name (_HID, \u0026#34;ACPI0008\u0026#34;) // _HID: Hardware ID Name (_CID, \u0026#34;smc-als\u0026#34;) // _STA: Status Name (_ALI, 300) // _ALI: Ambient Light Illuminance Name (_ALR, Package () // _ALR: Ambient Light Response { Package () { 100, 300 }, }) } [6-3] 修复触控板 灵刃 15 的标准版和精英版使用的触控板不同，请根据自己的电脑进行选择修复方案。\n[6-3-1] 标准版 [6-3-1-1]\n继续搜索 SSCN。找到 Scope 为 _SB.PCI0.I2C0 下的 SSCN 方法。复制 SSCN 与 FMCN（在 SSCN 下方）这 两个方法。并将这两个方法如图重命名（也可选择删除）。\n重命名为：\n[6-3-1-3]\n搜索 TPD0。将之前剪切的两个方法放到 _INI 方法后。\n[6-3-1-4]\n向下找到如下代码。\n将其更改为如图。\n[6-3-2] 精英版 [6-3-2-1]\n在 Patch 页面中粘贴以下代码代码，点击 Apply。\n[6-3-2-2]\n点击 Compile 进行编译确定无 error（默认没有）。\n1 2 3 4 5 6 7 into method label _STA parent_label GPI0 replace_content begin Return (0x0F) end; into_all method label _CRS parent_label TPD0 replace_content begin ConcatenateResTemplate (SBFB, SBFI) end; [6-4] 保存修改好的 DSDT.aml 点击 File -\u0026gt; save as 。\nFile Format 选择 ACPI Machine Language Binary。命名为 DSDT.aml。存入桌面中的 parched 文件夹中。\n[6-5] 屏蔽 Nvdia 显卡 如果你选择安装 High Sierra 安装 WebDriver 使用 Nvidia 显卡的话，不用该补丁。 [点击这里查看支持驱动的 High Sierra ](https : //www.tonymacx86.com/nvidia-drivers/)\n在的笔记本上使用该补丁会导致 type-c 转视频接口无信号，无法拓展显示器，若出现相同情况请删除该补丁。 [6-5-1]\n再次进入 origin 文件夹中，在终端输入\n1 ./origin/iasl -da -dl SSDT-12-OptTabl.aml [6-5-2]\n根据上方修补电池状态，触控板的方式类似，使用 MaciASL 打开 SSDT-12-OptTabl.dsl\n[6-5-3]\n按 command + F 搜索以下代码\n1 Method (_OFF, 0, Serialized) // _OFF: Power Off [6-5-4]\n在该代码上方，粘贴以下代码\n1 Method (_INI) {_OFF() } // added to call _OFF [6-5-5]\n点击 patch，将以下代码粘贴到弹窗中，点击 apply。\n1 2 3 4 5 6 into method label _INI parent_label \\_SB.PCI0.GFX0 insert begin //added to turn nvidia/radeon off\\n External(\\_SB.PCI0.PEG0.PEGP._OFF, MethodObj)\\n \\n end; [6-5-6]\n点击编译，出现一个错误。\n[6-5-7]\n搜索一下代码，并将其删除，再次编译。\n1 External (_SB_.PCI0.PEG0.TGPC, IntObj) // (from opcode) [6-5-8]\n点击 File -\u0026gt; Save As。将最终的 /aml 文件保存。\n[6-6] 制作 SSDT-USBX.aml 如果想制作自己的 SSDT-USBX.aml。请参考 点我。\n使用 USBMap。点我\n[6-7] 复制提供的的 .aml 文件 将文件夹中的 SSDT-PNLF.aml，SSDT-UIAC-ALL.aml，SSDT-USBX.aml，SSDT-XOSI.aml 同上面修补的两个文件一同放入 patched 文件夹中，最后 patched 文件夹中应该有如下6个文件。\n如果 type-c 转视频接口无信号，请删除SSDT-12-OptTabl.aml\n[7] 网卡 [7-1] 更换博通网卡 在网上找过拆机图，网卡附近的位置还是挺多的，我的选择是拆机的 BCM94360cs2 + 转接卡，可直接免驱使用。\n相比使用原装的网卡位置稍有点高，压在一根的排线上，但是不影响，如选择同款网卡，请注意绝缘，建议上螺丝的时候不要拧太紧，不松动即可。装上之后的效果如图。\n**小提示: **拧螺丝前最好把易碎贴给清理干净。这个贴纸分量太足，卡在螺丝孔中导致一直滑丝。\n**使用效果: **2.4G WIFI 和 蓝牙有干扰，尤其是 2.4G WIFI 使用带宽高的时候，蓝牙几乎不能用。其他使用场景基本良好。\n想折腾的话可选择 DW1820A，可参考 这里。\n博通 BCM94352Z ，现在价钱被炒的很高，目前将近 300，有钱随意。\n[7-2] 使用自带网卡 Intel 蓝牙默认免驱，WiFi 目前无解。\n蓝牙从 windows 重启进入 macOS 可使用（网卡未断电所以上传了驱动）。\n将 该驱动 放入 EFI/CLOVER/kexts，可以实现冷启动驱动自带网卡蓝牙。\n**使用效果: **蓝牙键盘，蓝牙音箱没有问题，蓝牙鼠标貌似不能用。\n[7-3] 使用USB网卡 usb 网卡驱动安装。点我。\nCOMFAST CF-WU815N 150M 单频 COMFAST CF-811AC 650M 双频 COMFAST CF-812AC 1300M 双频 更多其他型号自行搜索 [8] 一些优化 [8-1] HIDPI 开启 HIDPI 后可能会导致开机第二阶段 Logo 变大，因为分辨率是仿冒的，不影响使用。\n使用终端执行：\n1 sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/xzhih/one-key-hidpi/master/hidpi.sh)\u0026#34; 选择 \u0026ldquo;开启 HIDPI\u0026rdquo;\n显示的 ICON 选择 Macbook Pro（在设置界面显示的样式）\n选择分辨率配置 1080P 显示器（根据自身情况选择）\n更多详细情况可参考这篇文章。点我。\n[8-2] 打开 TRIM 如果使用 SSD，一定要打开 TRIM，防止系统多次擦写，确保硬盘寿命。\n1 sudo trimforce enable 完成后系统会进行一次重启。\n[8-3] 禁用睡眠 在终端运行以下命令，并在 设置 -\u0026gt; 节能 中关闭相应设置。\n1 2 3 4 5 sudo pmset -a hibernatemode 0 sudo rm /var/vm/sleepimage sudo mkdir /var/vm/sleepimage [8-4] “洗白”序列号 网络上已经有很多教程，自行搜一下。\n参考 https://github.com/stonevil/Razer_Blade_Advanced_early_2019_Hackintosh https://www.tonymacx86.com/threads/guide-razer-blade-15-2018-detailed-install-guide-high-sierra-10-13-6-17g2208-17g5019.264017/ https://blog.daliansky.net/ ","date":"2020-02-27T21:14:45+08:00","permalink":"https://emerywan.github.io/blog/p/razer-blade-base-hackintosh/","title":"雷蛇 灵刃 15 标准版 2018 黑苹果"}]