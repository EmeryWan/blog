<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="🚲 转到 https://nlp.letout.cn 🔔 文本处理与词嵌入 ➡️ 本节主要内容为 文本处理 Text Processing 和 词嵌入 Word Embedding。本节和下面两节内容都会使用 IMDb 电影评论的数据，用来搭建机"><title>文本处理与词嵌入</title><link rel=canonical href=https://www.letout.cn/p/nlp-in-action/text-processing-and-word-embedding/><link rel=stylesheet href=/scss/style.min.53b36bd111ab91c36b669e22939503ad8be1ecdac357e4514855ae8d8deda711.css><meta property="og:title" content="文本处理与词嵌入"><meta property="og:description" content="🚲 转到 https://nlp.letout.cn 🔔 文本处理与词嵌入 ➡️ 本节主要内容为 文本处理 Text Processing 和 词嵌入 Word Embedding。本节和下面两节内容都会使用 IMDb 电影评论的数据，用来搭建机"><meta property="og:url" content="https://www.letout.cn/p/nlp-in-action/text-processing-and-word-embedding/"><meta property="og:site_name" content="一层"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="自然语言处理"><meta property="article:published_time" content="2022-03-11T21:14:45+08:00"><meta property="article:modified_time" content="2022-03-11T21:14:45+08:00"><meta property="og:image" content="https://nlp.letout.cn/img/banner.png"><meta name=twitter:title content="文本处理与词嵌入"><meta name=twitter:description content="🚲 转到 https://nlp.letout.cn 🔔 文本处理与词嵌入 ➡️ 本节主要内容为 文本处理 Text Processing 和 词嵌入 Word Embedding。本节和下面两节内容都会使用 IMDb 电影评论的数据，用来搭建机"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://nlp.letout.cn/img/banner.png"><link rel="shortcut icon" href=https://www.letout.cn/imgs/favicon.ico><link rel=preconnect href=https://fonts.proxy.ustclug.org><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.proxy.ustclug.org/css2?family=Noto+Sans+SC&family=Roboto&family=Roboto+Mono&display=swap" rel=stylesheet><style>:root{--sys-font-family:-apple-system, BlinkMacSystemFont, "Roboto", "Noto Sans SC", "Segoe UI", "Droid Sans", "Helvetica Neue", Ubuntu;--zh-font-family:-apple-system, BlinkMacSystemFont, "Roboto", "Noto Sans SC",  "PingFang SC", "Hiragino Sans GB", "Droid Sans Fallback", Ubuntu, "Microsoft YaHei";--code-font-family:"SF Mono", SFMono-Regular, "Roboto Mono", "Ubuntu Mono", Menlo, Monaco, Consolas, "Courier New", monospace, var(--zh-font-family);--base-font-family:-apple-system, BlinkMacSystemFont, "Roboto", "Noto Sans SC", var(--sys-font-family), var(--zh-font-family), sans-serif;--article-font-family:-apple-system, BlinkMacSystemFont, "Roboto", "Noto Sans SC", var(--base-font-family);--article-line-height:1.6;--article-font-size:1.6rem}</style></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hud10ed4afecf1b63b1391b35c2778f738_36574_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>一层</a></h1><h2 class=site-description>迎着这岁月的风。</h2></div></header><ol class=social-menu><li><a href=https://github.com/emerywan target=_blank title=GitHub><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://emery.letout.cn target=_blank title=Home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-smart-home" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#6f32be" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M19 8.71l-5.333-4.148a2.666 2.666.0 00-3.274.0L5.059 8.71A2.665 2.665.0 004.03 10.815v7.2a2 2 0 002 2h12a2 2 0 002-2v-7.2c0-.823-.38-1.6-1.03-2.105"/><path d="M16 15c-2.21 1.333-5.792 1.333-8 0"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>首页</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>关于</span></a></li><li><a href=/categories/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg><span>分类</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>归档</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>搜索</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>🌗 Dark</span></li></div></ol></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/nlp-in-action/text-processing-and-word-embedding/><img src=https://nlp.letout.cn/img/banner.png loading=lazy alt="Featured image of post 文本处理与词嵌入"></a></div><div class=article-details><header class=article-category><a href=/categories/nlp-in-action/ style=background-color:#d3adf7;color:#fff>NLP in action</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/nlp-in-action/text-processing-and-word-embedding/>文本处理与词嵌入</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>03 - 11, 2022</time></div></footer></div></header><section class=article-content><hr><p><a class=link href=https://nlp.letout.cn/nlp/text-processing-and-word-embedding target=_blank rel=noopener>🚲 转到 https://nlp.letout.cn 🔔 文本处理与词嵌入 ➡️</a></p><hr><p>本节主要内容为 <strong>文本处理</strong> <code>Text Processing</code> 和 <strong>词嵌入</strong> <code>Word Embedding</code>。本节和下面两节内容都会使用 IMDb 电影评论的数据，用来搭建机器学习模型分析电影评论。</p><h2 id=-imdb>🌱 IMDb</h2><p><a class=link href=https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E7%94%B5%E5%BD%B1%E8%B5%84%E6%96%99%E5%BA%93 target=_blank rel=noopener>IMDb</a> 是最有名的电影评论网站，用户可以在 IMDb 上给电影打分，1 分是非常讨厌，10 分是非常喜欢，如果乐意，还可以写一段电影评论。</p><p><img src=https://nlp.letout.cn/img/nlp/02/imdb.png loading=lazy alt=IMDb></p><p>如果不给你看分数，只给你看评论，你大概能猜到用户打的分数，但你的猜测可能不太准确。如果换种方式，让你判断电影评论是 <strong>正面</strong> <code>positive</code> 的还是 <strong>负面</strong> <code>negative</code> 的，你应该会有很高的准确率。有人从 IMDb 上爬了 5 万条电影评论，这些评论都是很极端的，都是强烈的喜欢，或者强烈反感。这个二分类问题对于人来说很简单，人读一下电影评论就能轻易知道这是正面评价还是负面评价，人应该能有 100% 的准确率，这个数据集被分成两半，2 万 5 千条作为训练数据 <code>Train</code>，另外 2 万 5 千条作为测试数据 <code>Test</code>。</p><p>你可以在下面的链接中获取到数据集：<a class=link href=https://ai.stanford.edu/~amaas/data/sentiment/ target=_blank rel=noopener>https://ai.stanford.edu/~amaas/data/sentiment/</a></p><h2 id=-文本处理文本处理>🔖 文本处理文本处理</h2><p>在词嵌入 <code>Word Embedding</code> 和搭建机器学习模型之前，首先要进行文本处理，将文本变成序列 <code>Sequence</code>，文本处理很无聊，但我们应该重视它，文本处理的好坏，会直接影响机器学习模型的准确率。</p><h3 id=-tokenization>🚀 Tokenization</h3><p>文本处理的第一步是 <code>Tokenization</code>，把文本分割成很多 <code>tokens</code>，这里我们把文本分割成很多单词，一个 <code>token</code> 就是一个单词（假如你把文本分割成字符，那么一个 <code>token</code> 就是一个字符），做完 <code>Tokenization</code>，一个很长的字符串就被分割成一个很多单词的列表。</p><p><img src=https://nlp.letout.cn/img/nlp/02/1.png loading=lazy alt=1></p><p><code>Tokenization</code> 看起来很简单，但是讲究很多。比如：</p><ul><li>🌰 是否应该把大写变成小写？</li></ul><p>通常情况下应该把大写变成小写，大小写单词通常是一个意思；但有时候会混淆单词（Apple -> apple），比如 Apple 是苹果公司，apple 是水果，大小写的 apple 并不是相同的单词。</p><ul><li>🌰 去除停用词。<code>stop word</code></li></ul><p>有些应用会去除 stop word，它是 the、a、of 等最高频的单词，这些词几乎出现在所有的句子里，对这个二分类问题几乎是没有帮助。</p><ul><li>🌰 拼写纠错。</li></ul><p>用户发电影评论的时候，大部分情况下并不会仔细检查，所以写的东西难免会有拼写错误，所以做拼写纠错通常是有用的。</p><p>这里只是举了几个例子，实际上做 <code>Tokenization</code> 的时候需要做大量的工作，<code>Tokenization</code> 看似简单，但实际上并不容易。</p><h3 id=-build-dictionary>🧰 Build Dictionary</h3><p>第二步是建立一个字典。可以先统计词频，去掉一些低频词，让后让每个单词对应一个正整数，比如让 <code>the -> 1; cat -> 2; sat -> 3</code>。有了这个字典，就可以把每个单词对应到一个整数，这样一来，一句话就可以用正整数的列表表示，这个列表被称为序列 <code>Sequences</code>。</p><p><img src=https://nlp.letout.cn/img/nlp/02/2.png loading=lazy alt=2></p><p>如果有必要的话，还得进一步做 <code>one-hot encoding</code>，把单词表示成 <code>one-hot</code> 向量。</p><p>在电影评论的例子里，数据是 5 万条电影评论，每条电影评论可以表示成一个字符串。做完 <code>Tokenization</code> 和 <code>Encoding</code> 后，每条电影评论都会转换成一个 <code>Sequences</code>，也就是一个正整数的列表。</p><p><img src=https://nlp.letout.cn/img/nlp/02/3.png loading=lazy alt=3></p><p>电影评论有长有短，有人只能写几个字的评论，有人能洋洋洒洒写几千字，所以得到的这些 <code>Sequences</code> 的长度也各不相同。比如这两条 <code>Sequences</code> 的长度分别是 52 和 90。</p><p><img src=https://nlp.letout.cn/img/nlp/02/4.png loading=lazy alt=4></p><p>这就造成了一个问题，训练数据没有对齐，每条 <code>Sequences</code> 都有不同的长度。做机器学习的时候，我们需要把数据存储到矩阵或者张量里，每条序列都得有相同的长度，需要把序列对齐。</p><p><img src=https://nlp.letout.cn/img/nlp/02/5.png loading=lazy alt=5></p><p>解决方案是这样的：我们可以固定长度为 $w$。假如一个序列长度太长，超过了 $w$ 个词，就砍掉前面的词，只保留最后面 $w$个词（当然保留最前面 $w$ 个词也同样可以）；假如一个序列太短，不到 $w$ 个词，那么就做 <code>zero padding</code> 用 0 来补齐，把长度增加到 $w$。</p><p><img src=https://nlp.letout.cn/img/nlp/02/6.png loading=lazy alt=6></p><p>这样一来，所有序列的长度都是 $w$，可以存储到一个矩阵里。</p><h2 id=-词嵌入>🍀️ 词嵌入</h2><p>文本处理已经完成了，现在每个词都用一个正整数来表示，下一步是 <code>Word Embedding</code>，把每个词都表示为一个一维向量。</p><p>现在每个单词都用一个数字来表示，该怎么把这些 <code>Categorical</code> 特征表示为数值向量呢？</p><p>显然可以做 <code>one-hot encoding</code>，用一个 <code>one-hot</code> 向量来表示一个单词。
比如 <code>good: index = 2</code>，于是使用标准正交积 $e_2$ 来表示，它的第二个元素是 1，其余元素都是 0，$e_2=[0, 1, 0, 0, &mldr;, 0]$</p><p>假如 <code>vocabulary = v</code>，也就是说字典里一共有 $v$ 个单词，那么就需要维度 <code>dimension = v</code> 的 <code>one-hot</code> 向量，要是字典里有 1 万个单词，那么这些 <code>one-hot</code> 向量都是 1 万维的，这样的向量维度是在太高了。下一节介绍 RNN 的时候你会看到，RNN 的参数数量正比于输入向量的维度，我们肯定不想让输入的向量是 1 万维的，否则一层 RNN 将会有好几十万个参数。所以我们要做 <code>Word Embedding</code>，把这些高维 <code>one-hot</code> 向量映射到低维向量。</p><p>具体做法是吧 <code>one-hot</code> 向量 $e_i$ 乘到参数矩阵 $P^T$ 上，矩阵 $P^T$ 的大小是 $d*v$。其中 $d$ 是词向量的维度，由用户自己决定；$v$ 是 <code>vocabulary</code>，表示字典里单词的数量。</p><p><img src=https://nlp.letout.cn/img/nlp/02/7.png loading=lazy alt=7></p><p>矩阵的乘法的结果记做向量 $x_i$，$x_i$ 就是一个词向量，维度是 $d*1$，如果 <code>one-hot</code> 向量 $e$ 的第三个元素是 1，那么 $x_i$ 就是 $P^T$ 矩阵的第三列，可以看出，$P^T$ 矩阵每一列都是一个词向量。</p><p>同理，下面这个参数矩阵 $P$ 的每一行都是一个词向量。这个矩阵的行数是 $v$，也就是 <code>vocabulary</code>；每一行对应一个单词，矩阵的列数是 $d$，$d$ 是用户决定的，$d$ 的大小会影响机器学习模型的表现，应该用 交叉验证 <code>Cross Validation</code> 用来选择一个比较好的 $d$。</p><p>字典里的第一个词的是 <code>movie</code>，那么第一行就是 <code>movie</code> 的词向量；字典里的第二个词是 <code>good</code>，那么第二行就是 <code>good</code> 的词向量。</p><p><img src=https://nlp.letout.cn/img/nlp/02/8.png loading=lazy alt=8></p><p>我们的任务是判断电影评论是正面的还是负面的，这个参数矩阵是从训练数据中学习出来的，所以这些词向量都带有感情色彩，假如这些词向量都是二维的，我们就可以在平面坐标系中标出这些词向量。</p><p><img src=https://nlp.letout.cn/img/nlp/02/9.png loading=lazy alt=9></p><p><code>fantastic; good; fun</code> 这些词向量都带有正面情感，所以这三个词的词向量学出来都比较接近；同理，<code>poor; boring; mediocre</code> 这些词带有负面情感，所以学出来的词同样也应该比较接近，但是这些词的词向量应该远离正面色彩的词向量。像 <code>movie; is</code> 这样的中性词，没有感情色彩，它们应该在中间。</p><h2 id=-总结>🎐 总结</h2><p>最后总结一下这一章的内容。</p><p>这一节上半部分，说明了文本处理是什么样的。给我们一条电影评论，首先做 <code>Tokenization</code>，把电影评论分割成很多单词，然后把很多单词编码成数字，这样一整条电影评论就可以很多正整数来表示，我们把这个正整数序列叫做 <code>Sequences</code>，就是神经网络中 <code>Embedding</code> 层的输入。由于电影评论的长短不一，得到的 <code>Sequence</code> 的长短也不一样，没办法存储在一个矩阵里，解决方案是 <code>Alignment</code> 对齐。假设最大长度为 <code>20</code>，如果长度大于<code>20</code>，就只保留最后 <code>20</code> 个单词；如果长度不到 <code>20</code>，就用 <code>0</code> 补齐，把长度增加到 <code>20</code>。这样一来，每个 <code>Sequences</code> 长度都相同。</p></section><footer class=article-footer><section class=article-tags><a href=/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/>自然语言处理</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css integrity=sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js integrity=sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script></article><aside class=related-contents--wrapper><h2 class=section-title>相关文章</h2><div class=related-contents><div class="flex article-list--tile"><article class=has-image><a href=/p/nlp-in-action/long-short-term-memory/><div class=article-image><img src=https://nlp.letout.cn/img/banner.png loading=lazy data-key=/nlp-in-action/long-short-term-memory data-hash=https://nlp.letout.cn/img/banner.png></div><div class=article-details><h2 class=article-title>Long Shorter Term Memory</h2></div></a></article><article class=has-image><a href=/p/nlp-in-action/simple-rnn/><div class=article-image><img src=https://nlp.letout.cn/img/banner.png loading=lazy data-key=/nlp-in-action/simple-rnn data-hash=https://nlp.letout.cn/img/banner.png></div><div class=article-details><h2 class=article-title>RNN</h2></div></a></article><article class=has-image><a href=/p/nlp-in-action/data-processing/><div class=article-image><img src=https://nlp.letout.cn/img/banner.png loading=lazy data-key=/nlp-in-action/data-processing data-hash=https://nlp.letout.cn/img/banner.png></div><div class=article-details><h2 class=article-title>数据处理基础</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2023 一层</section><section class=powerby><b><a href=http://beian.miit.gov.cn/ target=_blank rel="nofollow noopener">赣ICP备19004365号-3</a></b><br>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=%s>Stack</a></b> by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a><br></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#-imdb>🌱 IMDb</a></li><li><a href=#-文本处理文本处理>🔖 文本处理文本处理</a><ol><li><a href=#-tokenization>🚀 Tokenization</a></li><li><a href=#-build-dictionary>🧰 Build Dictionary</a></li></ol></li><li><a href=#-词嵌入>🍀️ 词嵌入</a></li><li><a href=#-总结>🎐 总结</a></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script></script></body></html>